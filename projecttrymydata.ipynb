{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nutsudapenpong/DPDM/blob/master/projecttrymydata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pEoHjnXaqlE"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from keras import initializers, regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAsZHL5PiptM"
      },
      "source": [
        "#Config setting\n",
        "#This is a config class where we initiate the base model to use, anchor_box_scales-adjusted as per the bounding boxes of the objects in the image, number of rois(region of interests) to return at once, image augmentation and various other parameters."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l40u_wP_i1IK"
      },
      "source": [
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\t# Print the process or not\n",
        "\t\tself.verbose = True\n",
        "\n",
        "\t\t# Name of base network\n",
        "\t\tself.network = 'vgg'\n",
        "\n",
        "\t\t# Setting for data augmentation\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\t# Anchor box scales\n",
        "    # Note that if im_size is smaller, anchor_box_scales should be scaled\n",
        "    # Original anchor_box_scales in the paper is [128, 256, 512]\n",
        "\t\tself.anchor_box_scales = [8,16,32] \n",
        "\n",
        "\t\t# Anchor box ratios\n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "\t\t# Size to resize the smallest side of the image\n",
        "\t\t# Original setting in paper is 600. Set to 300 in here to save training time\n",
        "\t\tself.im_size = 300\n",
        "\n",
        "\t\t# image channel-wise mean to subtract\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "\n",
        "\t\t# number of ROIs at once\n",
        "\t\tself.num_rois = 4\n",
        "\n",
        "\t\t# stride at the RPN (this depends on the network configuration)\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\t# scaling the stdev\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\t# overlaps for RPN\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\t# overlaps for classifier ROIs\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\n",
        "\t\t# placeholder for the class mapping, automatically generated by the parser\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\tself.model_path = None"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccRFoL7EjFcH"
      },
      "source": [
        "#Parse the data from annotation file\n",
        "#Based on the annotation file input, number of classes and the bounding box information will be extracted."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc0Gsd0WjJtm"
      },
      "source": [
        "def get_data(input_path):\n",
        "\t\"\"\"Parse the data from annotation file\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tinput_path: annotation file path\n",
        "\n",
        "\tReturns:\n",
        "\t\tall_data: list(filepath, width, height, list(bboxes))\n",
        "\t\tclasses_count: dict{key:class_name, value:count_num} \n",
        "\t\t\te.g. {'red blood cell': 77420, 'trophozoite': 1473, 'difficult': 441, 'ring': 353,'schizont':179, 'gametocyte':144,\n",
        "            'leukocyte':103}\n",
        "\t\tclass_mapping: dict{key:class_name, value: idx}\n",
        "\t\t\te.g. {'red blood cell': 0, 'trophozoite': 1, 'difficult': 2, 'ring': 3,'schizont':4, 'gametocyte':5,\n",
        "            'leukocyte':6}\n",
        "\t\"\"\"\n",
        "\tfound_bg = False\n",
        "\tall_imgs = {}\n",
        "\n",
        "\tclasses_count = {}\n",
        "\n",
        "\tclass_mapping = {}\n",
        "\n",
        "\tvisualise = True\n",
        "\n",
        "\ti = 1\n",
        "\t\n",
        "\twith open(input_path,'r') as f:\n",
        "\n",
        "\t\tprint('Parsing annotation files')\n",
        "\n",
        "\t\tfor line in f:\n",
        "\n",
        "\t\t\t# Print process\n",
        "\t\t\tsys.stdout.write('\\r'+'idx=' + str(i))\n",
        "\t\t\ti += 1\n",
        "\n",
        "\t\t\tline_split = line.strip().split(',')\n",
        "   \t\t\n",
        "      # Make sure the info saved in annotation file matching the format (path_filename, x1, y1, x2, y2, class_name)\n",
        "\t\t\t# Note:\n",
        "\t\t\t#\tOne path_filename might has several classes (class_name)\n",
        "\t\t\t#\tx1, y1, x2, y2 are the pixel value of the origial image, not the ratio value\n",
        "\t\t\t#\t(x1, y1) top left coordinates; (x2, y2) bottom right coordinates\n",
        "\t\t\t#   x1,y1-------------------\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t---------------------x2,y2\n",
        "\n",
        "\t\t\t(filename,x1,y1,x2,y2,class_name) = line_split\n",
        "\n",
        "\t\t\tif class_name not in classes_count:\n",
        "\t\t\t\tclasses_count[class_name] = 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tclasses_count[class_name] += 1\n",
        "\n",
        "\t\t\tif class_name not in class_mapping:\n",
        "\t\t\t\tif class_name == 'bg' and found_bg == False:\n",
        "\t\t\t\t\tprint('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
        "\t\t\t\t\tfound_bg = True\n",
        "\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "\t\t\tif filename not in all_imgs:\n",
        "\t\t\t\tall_imgs[filename] = {}\n",
        "\t\t\t\t\n",
        "\t\t\t\timg = cv2.imread(filename)\n",
        "\t\t\t\t(rows,cols) = img.shape[:2]\n",
        "\t\t\t\tall_imgs[filename]['filepath'] = filename\n",
        "\t\t\t\tall_imgs[filename]['width'] = cols\n",
        "\t\t\t\tall_imgs[filename]['height'] = rows\n",
        "\t\t\t\tall_imgs[filename]['bboxes'] = []\n",
        "\t\t\t\t# if np.random.randint(0,6) > 0:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'trainval'\n",
        "\t\t\t\t# else:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'test'\n",
        "\n",
        "\t\t\tall_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
        "   \n",
        "\n",
        "\t\tall_data = []\n",
        "\t\tfor key in all_imgs:\n",
        "\t\t\tall_data.append(all_imgs[key])\n",
        "\t\t\n",
        "\t\t# make sure the bg class is last in the list\n",
        "\t\tif found_bg:\n",
        "\t\t\tif class_mapping['bg'] != len(class_mapping) - 1:\n",
        "\t\t\t\tkey_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
        "\t\t\t\tval_to_switch = class_mapping['bg']\n",
        "\t\t\t\tclass_mapping['bg'] = len(class_mapping) - 1\n",
        "\t\t\t\tclass_mapping[key_to_switch] = val_to_switch\n",
        "\t\t\n",
        "\t\treturn all_data, classes_count, class_mapping"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7AUTfh1jqm4"
      },
      "source": [
        "#Define ROI Pooling Convolutional Layer\n",
        "#Region-based convolutional neural network (R-CNN) is the final step in Faster R-CNN’s pipeline. After getting a convolutional feature map from the image, using it to get object proposals with the RPN and finally extracting features for each of those proposals (via RoI Pooling), we finally need to use these features for classification. R-CNN tries to mimic the final stages of classification CNNs where a fully-connected layer is used to output a score for each possible object class."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpnpHS3djwys"
      },
      "source": [
        "class RoiPoolingConv(Layer):\n",
        "    '''ROI pooling layer for 2D inputs.\n",
        "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
        "    K. He, X. Zhang, S. Ren, J. Sun\n",
        "    # Arguments\n",
        "        pool_size: int\n",
        "            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n",
        "        num_rois: number of regions of interest to be used\n",
        "    # Input shape\n",
        "        list of two 4D tensors [X_img,X_roi] with shape:\n",
        "        X_img:\n",
        "        `(1, rows, cols, channels)`\n",
        "        X_roi:\n",
        "        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "    # Output shape\n",
        "        3D tensor with shape:\n",
        "        `(1, num_rois, channels, pool_size, pool_size)`\n",
        "    '''\n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "\n",
        "        self.dim_ordering = K.image_data_format()\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]   \n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert(len(x) == 2)\n",
        "\n",
        "        # x[0] is image with shape (rows, cols, channels)\n",
        "        img = x[0]\n",
        "\n",
        "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
        "        rois = x[1]\n",
        "\n",
        "        input_shape = K.shape(img)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for roi_idx in range(self.num_rois):\n",
        "\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "\n",
        "            x = K.cast(x, 'int32')\n",
        "            y = K.cast(y, 'int32')\n",
        "            w = K.cast(w, 'int32')\n",
        "            h = K.cast(h, 'int32')\n",
        "\n",
        "            # Resized roi of the image to pooling size (7x7)\n",
        "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "            outputs.append(rs)\n",
        "                \n",
        "\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
        "        # Might be (1, 4, 7, 7, 3)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "\n",
        "        # permute_dimensions is similar to transpose\n",
        "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size,\n",
        "                  'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19rQB2MgkUOG"
      },
      "source": [
        "#Vgg-16 model\n",
        "#VGG-16 trained on imagenet is used as base model for detecting objects using Faster R-CNN"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g5e_HraoHyn"
      },
      "source": [
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        return input_length//16\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)    \n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "\n",
        "\n",
        "    input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    bn_axis = 3\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVJ2syboWg8"
      },
      "source": [
        "#RPN layer\n",
        "#The RPN takes all the reference boxes (anchors) and outputs a set of good proposals for objects. It does this by having two different outputs for each of the anchors.\n",
        "\n",
        "#The first one is the probability that an anchor is an object. An “objectness score”, if you will. Note that the RPN doesn’t care what class of object it is, only that it does in fact look like an object (and not background). We are going to use this objectness score to filter out the bad predictions for the second stage. The second output is the bounding box regression for adjusting the anchors to better fit the object it’s predicting.\n",
        "\n",
        "#The RPN is implemented efficiently in a fully convolutional way, using the convolutional feature map returned by the base network as an input. First, we use a convolutional layer with 512 channels and 3x3 kernel size and then we have two parallel convolutional layers using a 1x11x1 kernel, whose number of channels depends on the number of anchors per point."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h67HkMvooc6V"
      },
      "source": [
        "def rpn_layer(base_layers, num_anchors):\n",
        "    \"\"\"Create a rpn layer\n",
        "        Step1: Pass through the feature map from base layer to a 3x3 512 channels convolutional layer\n",
        "                Keep the padding 'same' to preserve the feature map's size\n",
        "        Step2: Pass the step1 to two (1,1) convolutional layer to replace the fully connected layer\n",
        "                classification layer: num_anchors (9 in here) channels for 0, 1 sigmoid activation output\n",
        "                regression layer: num_anchors*4 (36 in here) channels for computing the regression of bboxes with linear activation\n",
        "    Args:\n",
        "        base_layers: vgg in here\n",
        "        num_anchors: 9 in here\n",
        "\n",
        "    Returns:\n",
        "        [x_class, x_regr, base_layers]\n",
        "        x_class: classification for whether it's an object\n",
        "        x_regr: bboxes regression\n",
        "        base_layers: vgg in here\n",
        "    \"\"\"\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIsP0rm7oiEz"
      },
      "source": [
        "#Classifier layer\n",
        "#For the classification layer, we output two predictions per anchor: the score of it being background (not an object) and the score of it being foreground (an actual object).\n",
        "\n",
        "#For the regression, or bounding box adjustment layer, we output 4 predictions: the deltas \\Delta{x{center}}, \\Delta{y{center}}, \\Delta{width}, \\Delta{height}Δxcenter,Δycenter,Δwidth,Δheight which we will apply to the anchors to get the final proposals.\n",
        "\n",
        "#Using the final proposal coordinates and their “objectness” score we then have a good set of proposals for objects."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8OtwoNPopqN"
      },
      "source": [
        "def classifier_layer(base_layers, input_rois, num_rois, nb_classes = 4):\n",
        "    \"\"\"Create a classifier layer\n",
        "    \n",
        "    Args:\n",
        "        base_layers: vgg\n",
        "        input_rois: `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "        num_rois: number of rois to be processed in one time (4 in here)\n",
        "\n",
        "    Returns:\n",
        "        list(out_class, out_regr)\n",
        "        out_class: classifier layer output\n",
        "        out_regr: regression layer output\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = (num_rois,7,7,512)\n",
        "\n",
        "    pooling_regions = 7\n",
        "\n",
        "    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n",
        "    # num_rois (4) 7x7 roi pooling\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "\n",
        "    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n",
        "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "    # There are two output layer\n",
        "    # out_class: softmax acivation function for classify the class name of the object\n",
        "    # out_regr: linear activation function for bboxes coordinates regression\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    # note: no regression target for bg class\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "\n",
        "    return [out_class, out_regr]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAAnhp5Eoxba"
      },
      "source": [
        "#Calculate IoU (Intersection of Union)\n",
        "#IoU is to find the overlap score between anchors and ground truth bounding boxes."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp518mKMo0dg"
      },
      "source": [
        "def union(au, bu, area_intersection):\n",
        "\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "\tarea_union = area_a + area_b - area_intersection\n",
        "\treturn area_union\n",
        "\n",
        "\n",
        "def intersection(ai, bi):\n",
        "\tx = max(ai[0], bi[0])\n",
        "\ty = max(ai[1], bi[1])\n",
        "\tw = min(ai[2], bi[2]) - x\n",
        "\th = min(ai[3], bi[3]) - y\n",
        "\tif w < 0 or h < 0:\n",
        "\t\treturn 0\n",
        "\treturn w*h\n",
        "\n",
        "\n",
        "def iou(a, b):\n",
        "\t# a and b should be (x1,y1,x2,y2)\n",
        "\n",
        "\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "\t\treturn 0.0\n",
        "\n",
        "\tarea_i = intersection(a, b)\n",
        "\tarea_u = union(a, b, area_i)\n",
        "\n",
        "\treturn float(area_i) / float(area_u + 1e-6)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zygRxlH8o3mW"
      },
      "source": [
        "#Calculate the rpn for all anchors of all images"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ05yOQfpyz9"
      },
      "source": [
        "def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "\t\"\"\"(Important part!) Calculate the rpn for all anchors \n",
        "\t\tIf feature map has shape 38x50=1900, there are 1900x9=17100 potential anchors\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tC: config\n",
        "\t\timg_data: augmented image data\n",
        "\t\twidth: original image width (e.g. 600)\n",
        "\t\theight: original image height (e.g. 800)\n",
        "\t\tresized_width: resized image width according to C.im_size (e.g. 300)\n",
        "\t\tresized_height: resized image height according to C.im_size (e.g. 400)\n",
        "\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n",
        "\n",
        "\tReturns:\n",
        "\t\ty_rpn_cls: list(num_bboxes, y_is_box_valid + y_rpn_overlap)\n",
        "\t\t\ty_is_box_valid: 0 or 1 (0 means the box is invalid, 1 means the box is valid)\n",
        "\t\t\ty_rpn_overlap: 0 or 1 (0 means the box is not an object, 1 means the box is an object)\n",
        "\t\ty_rpn_regr: list(num_bboxes, 4*y_rpn_overlap + y_rpn_regr)\n",
        "\t\t\ty_rpn_regr: x1,y1,x2,y2 bunding boxes coordinates\n",
        "\t\"\"\"\n",
        "\tdownscale = float(C.rpn_stride) \n",
        "\tanchor_sizes = C.anchor_box_scales   # 128, 256, 512\n",
        "\tanchor_ratios = C.anchor_box_ratios  # 1:1, 1:2*sqrt(2), 2*sqrt(2):1\n",
        "\tnum_anchors = len(anchor_sizes) * len(anchor_ratios) # 3x3=9\n",
        "\n",
        "\t# calculate the output map size based on the network architecture\n",
        "\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "\n",
        "\tn_anchratios = len(anchor_ratios)    # 3\n",
        "\t\n",
        "\t# initialise empty output objectives\n",
        "\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "\tnum_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n",
        "\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n",
        "\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n",
        "\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n",
        "\n",
        "\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\tgta = np.zeros((num_bboxes, 4))\n",
        "\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "\t\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n",
        "\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "\t\n",
        "\t# rpn ground truth\n",
        "\n",
        "\tfor anchor_size_idx in range(len(anchor_sizes)):\n",
        "\t\tfor anchor_ratio_idx in range(n_anchratios):\n",
        "\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n",
        "\t\t\t\n",
        "\t\t\tfor ix in range(output_width):\t\t\t\t\t\n",
        "\t\t\t\t# x-coordinates of the current anchor box\t\n",
        "\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n",
        "\t\t\t\t\n",
        "\t\t\t\t# ignore boxes that go across image boundaries\t\t\t\t\t\n",
        "\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tfor jy in range(output_height):\n",
        "\n",
        "\t\t\t\t\t# y-coordinates of the current anchor box\n",
        "\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\n",
        "\t\t\t\t\t# ignore boxes that go across image boundaries\n",
        "\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t\t# bbox_type indicates whether an anchor should be a target\n",
        "\t\t\t\t\t# Initialize with 'negative'\n",
        "\t\t\t\t\tbbox_type = 'neg'\n",
        "\n",
        "\t\t\t\t\t# this is the best IOU for the (x,y) coord and the current anchor\n",
        "\t\t\t\t\t# note that this is different from the best IOU for a GT bbox\n",
        "\t\t\t\t\tbest_iou_for_loc = 0.0\n",
        "\n",
        "\t\t\t\t\tfor bbox_num in range(num_bboxes):\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t# get IOU of the current GT box and the current anchor box\n",
        "\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\t\t\t\t\t\t# calculate the regression targets if they will be needed\n",
        "\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n",
        "\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "\t\t\t\t\t\t\t# x,y are the center point of ground-truth bbox\n",
        "\t\t\t\t\t\t\t# xa,ya are the center point of anchor bbox (xa=downscale * (ix + 0.5); ya=downscale * (iy+0.5))\n",
        "\t\t\t\t\t\t\t# w,h are the width and height of ground-truth bbox\n",
        "\t\t\t\t\t\t\t# wa,ha are the width and height of anchor bboxe\n",
        "\t\t\t\t\t\t\t# tx = (x - xa) / wa\n",
        "\t\t\t\t\t\t\t# ty = (y - ya) / ha\n",
        "\t\t\t\t\t\t\t# tw = log(w / wa)\n",
        "\t\t\t\t\t\t\t# th = log(h / ha)\n",
        "\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n",
        "\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "\n",
        "\t\t\t\t\t\t\t# all GT boxes should be mapped to an anchor box, so we keep track of which anchor box was best\n",
        "\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n",
        "\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n",
        "\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n",
        "\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n",
        "\n",
        "\t\t\t\t\t\t\t# we set the anchor to positive if the IOU is >0.7 (it does not matter if there was another better box, it just indicates overlap)\n",
        "\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tbbox_type = 'pos'\n",
        "\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n",
        "\t\t\t\t\t\t\t\t# we update the regression layer target if this IOU is the best for the current (x,y) and anchor position\n",
        "\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n",
        "\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n",
        "\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n",
        "\n",
        "\t\t\t\t\t\t\t# if the IOU is >0.3 and <0.7, it is ambiguous and no included in the objective\n",
        "\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\t# gray zone between neg and pos\n",
        "\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n",
        "\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n",
        "\n",
        "\t\t\t\t\t# turn on or off outputs depending on IOUs\n",
        "\t\t\t\t\tif bbox_type == 'neg':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'neutral':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'pos':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "\t# we ensure that every bbox has at least one positive RPN region\n",
        "\n",
        "\tfor idx in range(num_anchors_for_bbox.shape[0]):\n",
        "\t\tif num_anchors_for_bbox[idx] == 0:\n",
        "\t\t\t# no box with an IOU greater than zero ...\n",
        "\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_is_box_valid[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\ty_rpn_overlap[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n",
        "\t\t\ty_rpn_regr[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n",
        "\n",
        "\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "\tnum_pos = len(pos_locs[0])\n",
        "\n",
        "\t# one issue is that the RPN has many more negative than positive regions, so we turn off some of the negative\n",
        "\t# regions. We also limit it to 256 regions.\n",
        "\tnum_regions = 256\n",
        "\n",
        "\tif len(pos_locs[0]) > num_regions/2:\n",
        "\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n",
        "\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "\t\tnum_pos = num_regions/2\n",
        "\n",
        "\tif len(neg_locs[0]) + num_pos > num_regions:\n",
        "\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n",
        "\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOQtotwUqMB4"
      },
      "source": [
        "#Get new image size and augment the image"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdTME5AjqRV-"
      },
      "source": [
        "def get_new_img_size(width, height, img_min_side=300):\n",
        "\tif width <= height:\n",
        "\t\tf = float(img_min_side) / width\n",
        "\t\tresized_height = int(f * height)\n",
        "\t\tresized_width = img_min_side\n",
        "\telse:\n",
        "\t\tf = float(img_min_side) / height\n",
        "\t\tresized_width = int(f * width)\n",
        "\t\tresized_height = img_min_side\n",
        "\n",
        "\treturn resized_width, resized_height\n",
        "\n",
        "def augment(img_data, config, augment=True):\n",
        "\tassert 'filepath' in img_data\n",
        "\tassert 'bboxes' in img_data\n",
        "\tassert 'width' in img_data\n",
        "\tassert 'height' in img_data\n",
        "\n",
        "\timg_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "\timg = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "\tif augment:\n",
        "\t\trows, cols = img.shape[:2]\n",
        "\n",
        "\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\tbbox['x1'] = cols - x2\n",
        "\n",
        "\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\tbbox['y1'] = rows - y2\n",
        "\n",
        "\t\tif config.rot_90:\n",
        "\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n",
        "\t\t\tif angle == 270:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\telif angle == 180:\n",
        "\t\t\t\timg = cv2.flip(img, -1)\n",
        "\t\t\telif angle == 90:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\telif angle == 0:\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tif angle == 270:\n",
        "\t\t\t\t\tbbox['x1'] = y1\n",
        "\t\t\t\t\tbbox['x2'] = y2\n",
        "\t\t\t\t\tbbox['y1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = cols - x1\n",
        "\t\t\t\telif angle == 180:\n",
        "\t\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\t\tbbox['x1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = rows - y2\n",
        "\t\t\t\telif angle == 90:\n",
        "\t\t\t\t\tbbox['x1'] = rows - y2\n",
        "\t\t\t\t\tbbox['x2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = x1\n",
        "\t\t\t\t\tbbox['y2'] = x2        \n",
        "\t\t\t\telif angle == 0:\n",
        "\t\t\t\t\tpass\n",
        "\n",
        "\timg_data_aug['width'] = img.shape[1]\n",
        "\timg_data_aug['height'] = img.shape[0]\n",
        "\treturn img_data_aug, img"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2DSI_UMqbHR"
      },
      "source": [
        "#Generate the ground_truth anchors"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV9tLLqgqfEW"
      },
      "source": [
        "def get_anchor_gt(all_img_data, C, img_length_calc_function, mode='train'):\n",
        "\t\"\"\" Yield the ground-truth anchors as Y (labels)\n",
        "\t\t\n",
        "\tArgs:\n",
        "\t\tall_img_data: list(filepath, width, height, list(bboxes))\n",
        "\t\tC: config\n",
        "\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n",
        "\t\tmode: 'train' or 'test'; 'train' mode need augmentation\n",
        "\n",
        "\tReturns:\n",
        "\t\tx_img: image data after resized and scaling (smallest size = 300px)\n",
        "\t\tY: [y_rpn_cls, y_rpn_regr]\n",
        "\t\timg_data_aug: augmented image data (original image with augmentation)\n",
        "\t\tdebug_img: show image for debug\n",
        "\t\tnum_pos: show number of positive anchors for debug\n",
        "\t\"\"\"\n",
        "\twhile True:\n",
        "\n",
        "\t\tfor img_data in all_img_data:\n",
        "\t\t\ttry:\n",
        "\n",
        "\t\t\t\t# read in image, and optionally add augmentation\n",
        "\n",
        "\t\t\t\tif mode == 'train':\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=False)\n",
        "\n",
        "\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
        "\t\t\t\t(rows, cols, _) = x_img.shape\n",
        "\n",
        "\t\t\t\tassert cols == width\n",
        "\t\t\t\tassert rows == height\n",
        "\n",
        "\t\t\t\t# get image dimensions for resizing\n",
        "\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\t\t\t\t# resize the image so that smalles side is length = 300px\n",
        "\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t\t\t\tdebug_img = x_img.copy()\n",
        "\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ty_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# Zero-center by mean pixel, and preprocess image\n",
        "\n",
        "\t\t\t\tx_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n",
        "\t\t\t\tx_img = x_img.astype(np.float32)\n",
        "\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n",
        "\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n",
        "\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n",
        "\t\t\t\tx_img /= C.img_scaling_factor\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n",
        "\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n",
        "\n",
        "\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug, debug_img, num_pos\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059WQjXrqkrV"
      },
      "source": [
        "#Define loss functions for all four outputs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26vd7_1qp_R"
      },
      "source": [
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp6s0Zr3qrGO"
      },
      "source": [
        "def rpn_loss_regr(num_anchors):\n",
        "    \"\"\"Loss function for rpn regression\n",
        "    Args:\n",
        "        num_anchors: number of anchors (9 in here)\n",
        "    Returns:\n",
        "        Smooth L1 loss function \n",
        "                           0.5*x*x (if x_abs < 1)\n",
        "                           x_abx - 0.5 (otherwise)\n",
        "    \"\"\"\n",
        "    def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "\n",
        "        # x is the difference between true value and predicted vaue\n",
        "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
        "\n",
        "        # absolute value of x\n",
        "        x_abs = K.abs(x)\n",
        "\n",
        "        # If x_abs <= 1.0, x_bool = 1\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
        "\n",
        "        return lambda_rpn_regr * K.sum(\n",
        "            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
        "\n",
        "    return rpn_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "    \"\"\"Loss function for rpn classification\n",
        "    Args:\n",
        "        num_anchors: number of anchors (9 in here)\n",
        "        y_true[:, :, :, :9]: [0,1,0,0,0,0,0,1,0] means only the second and the eighth box is valid which contains pos or neg anchor => isValid\n",
        "        y_true[:, :, :, 9:]: [0,1,0,0,0,0,0,0,0] means the second box is pos and eighth box is negative\n",
        "    Returns:\n",
        "        lambda * sum((binary_crossentropy(isValid*y_pred,y_true))) / N\n",
        "    \"\"\"\n",
        "    def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "\n",
        "            return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
        "\n",
        "    return rpn_loss_cls_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "    \"\"\"Loss function for rpn regression\n",
        "    Args:\n",
        "        num_anchors: number of anchors (9 in here)\n",
        "    Returns:\n",
        "        Smooth L1 loss function \n",
        "                           0.5*x*x (if x_abs < 1)\n",
        "                           x_abx - 0.5 (otherwise)\n",
        "    \"\"\"\n",
        "    def class_loss_regr_fixed_num(y_true, y_pred):\n",
        "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n",
        "        return lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n",
        "    return class_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_cls(y_true, y_pred):\n",
        "    return lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49BXVVvcqwIB"
      },
      "source": [
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "    # code used from here: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
        "    # if there are no boxes, return an empty list\n",
        "\n",
        "    # Process explanation:\n",
        "    #   Step 1: Sort the probs list\n",
        "    #   Step 2: Find the larget prob 'Last' in the list and save it to the pick list\n",
        "    #   Step 3: Calculate the IoU with 'Last' box and other boxes in the list. If the IoU is larger than overlap_threshold, delete the box from list\n",
        "    #   Step 4: Repeat step 2 and step 3 until there is no item in the probs list \n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # grab the coordinates of the bounding boxes\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    np.testing.assert_array_less(x1, x2)\n",
        "    np.testing.assert_array_less(y1, y2)\n",
        "\n",
        "    # if the bounding boxes integers, convert them to floats --\n",
        "    # this is important since we'll be doing a bunch of divisions\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    # initialize the list of picked indexes\t\n",
        "    pick = []\n",
        "\n",
        "    # calculate the areas\n",
        "    area = (x2 - x1) * (y2 - y1)\n",
        "\n",
        "    # sort the bounding boxes \n",
        "    idxs = np.argsort(probs)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes\n",
        "    # list\n",
        "    while len(idxs) > 0:\n",
        "        # grab the last index in the indexes list and add the\n",
        "        # index value to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # find the intersection\n",
        "\n",
        "        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        ww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "        hh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "        area_int = ww_int * hh_int\n",
        "\n",
        "        # find the union\n",
        "        area_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "        # compute the ratio of overlap\n",
        "        overlap = area_int/(area_union + 1e-6)\n",
        "\n",
        "        # delete all indexes from the index list that have\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "            np.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "        if len(pick) >= max_boxes:\n",
        "            break\n",
        "\n",
        "    # return only the bounding boxes that were picked using the integer data type\n",
        "    boxes = boxes[pick].astype(\"int\")\n",
        "    probs = probs[pick]\n",
        "    return boxes, probs\n",
        "\n",
        "def apply_regr_np(X, T):\n",
        "    \"\"\"Apply regression layer to all anchors in one feature map\n",
        "\n",
        "    Args:\n",
        "        X: shape=(4, 18, 25) the current anchor type for all points in the feature map\n",
        "        T: regression layer shape=(4, 18, 25)\n",
        "\n",
        "    Returns:\n",
        "        X: regressed position and size for current anchor\n",
        "    \"\"\"\n",
        "    try:\n",
        "        x = X[0, :, :]\n",
        "        y = X[1, :, :]\n",
        "        w = X[2, :, :]\n",
        "        h = X[3, :, :]\n",
        "\n",
        "        tx = T[0, :, :]\n",
        "        ty = T[1, :, :]\n",
        "        tw = T[2, :, :]\n",
        "        th = T[3, :, :]\n",
        "\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "\n",
        "        w1 = np.exp(tw.astype(np.float64)) * w\n",
        "        h1 = np.exp(th.astype(np.float64)) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "\n",
        "        x1 = np.round(x1)\n",
        "        y1 = np.round(y1)\n",
        "        w1 = np.round(w1)\n",
        "        h1 = np.round(h1)\n",
        "        return np.stack([x1, y1, w1, h1])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return X\n",
        "    \n",
        "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
        "    # Apply regression to x, y, w and h\n",
        "    try:\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "        w1 = math.exp(tw) * w\n",
        "        h1 = math.exp(th) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        w1 = int(round(w1))\n",
        "        h1 = int(round(h1))\n",
        "\n",
        "        return x1, y1, w1, h1\n",
        "\n",
        "    except ValueError:\n",
        "        return x, y, w, h\n",
        "    except OverflowError:\n",
        "        return x, y, w, h\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return x, y, w, h\n",
        "\n",
        "def calc_iou(R, img_data, C, class_mapping):\n",
        "    \"\"\"Converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "\n",
        "    Args:\n",
        "        R: bboxes, probs\n",
        "    \"\"\"\n",
        "    bboxes = img_data['bboxes']\n",
        "    (width, height) = (img_data['width'], img_data['height'])\n",
        "    # get image dimensions for resizing\n",
        "    (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "    gta = np.zeros((len(bboxes), 4))\n",
        "\n",
        "    for bbox_num, bbox in enumerate(bboxes):\n",
        "        # get the GT box coordinates, and resize to account for image resizing\n",
        "        # gta[bbox_num, 0] = (40 * (600 / 800)) / 16 = int(round(1.875)) = 2 (x in feature map)\n",
        "        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
        "        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
        "\n",
        "    x_roi = []\n",
        "    y_class_num = []\n",
        "    y_class_regr_coords = []\n",
        "    y_class_regr_label = []\n",
        "    IoUs = [] # for debugging only\n",
        "\n",
        "    # R.shape[0]: number of bboxes (=300 from non_max_suppression)\n",
        "    for ix in range(R.shape[0]):\n",
        "        (x1, y1, x2, y2) = R[ix, :]\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        x2 = int(round(x2))\n",
        "        y2 = int(round(y2))\n",
        "\n",
        "        best_iou = 0.0\n",
        "        best_bbox = -1\n",
        "        # Iterate through all the ground-truth bboxes to calculate the iou\n",
        "        for bbox_num in range(len(bboxes)):\n",
        "            curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
        "\n",
        "            # Find out the corresponding ground-truth bbox_num with larget iou\n",
        "            if curr_iou > best_iou:\n",
        "                best_iou = curr_iou\n",
        "                best_bbox = bbox_num\n",
        "\n",
        "        if best_iou < C.classifier_min_overlap:\n",
        "                continue\n",
        "        else:\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            x_roi.append([x1, y1, w, h])\n",
        "            IoUs.append(best_iou)\n",
        "\n",
        "            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
        "                # hard negative example\n",
        "                cls_name = 'bg'\n",
        "            elif C.classifier_max_overlap <= best_iou:\n",
        "                cls_name = bboxes[best_bbox]['class']\n",
        "                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
        "                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
        "\n",
        "                cx = x1 + w / 2.0\n",
        "                cy = y1 + h / 2.0\n",
        "\n",
        "                tx = (cxg - cx) / float(w)\n",
        "                ty = (cyg - cy) / float(h)\n",
        "                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
        "                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
        "            else:\n",
        "                print('roi = {}'.format(best_iou))\n",
        "                raise RuntimeError\n",
        "\n",
        "        class_num = class_mapping[cls_name]\n",
        "        class_label = len(class_mapping) * [0]\n",
        "        class_label[class_num] = 1\n",
        "        y_class_num.append(copy.deepcopy(class_label))\n",
        "        coords = [0] * 4 * (len(class_mapping) - 1)\n",
        "        labels = [0] * 4 * (len(class_mapping) - 1)\n",
        "        if cls_name != 'bg':\n",
        "            label_pos = 4 * class_num\n",
        "            sx, sy, sw, sh = C.classifier_regr_std\n",
        "            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
        "            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "        else:\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "\n",
        "    if len(x_roi) == 0:\n",
        "        return None, None, None, None\n",
        "\n",
        "    # bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "    X = np.array(x_roi)\n",
        "    # one hot code for bboxes from above => x_roi (X)\n",
        "    Y1 = np.array(y_class_num)\n",
        "    # corresponding labels and corresponding gt bboxes\n",
        "    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n",
        "\n",
        "    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0), IoUs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4l_eBHrDev"
      },
      "source": [
        "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
        "\t\"\"\"Convert rpn layer to roi bboxes\n",
        "\n",
        "\tArgs: (num_anchors = 9)\n",
        "\t\trpn_layer: output layer for rpn classification \n",
        "\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n",
        "\t\t\tMight be (1, 18, 25, 18) if resized image is 400 width and 300\n",
        "\t\tregr_layer: output layer for rpn regression\n",
        "\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n",
        "\t\t\tMight be (1, 18, 25, 72) if resized image is 400 width and 300\n",
        "\t\tC: config\n",
        "\t\tuse_regr: Wether to use bboxes regression in rpn\n",
        "\t\tmax_boxes: max bboxes number for non-max-suppression (NMS)\n",
        "\t\toverlap_thresh: If iou in NMS is larger than this threshold, drop the box\n",
        "\n",
        "\tReturns:\n",
        "\t\tresult: boxes from non-max-suppression (shape=(300, 4))\n",
        "\t\t\tboxes: coordinates for bboxes (on the feature map)\n",
        "\t\"\"\"\n",
        "\tregr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "\tanchor_sizes = C.anchor_box_scales   # (3 in here)\n",
        "\tanchor_ratios = C.anchor_box_ratios  # (3 in here)\n",
        "\n",
        "\tassert rpn_layer.shape[0] == 1\n",
        "\n",
        "\t(rows, cols) = rpn_layer.shape[1:3]\n",
        "\n",
        "\tcurr_layer = 0\n",
        "\n",
        "\t# A.shape = (4, feature_map.height, feature_map.width, num_anchors) \n",
        "\t# Might be (4, 18, 25, 18) if resized image is 400 width and 300\n",
        "\t# A is the coordinates for 9 anchors for every point in the feature map \n",
        "\t# => all 18x25x9=4050 anchors cooridnates\n",
        "\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
        "\n",
        "\tfor anchor_size in anchor_sizes:\n",
        "\t\tfor anchor_ratio in anchor_ratios:\n",
        "\t\t\t# anchor_x = (128 * 1) / 16 = 8  => width of current anchor\n",
        "\t\t\t# anchor_y = (128 * 2) / 16 = 16 => height of current anchor\n",
        "\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\t\t\t\n",
        "\t\t\t# curr_layer: 0~8 (9 anchors)\n",
        "\t\t\t# the Kth anchor of all position in the feature map (9th in total)\n",
        "\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] # shape => (18, 25, 4)\n",
        "\t\t\tregr = np.transpose(regr, (2, 0, 1)) # shape => (4, 18, 25)\n",
        "\n",
        "\t\t\t# Create 18x25 mesh grid\n",
        "\t\t\t# For every point in x, there are all the y points and vice versa\n",
        "\t\t\t# X.shape = (18, 25)\n",
        "\t\t\t# Y.shape = (18, 25)\n",
        "\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\n",
        "\t\t\t# Calculate anchor position and size for each feature map point\n",
        "\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2 # Top left x coordinate\n",
        "\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2 # Top left y coordinate\n",
        "\t\t\tA[2, :, :, curr_layer] = anchor_x       # width of current anchor\n",
        "\t\t\tA[3, :, :, curr_layer] = anchor_y       # height of current anchor\n",
        "\n",
        "\t\t\t# Apply regression to x, y, w and h if there is rpn regression layer\n",
        "\t\t\tif use_regr:\n",
        "\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
        "\n",
        "\t\t\t# Avoid width and height exceeding 1\n",
        "\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\t# Convert (x, y , w, h) to (x1, y1, x2, y2)\n",
        "\t\t\t# x1, y1 is top left coordinate\n",
        "\t\t\t# x2, y2 is bottom right coordinate\n",
        "\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
        "\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
        "\n",
        "\t\t\t# Avoid bboxes drawn outside the feature map\n",
        "\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
        "\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\tcurr_layer += 1\n",
        "\n",
        "\tall_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  # shape=(4050, 4)\n",
        "\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                   # shape=(4050,)\n",
        "\n",
        "\tx1 = all_boxes[:, 0]\n",
        "\ty1 = all_boxes[:, 1]\n",
        "\tx2 = all_boxes[:, 2]\n",
        "\ty2 = all_boxes[:, 3]\n",
        "\n",
        "\t# Find out the bboxes which is illegal and delete them from bboxes list\n",
        "\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "\n",
        "\tall_boxes = np.delete(all_boxes, idxs, 0)\n",
        "\tall_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "\t# Apply non_max_suppression\n",
        "\t# Only extract the bboxes. Don't need rpn probs in the later process\n",
        "\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "\n",
        "\treturn result"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOXdLfw7rQMZ"
      },
      "source": [
        "#Start training"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K82dGEVQiM9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3960ea22-e767-4735-82f7-0d40016747cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isLfHuNrrRcb"
      },
      "source": [
        "base_path = '/content/drive/My Drive/Parasite/New/Newlabel'\n",
        "\n",
        "train_path =  '/content/drive/My Drive/Parasite/New/Newlabel/train_annotations.txt' # Training data (annotation file)\n",
        "\n",
        "num_rois = 4 # Number of RoIs to process at once.\n",
        "\n",
        "# Augmentation flag\n",
        "horizontal_flips = True # Augment with horizontal flips in training. \n",
        "vertical_flips = True   # Augment with vertical flips in training. \n",
        "rot_90 = True           # Augment with 90 degree rotations in training. \n",
        "\n",
        "output_weight_path = os.path.join(base_path, 'model_frcnn_vgg.hdf5')\n",
        "\n",
        "record_path = os.path.join(base_path, 'record.csv') # Record data (used to save the losses, classification accuracy and mean average precision)\n",
        "\n",
        "base_weight_path = os.path.join(base_path, 'vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "config_output_filename = os.path.join(base_path, 'model_vgg_config.pickle')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4hOcEgOrT4q"
      },
      "source": [
        "# Create the config\n",
        "C = Config()\n",
        "\n",
        "C.use_horizontal_flips = horizontal_flips\n",
        "C.use_vertical_flips = vertical_flips\n",
        "C.rot_90 = rot_90\n",
        "\n",
        "C.record_path = record_path\n",
        "C.model_path = output_weight_path\n",
        "C.num_rois = num_rois\n",
        "\n",
        "C.base_net_weights = base_weight_path"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8op4aFE_Uwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f50df85-8ed2-4472-839d-c230538c0584"
      },
      "source": [
        "os.path.exists(C.model_path)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLzQhkS4rXkT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a0343e-e0a7-4ec7-cbe3-dcdf434b36c2"
      },
      "source": [
        "#--------------------------------------------------------#\n",
        "# This step will spend some time to load the data        #\n",
        "#--------------------------------------------------------#\n",
        "st = time.time()\n",
        "train_imgs, classes_count, class_mapping = get_data(train_path)\n",
        "print()\n",
        "print('Spend %0.2f mins to load the data' % ((time.time()-st)/60) )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing annotation files\n",
            "idx=516\n",
            "Spend 13.23 mins to load the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnL6NPh8icdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5001b4-cab5-481e-903c-36b291beeac3"
      },
      "source": [
        "if 'bg' not in classes_count:\n",
        "\tclasses_count['bg'] = 0\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "# e.g.\n",
        "#    classes_count: {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745, 'bg': 0}\n",
        "#    class_mapping: {'Person': 0, 'Car': 1, 'Mobile phone': 2, 'bg': 3}\n",
        "C.class_mapping = class_mapping\n",
        "\n",
        "print('Training images per class:')\n",
        "pprint.pprint(classes_count)\n",
        "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
        "print(class_mapping)\n",
        "\n",
        "# Save the configuration\n",
        "with open(config_output_filename, 'wb') as config_f:\n",
        "\tpickle.dump(C,config_f)\n",
        "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images per class:\n",
            "{'Ascaris': 68,\n",
            " 'Echinostoma': 53,\n",
            " 'Hookworm': 87,\n",
            " 'Mif': 52,\n",
            " 'Ov': 110,\n",
            " 'Taenia': 146,\n",
            " 'bg': 0}\n",
            "Num classes (including bg) = 7\n",
            "{'Echinostoma': 0, 'Ov': 1, 'Taenia': 2, 'Hookworm': 3, 'Ascaris': 4, 'Mif': 5, 'bg': 6}\n",
            "Config has been written to /content/drive/My Drive/Parasite/New/Newlabel/model_vgg_config.pickle, and can be loaded when testing to ensure correct results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkiGQA3Ui8F2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54007169-ea52-4ca4-b5c3-03840b2d7635"
      },
      "source": [
        "# Shuffle the images with seed\n",
        "random.seed(1)\n",
        "random.shuffle(train_imgs)\n",
        "\n",
        "print('Num train samples (images) {}'.format(len(train_imgs)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num train samples (images) 455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhX570d9NoHp"
      },
      "source": [
        "# Get train data generator which generate X, Y, image_data\n",
        "data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUlAcyK-NyK2"
      },
      "source": [
        "X, Y, image_data, debug_img, debug_num_pos = next(data_gen_train)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfs57GZPOB_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "fe7a5645-ae70-41ff-a7cc-e82f70bf2c44"
      },
      "source": [
        "print('Original image: height=%d width=%d'%(image_data['height'], image_data['width']))\n",
        "print('Resized image:  height=%d width=%d C.im_size=%d'%(X.shape[1], X.shape[2], C.im_size))\n",
        "print('Feature map size: height=%d width=%d C.rpn_stride=%d'%(Y[0].shape[1], Y[0].shape[2], C.rpn_stride))\n",
        "print(X.shape)\n",
        "print(str(len(Y))+\" includes 'y_rpn_cls' and 'y_rpn_regr'\")\n",
        "print('Shape of y_rpn_cls {}'.format(Y[0].shape))\n",
        "print('Shape of y_rpn_regr {}'.format(Y[1].shape))\n",
        "print(image_data)\n",
        "\n",
        "print('Number of positive anchors for this image: %d' % (debug_num_pos))\n",
        "if debug_num_pos==0:\n",
        "    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[1]/image_data['width']), image_data['bboxes'][0]['x2']*(X.shape[1]/image_data['width'])\n",
        "    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['y2']*(X.shape[2]/image_data['height'])\n",
        "    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n",
        "\n",
        "    img = debug_img.copy()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    color = (0, 255, 0)\n",
        "    cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n",
        "    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n",
        "    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n",
        "\n",
        "    plt.grid()\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "else:\n",
        "    cls = Y[0][0]\n",
        "    pos_cls = np.where(cls==1)\n",
        "    print(pos_cls)\n",
        "    regr = Y[1][0]\n",
        "    pos_regr = np.where(regr==1)\n",
        "    print(pos_regr)\n",
        "    print('y_rpn_cls for possible pos anchor: {}'.format(cls[pos_cls[0][0],pos_cls[1][0],:]))\n",
        "    print('y_rpn_regr for positive anchor: {}'.format(regr[pos_regr[0][0],pos_regr[1][0],:]))\n",
        "\n",
        "    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[1]/image_data['width']), image_data['bboxes'][0]['x2']*(X.shape[1]/image_data['width'])\n",
        "    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['y2']*(X.shape[2]/image_data['height'])\n",
        "    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n",
        "\n",
        "    img = debug_img.copy()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    color = (0, 255, 0)\n",
        "    #   cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n",
        "    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n",
        "    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n",
        "\n",
        "    # Add text\n",
        "    textLabel = 'gt bbox'\n",
        "    (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,0.5,1)\n",
        "    textOrg = (gt_x1, gt_y1+5)\n",
        "    cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n",
        "    cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
        "    cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1)\n",
        "\n",
        "    # Draw positive anchors according to the y_rpn_regr\n",
        "    for i in range(debug_num_pos):\n",
        "\n",
        "        color = (100+i*(155/4), 0, 100+i*(155/4))\n",
        "\n",
        "        idx = pos_regr[2][i*4]/4\n",
        "        anchor_size = C.anchor_box_scales[int(idx/3)]\n",
        "        anchor_ratio = C.anchor_box_ratios[2-int((idx+1)%3)]\n",
        "\n",
        "        center = (pos_regr[1][i*4]*C.rpn_stride, pos_regr[0][i*4]*C.rpn_stride)\n",
        "        print('Center position of positive anchor: ', center)\n",
        "        cv2.circle(img, center, 3, color, -1)\n",
        "        anc_w, anc_h = anchor_size*anchor_ratio[0], anchor_size*anchor_ratio[1]\n",
        "        cv2.rectangle(img, (center[0]-int(anc_w/2), center[1]-int(anc_h/2)), (center[0]+int(anc_w/2), center[1]+int(anc_h/2)), color, 2)\n",
        "#         cv2.putText(img, 'pos anchor bbox '+str(i+1), (center[0]-int(anc_w/2), center[1]-int(anc_h/2)-5), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
        "\n",
        "print('Green bboxes is ground-truth bbox. Others are positive anchors')\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.grid()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image: height=6000 width=8000\n",
            "Resized image:  height=300 width=400 C.im_size=300\n",
            "Feature map size: height=18 width=25 C.rpn_stride=16\n",
            "(1, 300, 400, 3)\n",
            "2 includes 'y_rpn_cls' and 'y_rpn_regr'\n",
            "Shape of y_rpn_cls (1, 18, 25, 18)\n",
            "Shape of y_rpn_regr (1, 18, 25, 72)\n",
            "{'filepath': '/content/drive/My Drive/Parasite/New/Newlabel/Train/IMG_20190722_154305.jpg', 'width': 8000, 'height': 6000, 'bboxes': [{'class': 'Taenia', 'x1': 3245, 'x2': 3909, 'y1': 3278, 'y2': 3860}]}\n",
            "Number of positive anchors for this image: 1\n",
            "(array([ 4, 11, 11]), array([ 3, 11, 11]), array([ 4,  6, 15]))\n",
            "(array([11, 11, 11, 11]), array([11, 11, 11, 11]), array([24, 25, 26, 27]))\n",
            "y_rpn_cls for possible pos anchor: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "y_rpn_regr for positive anchor: [ 0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  1.          1.          1.          1.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            " -0.64375001 -0.69375002  0.1472559  -0.37999091  0.          0.\n",
            "  0.          0.          0.          0.          0.          0.        ]\n",
            "Center position of positive anchor:  (176, 176)\n",
            "Green bboxes is ground-truth bbox. Others are positive anchors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxXfY_rwOH3i"
      },
      "source": [
        "input_shape_img = (None, None, 3)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(None, 4))\n",
        "\n",
        "# define the base network (VGG here, can be Resnet50, Inception, etc)\n",
        "shared_layers = nn_base(img_input, trainable=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf77KDXg8l7Y"
      },
      "source": [
        "from keras.utils import data_utils"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQibNWK68sJm"
      },
      "source": [
        "WEIGHTS_PATH = ('https://storage.googleapis.com/tensorflow/keras-applications/'\n",
        "                'vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cVv4N488LN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183fec83-8d20-4c70-9f3b-61a0122e741c"
      },
      "source": [
        "C.model_path = data_utils.get_file(\n",
        "          'vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "          WEIGHTS_PATH,\n",
        "          cache_subdir='models',\n",
        "          file_hash='64373286793e3c8b2b4e3219cbf3544b')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "553476096/553467096 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmcdTTzOM2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5211f75-893a-47d7-a262-b6ed70c5031d"
      },
      "source": [
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) # 9\n",
        "rpn = rpn_layer(shared_layers, num_anchors)\n",
        "\n",
        "classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))\n",
        "\n",
        "model_rpn = Model(img_input, rpn[:2])\n",
        "model_classifier = Model([img_input, roi_input], classifier)\n",
        "\n",
        "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
        "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
        "\n",
        "# Because the google colab can only run the session several hours one time (then you need to connect again), \n",
        "# we need to save the model and load the model to continue training\n",
        "\n",
        "# If this is a continued training, load the trained model from before\n",
        "print('Continue training based on previous trained model')\n",
        "print('Loading weights from {}'.format(C.model_path))\n",
        "model_rpn.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "    \n",
        "# Load the records\n",
        "record_df = pd.read_csv(record_path)\n",
        "\n",
        "r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
        "r_class_acc = record_df['class_acc']\n",
        "r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
        "r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
        "r_loss_class_cls = record_df['loss_class_cls']\n",
        "r_loss_class_regr = record_df['loss_class_regr']\n",
        "r_curr_loss = record_df['curr_loss']\n",
        "r_elapsed_time = record_df['elapsed_time']\n",
        "r_mAP = record_df['mAP']\n",
        "\n",
        "print('Already train %dK batches'% (len(record_df)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continue training based on previous trained model\n",
            "Loading weights from /root/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "Already train 144K batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2CUroB75lYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "cab06087-db3b-49c3-f00c-c4ba068256be"
      },
      "source": [
        "record_df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_overlapping_bboxes</th>\n",
              "      <th>class_acc</th>\n",
              "      <th>loss_rpn_cls</th>\n",
              "      <th>loss_rpn_regr</th>\n",
              "      <th>loss_class_cls</th>\n",
              "      <th>loss_class_regr</th>\n",
              "      <th>curr_loss</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>mAP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.844</td>\n",
              "      <td>0.651</td>\n",
              "      <td>1.281</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0.058</td>\n",
              "      <td>2.227</td>\n",
              "      <td>112.049</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.025</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.532</td>\n",
              "      <td>0.057</td>\n",
              "      <td>1.205</td>\n",
              "      <td>115.333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.697</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.051</td>\n",
              "      <td>1.028</td>\n",
              "      <td>112.334</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30.348</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.926</td>\n",
              "      <td>114.271</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.266</td>\n",
              "      <td>0.834</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.395</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.862</td>\n",
              "      <td>113.325</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_overlapping_bboxes  class_acc  ...  elapsed_time  mAP\n",
              "0                   28.844      0.651  ...       112.049  0.0\n",
              "1                   31.025      0.780  ...       115.333  0.0\n",
              "2                   30.697      0.804  ...       112.334  0.0\n",
              "3                   30.348      0.825  ...       114.271  0.0\n",
              "4                   30.266      0.834  ...       113.325  0.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tn9LmqyT-sJ"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b8mWHe2OgfR"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "optimizer_classifier = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
        "model_all.compile(optimizer='sgd', loss='mae')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RftDxilRSZcP"
      },
      "source": [
        "# Training setting\n",
        "total_epochs = len(record_df)\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "epoch_length = 6\n",
        "num_epochs = 5\n",
        "iter_num = 0\n",
        "\n",
        "total_epochs += num_epochs\n",
        "\n",
        "losses = np.zeros((epoch_length, 5))\n",
        "rpn_accuracy_rpn_monitor = []\n",
        "rpn_accuracy_for_epoch = []\n",
        "\n",
        "if len(record_df)==0:\n",
        "    best_loss = np.Inf\n",
        "else:\n",
        "    best_loss = np.min(r_curr_loss)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8MrHYrdSijd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ab0756-f789-4305-e7d5-0ad6f0b40154"
      },
      "source": [
        "print(len(record_df))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_EMW1eBpSeY"
      },
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOLDMybkiAB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e295b5c-8e15-46bb-b721-60cfb3dc6f9b"
      },
      "source": [
        "print(rpn_accuracy_rpn_monitor)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1O4XWxbUUuw",
        "outputId": "a6d7a827-95d9-4c48-ef62-489288ea23f3"
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 145/149\n",
            "2/6 [=========>....................] - ETA: 1:02 - rpn_cls: 0.4390 - rpn_regr: 0.0144 - final_cls: 1.9304 - final_regr: 0.6545Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f5af36aea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/6 [==============>...............] - ETA: 1:03 - rpn_cls: 1.0826 - rpn_regr: 0.0171 - final_cls: 1.8965 - final_regr: 0.5823Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 52s - rpn_cls: 1.2563 - rpn_regr: 0.0533 - final_cls: 1.8742 - final_regr: 0.5189 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 202s 35s/step - rpn_cls: 1.7588 - rpn_regr: 0.1078 - final_cls: 1.8238 - final_regr: 0.4264\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.3684210526315789\n",
            "Classifier accuracy for bounding boxes from RPN: 0.5416666666666666\n",
            "Loss RPN classifier: 3.5307988405111246\n",
            "Loss RPN regression: 0.2869034898467362\n",
            "Loss Detector classifier: 1.703989863395691\n",
            "Loss Detector regression: 0.21962377340726866\n",
            "Total loss: 5.74131596716082\n",
            "Elapsed time: 201.86034035682678\n",
            "Epoch 146/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 2:08 - rpn_cls: 0.0420 - rpn_regr: 0.1926 - final_cls: 1.0841 - final_regr: 0.0051Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 4:00 - rpn_cls: 1.6167 - rpn_regr: 0.1758 - final_cls: 1.1677 - final_regr: 0.0038Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 1:11 - rpn_cls: 1.9235 - rpn_regr: 0.1912 - final_cls: 1.2662 - final_regr: 0.0833Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 33s - rpn_cls: 2.1056 - rpn_regr: 0.1978 - final_cls: 1.2488 - final_regr: 0.0894 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 185s 32s/step - rpn_cls: 2.3263 - rpn_regr: 0.2026 - final_cls: 1.2332 - final_regr: 0.0927\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.4117647058823529\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 3.430293674891194\n",
            "Loss RPN regression: 0.22697583958506584\n",
            "Loss Detector classifier: 1.1555266578992207\n",
            "Loss Detector regression: 0.10889608894164364\n",
            "Total loss: 4.921692261317125\n",
            "Elapsed time: 184.94653701782227\n",
            "Epoch 147/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 54s - rpn_cls: 5.9108 - rpn_regr: 0.1557 - final_cls: 1.2560 - final_regr: 0.2550 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 124s 18s/step - rpn_cls: 3.6111 - rpn_regr: 0.1428 - final_cls: 1.2736 - final_regr: 0.3163\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.7272727272727273\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 2.383630736493861\n",
            "Loss RPN regression: 0.14258028691013655\n",
            "Loss Detector classifier: 1.1751083234945934\n",
            "Loss Detector regression: 0.2469572170327107\n",
            "Total loss: 3.948276563931302\n",
            "Elapsed time: 124.09492921829224\n",
            "Epoch 148/149\n",
            "1/6 [====>.........................] - ETA: 1:25 - rpn_cls: 11.0165 - rpn_regr: 0.2509 - final_cls: 0.9418 - final_regr: 0.0347Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:10 - rpn_cls: 9.0165 - rpn_regr: 0.2022 - final_cls: 1.0099 - final_regr: 0.2763Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 27s - rpn_cls: 7.5016 - rpn_regr: 0.1795 - final_cls: 1.0096 - final_regr: 0.3564 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 180s 33s/step - rpn_cls: 7.0860 - rpn_regr: 0.1800 - final_cls: 1.0070 - final_regr: 0.3613\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.5294117647058824\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 5.0079188247521715\n",
            "Loss RPN regression: 0.1824907964716355\n",
            "Loss Detector classifier: 0.9936744372049967\n",
            "Loss Detector regression: 0.38631249964237213\n",
            "Total loss: 6.5703965580711765\n",
            "Elapsed time: 180.5191605091095\n",
            "Epoch 149/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 38s - rpn_cls: 5.6214 - rpn_regr: 0.5575 - final_cls: 1.2900 - final_regr: 0.0423Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 29s - rpn_cls: 5.4304 - rpn_regr: 0.5433 - final_cls: 1.3119 - final_regr: 0.0613Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 178s 28s/step - rpn_cls: 5.1735 - rpn_regr: 0.5241 - final_cls: 1.3078 - final_regr: 0.0705\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.4375\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 3.8886796588651773\n",
            "Loss RPN regression: 0.4283622360477845\n",
            "Loss Detector classifier: 1.28700057665507\n",
            "Loss Detector regression: 0.11634414309325318\n",
            "Total loss: 5.720386614661286\n",
            "Elapsed time: 178.42108464241028\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9fYNxQUtwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854d80be-a863-4b58-86e0-06a9cfb429c9"
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 150/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 1:46 - rpn_cls: 9.8973e-07 - rpn_regr: 0.2028 - final_cls: 1.0977 - final_regr: 0.0000e+00Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:34 - rpn_cls: 1.5306 - rpn_regr: 0.1687 - final_cls: 1.0073 - final_regr: 6.8864e-04    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "3/6 [==============>...............] - ETA: 2:09 - rpn_cls: 2.4052 - rpn_regr: 0.2084 - final_cls: 0.9908 - final_regr: 7.6515e-04Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 46s - rpn_cls: 2.5648 - rpn_regr: 0.2146 - final_cls: 0.9690 - final_regr: 0.0016 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 246s 45s/step - rpn_cls: 2.4835 - rpn_regr: 0.2114 - final_cls: 0.9760 - final_regr: 0.0017\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.24\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 2.0771823660020683\n",
            "Loss RPN regression: 0.1956972082455953\n",
            "Loss Detector classifier: 1.0109775861104329\n",
            "Loss Detector regression: 0.0022751912862683334\n",
            "Total loss: 3.286132351644365\n",
            "Elapsed time: 246.34316635131836\n",
            "Epoch 151/149\n",
            "2/6 [=========>....................] - ETA: 58s - rpn_cls: 5.7784 - rpn_regr: 0.0771 - final_cls: 0.9894 - final_regr: 0.4954 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 58s - rpn_cls: 5.2134 - rpn_regr: 0.1030 - final_cls: 0.9894 - final_regr: 0.4714Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 109s 19s/step - rpn_cls: 4.8233 - rpn_regr: 0.1571 - final_cls: 0.9818 - final_regr: 0.4271\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.25\n",
            "Classifier accuracy for bounding boxes from RPN: 0.5833333333333334\n",
            "Loss RPN classifier: 5.236278756950014\n",
            "Loss RPN regression: 0.23969543601075807\n",
            "Loss Detector classifier: 1.0151443183422089\n",
            "Loss Detector regression: 0.4381152669908867\n",
            "Total loss: 6.929233778293868\n",
            "Elapsed time: 108.56322479248047\n",
            "Epoch 152/149\n",
            "3/6 [==============>...............] - ETA: 39s - rpn_cls: 6.8180 - rpn_regr: 0.1519 - final_cls: 0.7101 - final_regr: 0.0049Exception: 'a' cannot be empty unless no samples are taken\n",
            "4/6 [===================>..........] - ETA: 30s - rpn_cls: 6.5700 - rpn_regr: 0.1604 - final_cls: 0.7135 - final_regr: 0.0049Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 27s - rpn_cls: 6.6983 - rpn_regr: 0.1664 - final_cls: 0.7425 - final_regr: 0.0047Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "6/6 [==============================] - 181s 34s/step - rpn_cls: 6.5837 - rpn_regr: 0.1692 - final_cls: 0.7611 - final_regr: 0.0047\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.35\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 6.011121701914817\n",
            "Loss RPN regression: 0.18314866349101067\n",
            "Loss Detector classifier: 0.8537247677644094\n",
            "Loss Detector regression: 0.005089781751545767\n",
            "Total loss: 7.053084914921783\n",
            "Elapsed time: 181.0307297706604\n",
            "Epoch 153/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: 'a' cannot be empty unless no samples are taken\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 37s - rpn_cls: 9.0949 - rpn_regr: 0.2981 - final_cls: 1.5315 - final_regr: 0.0460Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 20s - rpn_cls: 8.7913 - rpn_regr: 0.3058 - final_cls: 1.4631 - final_regr: 0.0649Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 173s 22s/step - rpn_cls: 8.3785 - rpn_regr: 0.3080 - final_cls: 1.4023 - final_regr: 0.0741\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.4375\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 6.314241771200652\n",
            "Loss RPN regression: 0.31873920063177746\n",
            "Loss Detector classifier: 1.0982836385567982\n",
            "Loss Detector regression: 0.12027592460314433\n",
            "Total loss: 7.851540534992372\n",
            "Elapsed time: 173.35902953147888\n",
            "Epoch 154/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 1:43 - rpn_cls: 0.7172 - rpn_regr: 0.1665 - final_cls: 0.7703 - final_regr: 0.0287Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:31 - rpn_cls: 2.0553 - rpn_regr: 0.1822 - final_cls: 0.7928 - final_regr: 0.1905Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 24s - rpn_cls: 2.4452 - rpn_regr: 0.1836 - final_cls: 0.8080 - final_regr: 0.2124Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 296s 55s/step - rpn_cls: 2.3990 - rpn_regr: 0.1836 - final_cls: 0.8380 - final_regr: 0.2323\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.23529411764705882\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 2.167800282092817\n",
            "Loss RPN regression: 0.18362699945767721\n",
            "Loss Detector classifier: 0.9884333113829294\n",
            "Loss Detector regression: 0.33190595828151953\n",
            "Total loss: 3.671766551214943\n",
            "Elapsed time: 296.24114084243774\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nujhdfLVUzbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a865145-9e73-4dbd-ab55-1b24e5824f0b"
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 155/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 3:51 - rpn_cls: 0.0018 - rpn_regr: 0.1782 - final_cls: 1.1958 - final_regr: 0.0000e+00Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 2:35 - rpn_cls: 0.0013 - rpn_regr: 0.1669 - final_cls: 1.0880 - final_regr: 5.8746e-04Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 2:09 - rpn_cls: 1.4169 - rpn_regr: 0.1682 - final_cls: 1.0740 - final_regr: 6.5273e-04Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 1:38 - rpn_cls: 2.2554 - rpn_regr: 0.1921 - final_cls: 1.1241 - final_regr: 0.0340    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 44s - rpn_cls: 2.8213 - rpn_regr: 0.2102 - final_cls: 1.1905 - final_regr: 0.0690 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 261s 43s/step - rpn_cls: 3.1260 - rpn_regr: 0.2334 - final_cls: 1.2521 - final_regr: 0.0865\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.44\n",
            "Classifier accuracy for bounding boxes from RPN: 0.625\n",
            "Loss RPN classifier: 4.649077854158578\n",
            "Loss RPN regression: 0.34948871781428653\n",
            "Loss Detector classifier: 1.560242881377538\n",
            "Loss Detector regression: 0.174281831481494\n",
            "Total loss: 6.733091284831896\n",
            "Elapsed time: 261.3321011066437\n",
            "Epoch 156/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 5:46 - rpn_cls: 1.7510e-05 - rpn_regr: 0.2539 - final_cls: 0.5554 - final_regr: 0.0037Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 2:39 - rpn_cls: 2.4739 - rpn_regr: 0.2657 - final_cls: 0.6719 - final_regr: 0.0773Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 1:36 - rpn_cls: 2.8492 - rpn_regr: 0.2540 - final_cls: 0.7524 - final_regr: 0.1323Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 47s - rpn_cls: 2.9155 - rpn_regr: 0.2540 - final_cls: 0.8352 - final_regr: 0.1534 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 351s 56s/step - rpn_cls: 2.8713 - rpn_regr: 0.2511 - final_cls: 0.8832 - final_regr: 0.1609\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.175\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 2.6502517655242364\n",
            "Loss RPN regression: 0.23625730474789938\n",
            "Loss Detector classifier: 1.123313268025716\n",
            "Loss Detector regression: 0.19823281997620748\n",
            "Total loss: 4.2080551582740595\n",
            "Elapsed time: 350.7705490589142\n",
            "Epoch 157/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 3:07 - rpn_cls: 7.0017 - rpn_regr: 0.1118 - final_cls: 0.8102 - final_regr: 0.0305Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:30 - rpn_cls: 6.1264 - rpn_regr: 0.1323 - final_cls: 0.7344 - final_regr: 0.0212Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 1:13 - rpn_cls: 5.8712 - rpn_regr: 0.1432 - final_cls: 0.7210 - final_regr: 0.0192Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 37s - rpn_cls: 5.5139 - rpn_regr: 0.1457 - final_cls: 0.7085 - final_regr: 0.0175 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 213s 35s/step - rpn_cls: 5.1622 - rpn_regr: 0.1503 - final_cls: 0.7138 - final_regr: 0.0163\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.3\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 3.403815766242399\n",
            "Loss RPN regression: 0.17343588545918465\n",
            "Loss Detector classifier: 0.7403826912244161\n",
            "Loss Detector regression: 0.010576090639612326\n",
            "Total loss: 4.328210433565612\n",
            "Elapsed time: 212.52821326255798\n",
            "Epoch 158/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 6:03 - rpn_cls: 6.0841e-04 - rpn_regr: 0.3022 - final_cls: 0.9122 - final_regr: 0.0000e+00Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:26 - rpn_cls: 0.0828 - rpn_regr: 0.2882 - final_cls: 0.8604 - final_regr: 0.0011        Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 53s - rpn_cls: 0.1257 - rpn_regr: 0.2740 - final_cls: 0.8570 - final_regr: 0.0013 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 36s - rpn_cls: 0.1412 - rpn_regr: 0.2695 - final_cls: 0.8688 - final_regr: 0.0013Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 245s 34s/step - rpn_cls: 0.1459 - rpn_regr: 0.2619 - final_cls: 0.8684 - final_regr: 0.0013\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.24\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 0.1694609118172797\n",
            "Loss RPN regression: 0.22379802291591963\n",
            "Loss Detector classifier: 0.8669442236423492\n",
            "Loss Detector regression: 0.00143231893889606\n",
            "Total loss: 1.2616354773144447\n",
            "Elapsed time: 244.6205871105194\n",
            "Epoch 159/149\n",
            "1/6 [====>.........................] - ETA: 1:50 - rpn_cls: 6.4137 - rpn_regr: 0.1986 - final_cls: 0.5654 - final_regr: 0.0023Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:49 - rpn_cls: 6.4137 - rpn_regr: 0.1582 - final_cls: 0.6241 - final_regr: 0.0030Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:41 - rpn_cls: 5.7011 - rpn_regr: 0.1420 - final_cls: 0.7085 - final_regr: 0.0757Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 154s 26s/step - rpn_cls: 4.3471 - rpn_regr: 0.1574 - final_cls: 0.8037 - final_regr: 0.1218\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.7272727272727273\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 3.206825335820549\n",
            "Loss RPN regression: 0.17754199107487997\n",
            "Loss Detector classifier: 0.903117428223292\n",
            "Loss Detector regression: 0.15343443428476652\n",
            "Total loss: 4.440919189403488\n",
            "Elapsed time: 154.3916335105896\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOSpIJMU01y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa3a5ac-ef37-4b58-a3d3-ffb1da5f1231"
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(C.model_path)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 160/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:03 - rpn_cls: 1.6034 - rpn_regr: 0.0784 - final_cls: 1.5781 - final_regr: 0.6401    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 39s - rpn_cls: 2.1333 - rpn_regr: 0.0929 - final_cls: 1.3441 - final_regr: 0.5081 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 26s - rpn_cls: 2.4734 - rpn_regr: 0.0975 - final_cls: 1.2661 - final_regr: 0.4586Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 177s 27s/step - rpn_cls: 2.7697 - rpn_regr: 0.1060 - final_cls: 1.2057 - final_regr: 0.4185\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.5\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 4.251439514080232\n",
            "Loss RPN regression: 0.14816677321990332\n",
            "Loss Detector classifier: 0.9038642346858978\n",
            "Loss Detector regression: 0.2178161417687079\n",
            "Total loss: 5.521286663754741\n",
            "Elapsed time: 177.16753125190735\n",
            "Epoch 161/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 3:09 - rpn_cls: 2.2893e-05 - rpn_regr: 0.0455 - final_cls: 1.0558 - final_regr: 0.0036Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 2:57 - rpn_cls: 1.5633e-04 - rpn_regr: 0.1042 - final_cls: 0.8980 - final_regr: 0.0057Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 2:04 - rpn_cls: 0.5878 - rpn_regr: 0.1079 - final_cls: 0.9044 - final_regr: 0.0774    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 2:05 - rpn_cls: 1.1678 - rpn_regr: 0.1121 - final_cls: 0.8809 - final_regr: 0.1428Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: 'a' cannot be empty unless no samples are taken\n",
            "5/6 [========================>.....] - ETA: 54s - rpn_cls: 1.4017 - rpn_regr: 0.1125 - final_cls: 0.8599 - final_regr: 0.1693 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 334s 59s/step - rpn_cls: 1.6709 - rpn_regr: 0.1176 - final_cls: 0.8393 - final_regr: 0.1795\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.21621621621621623\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 3.0167528349499357\n",
            "Loss RPN regression: 0.1426913213605682\n",
            "Loss Detector classifier: 0.7360923886299133\n",
            "Loss Detector regression: 0.23051258840132505\n",
            "Total loss: 4.126049133341742\n",
            "Elapsed time: 333.53868079185486\n",
            "Epoch 162/149\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 2:07 - rpn_cls: 2.0205e-13 - rpn_regr: 0.2260 - final_cls: 1.0423 - final_regr: 0.0000e+00Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 48s - rpn_cls: 0.0023 - rpn_regr: 0.1577 - final_cls: 0.8107 - final_regr: 0.0026     Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 28s - rpn_cls: 0.0032 - rpn_regr: 0.1507 - final_cls: 0.7879 - final_regr: 0.0033Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 193s 33s/step - rpn_cls: 0.0037 - rpn_regr: 0.1482 - final_cls: 0.7923 - final_regr: 0.0045\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.35294117647058826\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 0.00600202792781828\n",
            "Loss RPN regression: 0.13590005909403166\n",
            "Loss Detector classifier: 0.8141989558935165\n",
            "Loss Detector regression: 0.010211839883898696\n",
            "Total loss: 0.9663128827992652\n",
            "Elapsed time: 192.94624042510986\n",
            "Epoch 163/149\n",
            "1/6 [====>.........................] - ETA: 1:15 - rpn_cls: 4.3561e-17 - rpn_regr: 0.0849 - final_cls: 0.5452 - final_regr: 0.0059Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: 'a' cannot be empty unless no samples are taken\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:46 - rpn_cls: 0.7126 - rpn_regr: 0.1023 - final_cls: 0.5310 - final_regr: 0.0091    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 29s - rpn_cls: 1.8353 - rpn_regr: 0.1163 - final_cls: 0.6863 - final_regr: 0.0093 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 192s 35s/step - rpn_cls: 2.0638 - rpn_regr: 0.1197 - final_cls: 0.7141 - final_regr: 0.0091\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.3888888888888889\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 3.206234843799399\n",
            "Loss RPN regression: 0.13699851805965105\n",
            "Loss Detector classifier: 0.852815051873525\n",
            "Loss Detector regression: 0.008188535265314082\n",
            "Total loss: 4.204236948997889\n",
            "Elapsed time: 191.89727401733398\n",
            "Epoch 164/149\n",
            "1/6 [====>.........................] - ETA: 1:26 - rpn_cls: 8.7044e-10 - rpn_regr: 0.1807 - final_cls: 0.3528 - final_regr: 0.0127Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:47 - rpn_cls: 6.5283e-10 - rpn_regr: 0.1364 - final_cls: 0.4281 - final_regr: 0.0108Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 30s - rpn_cls: 1.8573 - rpn_regr: 0.1167 - final_cls: 0.6386 - final_regr: 0.0092 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 259s 48s/step - rpn_cls: 2.1150 - rpn_regr: 0.1184 - final_cls: 0.6732 - final_regr: 0.0088\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.46153846153846156\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 3.403847177968459\n",
            "Loss RPN regression: 0.12682887096889317\n",
            "Loss Detector classifier: 0.8459905634323756\n",
            "Loss Detector regression: 0.007036773031965519\n",
            "Total loss: 4.383703385401693\n",
            "Elapsed time: 259.0629782676697\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE1qTtYeU7CH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "652f7bc4-3602-4fe3-de26-0f7d4e7de54c"
      },
      "source": [
        "r_epochs=164\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
        "plt.title('mean_overlapping_bboxes')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
        "plt.title('class_acc')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
        "plt.title('loss_rpn_cls')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
        "plt.title('loss_rpn_regr')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "plt.title('loss_class_cls')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
        "plt.title('loss_class_regr')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "plt.title('total_loss')\n",
        "plt.show()\n",
        "\n",
        "# plt.figure(figsize=(15,5))\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "# plt.title('total_loss')\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['elapsed_time'], 'r')\n",
        "# plt.title('elapsed_time')\n",
        "# plt.show()\n",
        "\n",
        "# plt.title('loss')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'b')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'g')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'c')\n",
        "# # plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'm')\n",
        "# plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAE/CAYAAADCCbvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hU5fUH8O9hd+lLkyIsIIIoYmwRsZLYC7bYJZZorIkmsWES9WdLTIwNG/YaK2rsYi9Ro6KggAISEER2qQKyC+yy7fz+OPNm7s7emb0zO+XOzvfzPPvMzsydmXcG3Tvfe973XFFVEBERERERUW61y/UAiIiIiIiIiOGMiIiIiIgoFBjOiIiIiIiIQoDhjIiIiIiIKAQYzoiIiIiIiEKA4YyIiIiIiCgEGM6IkiAi34nIfll4nddE5FcZfP4hIqIiUhzn/qtE5LFMvT4RERERNcdwRhRCqnqwqj6S63EQEREBgIicKiIf5XocRG0dwxlRAPEqTERERERE6cJwRoFEpvONF5GZIrJeRB4QkX6R6XdVIvK2iPSMbLuriHwsIj+KyAwR2cvzPKeJyJzIYxaIyNme+/YSkXIRuUhEVojIUhE5LcDYuovIP0VkpYgsEpHLRaSdiHSIjOEnnm37iEi1iPSNXD9URKZHtvtYRLaLec9/FJGZANbHBjQRGS0in0Qeu1RE7hCR9p77VUR+H3mfP4jIDSLSLnLfqSLyn8hj1orINyKyr+ex74vIGZ5tPxKRG0VkjYgsFJGDPdtuLiIfeP4dJiYxJfHXIrIkMv6LY+7rKCKTIs/7hYhs73nNrSNj/FFEZonI4ZHbd4+810GR69tHxjwiwOf9RxGpiLzeXO/nQURERFQIGM4oGUcD2B/AlgAOA/AagEsB9IH9t/R7ESkD8CqAvwLoBeBiAP8SkT6R51gB4FAA3QCcBmCCiPzU8xqbAugOoAzA6QAmutCXwO2RxwwF8HMApwA4TVU3AngOwDjPtscB+LeqrhCRHQE8COBsAJsAuAfASyLSwbP9OACHAOihqvUxr9sA4AIAvQHsBmBfAL+N2eZIAKMA/BTAEQB+7blvFwDfRh5/JYDnRKRXnPe4C4C5kW2vB/CAiEjkvicAfBZ5D1cBODnOc/jZG8BwAAcA+KM0XU93BIBnYP+OTwB4QURKRKQEwMsA3gTQF8DvADwuIlup6sewz/EREekE4DEA/6eq3yT6vEVkKwDnAdhZVUsBHAjguyTeBxERpYmIDBKR5yIHPVeJyB0+29wqIotFpFJEponIGM99o0VkauS+5SJyc+T2jiLyWOQ5fxSRz0WkXwtjOU3iHNSN3H9E5KBfpYh8KyIHRW7vJSIPRQ5ArhGRF9Lz6RBlFsMZJeN2VV2uqhUAPgQwRVW/VNUaAM8D2BHASQAmq+pkVW1U1bcATAUwFgBU9VVV/VbNv2Ff8Md4XqMOwDWqWqeqkwGsA7BVvAGJSBGAEwD8WVWrVPU7ADchGlCeiNzv/DJyGwCcBeAeVZ2iqg2RNV4bAezq2f42VV2sqtWxr62q01T1U1Wtj7zuPbBw6PUPVV2tqt8DuAVNg+IKALdE3uskWPg6JM5bXaSq96lqA4BHAPQH0E9EBgPYGcAVqlqrqh8BeCnOc/i5WlXXq+pXAB6KGd80VX1WVesA3AygI+yz2RVAVwDXRV7zXQCveB57FSwsfwagAsDEyO2JPu8GAB0AjBSRElX9TlW/TeJ9EBFRGkT2q68AWARgCOxg6VM+m34OYAdED+A9IyIdI/fdCuBWVe0GYBiApyO3/wq2fxgEO0h3DoBm+9cYcQ/qishoAP8EMB5ADwA/Q/TA3qMAOgPYBnYgcUKAt0+UcwxnlIzlnt+rfa53BbAZgGMjR8R+FJEfAewJCxMQkYNF5FMRWR25byysGuSsiqlQbYg8bzy9AZTAdiLOItjOBADeA9BZRHYRkSGwHcnzkfs2A3BRzFgHARjgea7F8V5YRLYUkVdEZJmIVAL4W8x7iX38opjnrlBVTXC/1zL3i6puiPzaNbL9as9tCcfsI9H4/nefqjYCKI/cPwDA4sht3seWRbatA/AwgJ8AuMnzHuN+3qo6H8D5sGC3QkSeEpF4nwUREWXOaNjf+fGRg3c1kQN/TajqY6q6KnKA8ibYATZ3MLUOwBYi0ltV16nqp57bNwGwReQg3TRVrUw0mBYO6p4O4EFVfStyQLgiMlOjP4CDAZyjqmsiB0H/3crPhSgrGM4o3RYDeFRVe3h+uqjqdZHpgv8CcCOAfqraA8BkAJLoCVvwA+yP/Wae2wbDKjaIVJqehlV1xgF4RVWrPGO9NmasnVX1Sc9zecNTrLsAfANgeOTo4KU+72VQzLiWeK6XeaYm+t0fxFIAvUSkc5zXbEmi8f3vPrG1cgMj9y8BMChym/exFZFty2DTNB8CcJNnmmjCz1tVn1DVPWH/lgrgH0m8DyIiSo9BsNkasVP5mxCRiyPTDddGDrZ1R/QA5emwJRDfRKYuHhq5/VEAbwB4KjLd8PrIVPlEr5PooO4g2PIAv/ewWlXXBHi/RKHCcEbp9hiAw0TkQBEpiswv30tEBgJoDzuythJAvVhTiwNa82Ke8HWtiJSKyGYALoyMw3kCwPEATkR0SiMA3AfgnEhVTUSki4gcIiKlAV++FEAlgHViDS9+47PNeBHpKdYg4w8AJnnu6wtbp1ciIscC2BoWVgNT1UWwaaNXiUh7EdkNth4wqP8Tkc4isg1suoh3fDuJyFFijVDOh01B/BTAFFhF85LI2PeKvOZTkbD5MIAHYDvnpQD+Enm+uJ+3iGwlIvtEglwNrBLrrcwREVF2LAYwWBJ0KY6sL7sEto67Z+Rg61pEDlCq6jxVHQfbz/0DwLMi0iVSwbpaVUcC2B02XfGUBK/T0kHdxbBpk37voZeI9EjifROFAsMZpZWqLoY1krgUFsIWw+aCt4tUrH4PC1NrYOu/klkfFc/vAKwHsADAR7AA9qBnTFMi9w+ANTFxt08FcCaAOyLjmQ/g1CRe92LYe6iCBY9JPtu8CGAagOmwRikPeO6bAmvG8QOAawEco6qrknh950RYQ5JVsEYsk2BBKoh/w973OwBuVNU3Y8Z+POyzORnAUZEday0sjB0cGfudAE5R1W9g/759YU1AFBb4ThORMS183h0AXBd5vmWR5/hzch8DERGlwWewA2vXRQ6idRSRPWK2KQVQD9vPF4vIFbA1YQAAETlJRPpEpr//GLm5UUT2FpFtI+vaKmEzXxIdiGvpoO4DsH3MvmJdmstEZISqLoXt7++MHCAtEZGfpfh5EGWVNF3yQkTpIiIKm/I43+e+UwGcEZnGl+7XnQTgG1W9Mt3PTUREbV+k2dRtsLVdCjvo+QUi+61IuLoPwDGwg58TYN2Kz1DVt8VO53IArCHHIgCXqeoLIjIOtrZ4IKzh1yQAFyaaQiki5wK4AhbSXoatM5+vqpdH7j8SwNUANoethT9XVd8Q6348AcBBsJD3nqoelaaPiChjGM6IMiRb4UxEdgawGsBC2M7wBQC7qeqXrX1uIiIiIsoeTmukvCB2ouN1Pj8n5npsIbApgPdhRyFvA/AbVf1SRE6M85nNyuloiYiIiMgXK2dERERElDMisi7OXQer6odZHQxRjjGcERERERERhQCnNRIREREREYVA3HNYZELv3r11yJAh2XxJIiLKgWnTpv2gqn1yPY58wf0jEVHhSLSPzGo4GzJkCKZOnZrNlyQiohwQkUW5HkM+4f6RiKhwJNpHclojERERERFRCDCcERERERERhQDDGRERERERUQgwnBEREREREYUAwxkREREREVEIMJwRERERERGFAMMZERERERFRCDCcERERERERhQDDGRERERERUQgwnBFR+Lz3HrBxY65HQURE+eCTT4CKilyPgigtGM6IKFwqKoB99gGeeSbXIyEiorBbuhQYMwYYORJ4+GFANdcjImoVhjMiCpe1a+1y5crcjoOIiJKX7XD07LNAQwMwfDhw2mnARRe1/JiaGgty9fUZHx5RshjOiChc3HRGF9KIiCj81q4FDjoI2G03YNky/22mTwf69QP+85+mt6sC++0HlJUBxx4LvP5688f++CPw4IPNA9VTTwHbbQd89hlw9tnAhAnR5//0U+DPf7Yfb1XtuussyE2Z0qq3TJQJDGdEFC41NXbJcEZE5K++PrUKVW0tcMstwMKFwR+zciVw7bVNA1d1ddNtli4Ffv5z4J13gK++AnbfHfjyS3vM+vW2jSpwwQXAihXA5Zc3ffznn9tjN9sM+Phj4IgjgC++aLrNZZcBp59u4cv5/nvb/vjjgXbtgBtvBAYPBs46C3j0UeBnPwNuuAG46SYLYw89BCxZYrcBXNtMocRwRkThwnBGRBTfl19aiDn99Ob3NTQ0DRzffw+MH28BpqoKOOwwC0i//nWwcNfYCJx4ooWpbbYB7roLOOUUoFs3e466OmDuXKuWzZ8PvPqqNXSqqgJ++lOgf3+rlE2ebPe9/z6w8852+cEH0de55x6gSxermM2cCfTta4Grqsrur6gA7r8f6NgRuPJKYMECu/3pp+3y+OPtsmtXG+Ps2TbOXXaxcFldbWuZzzvPxr1hg23PaY0UQgxnRBQu7otFZWVux0FEhWndOuD884GXXrJwkg6qVvk5/nj7efvt1J7n3XetQrVqlVWBXnstOuZbbgGGDQN69gRuu81Czu67WzVpjz2sovTOO8AvfmHh6JVXbFwTJgB/+xvwww/NX+8f/wDeesvC2bBhwG9/Czz3HHDggfb6Bx1kz71hgz3nAQcAo0cD06YBd99tQWmrrYDDDwfOPNPWhb39tgW2a66x1/jxR+DJJ4Ff/tJC3yabAE88YQHslFPsvV1/vf1bvPUWUFxs0xdnzLDtRo2ysTljxwIXXgiceirw5pv2eRQVAY89BpSWAm+8Aey5p23LcEZhpKpZ+9lpp52UiCih559XBVT32y/XI6FWADBVs7h/yfcf7h9D5M477W8QoLrllqp33626YUPrnvP11+35hgxR7d1btXt31SVLknuO775T7dhRdZttVL/9VnXECNXNNlN96SXVwYPt+ffcU/XAA+33du1UBwxQ/eQT1dtvV91jD9WXX1atrbX3tdVWqr/+dfS9dupkjz3kEPsZO1a1qEj1uONUGxtV6+pU33lHdfVqG89dd9lrDB2qOm9e/HFXVtrfc8D+vquq3nSTXZ8wQfX66+33qVObPm7CBFURe/6OHW2sqqp33BEdM2DPFdT776sefrjqW2/ZY198MfhjidIo0T5SNEhZO01GjRqlU6dOzdrrEVEemjQJOOEEm/ry2We5Hg2lSESmqeqoXI8jX3D/GCK77mrrpC67zNYqTZ0K9O5t66B2282qQH36NH1MTQ3wwgs2fXDBAmtQMWaMVZhErLpUUQHMmwcsWgRsu609j5uWB9hrzplj0wc7dWo+rpNOAv71L5tGOHgw8NFH9hqAVafuu8+uq1rzixdesAraZps1f64XX7QKGgD83/9ZNe+WW2zKpNfgwVYh697d/7P66itg4ECrTiVSWwvMmgXsuGP0vR54YLRxx0472ecc64MPbK3Y4sX22QwbZu/vgw+A1auBkhJg//2BDh0Sv36smTOB7be3z/Ooo5J7LFEaJNxHxkttmfjhkUEiatHDD0ePWFPeAitn3D/mwvLlquPGqc6aldrjv/nG/v7ccINdb2xU/fe/VY8+WrVnT7tv4EDVr7+OPmbjxmhlqHNnq2wVFdn1E09UffVV+/2uu6KPufZau+2hh1RralTffdeqYIBqcbHq6NGq55+v+uyzqtXVqp9/bvddemnT8d54o+pllyVf2WtsVB0/XvXBB1P5lNKjsdEqWSedZJWseNavV50/P72vPWuWfZ6TJqX3eYkCSrSPZOWMiMLlnnuAc86xNQnx2jFT6LFylhzuH9PknHPsb8jOOwOffGJrjeK54w5bV/ab31gVq6gIuPRSW2dVXm7NLLwaG601+9FHW6Xs/vuBffcFfvc7W890993WpKO42NZg3XyzVaVKSqzBxbffRis8tbW2NmvGDKB9e7s+fLi9/ty5VoH7/HNrZNGvn1Wu1qyxphvdumXu8ysU//2vVRsff9zWuhFlWaJ9ZHG2B0NElBAbghBRKmbPtql9O+5oweaOO4A//MHuU7WGFPX1NlXx9dctVHXpYk0mttjCuhg+9phNt4sNZoC1at99dwt9Bx4IHHNM9L6//tWaVDidO1sTjbIya+t+5ZVNp961bw98+KE1x/j4Y+syOH68Pc6pq7MmGxMmWOOPe+9lMEuX4sjXXzYEoRBiOCOicHGt9Kur7ctJSUlux0NE4bVqlbVp33prC0Clpdah75RTbM3Y4YcDm29uFZIHHrDHvPaaVaH22svau7/6qgW2c8+1+905sOIZMsROpvzxx7Zmql8/C2B+TjsNOO44C4GxSkuBI4+0Hz9uPdX++1tHwx49gnwiFITbrzCcUQjlZzj75BM74jVpUtP2qUSU/1w4A+xcZ717524sRBRelZXAfvtZUHKuv97+Ztx5pzXl2Gsva7d+wQXW6OPOO23qYVkZ8PzzVqk69lirgn38sVWz4oUlr06dbErjvvu2vK1fMEsWg1l6sXJGIZaf4ezdd+0cGocfbkGtUMr806fbUcIxY2xKBFFb5D2BKsMZhZCIHATgVgBFAO5X1eti7t8MwIMA+gBYDeAkVS3P+kDzWUOD/3oxVQtlDQ3W1fWrryx8FRXZCZd/9zvbbsgQOxny2LF2TqviYpsWuO229v1B1aYpOq6j4h57ZOXtUY4xnFGI5edJqL/7zs4SP3eunbm+oSHXI4qvttb/9k8/Bf7yF1uU6iRqzvL449Zqdr/97ASN553XtMJA1FZ4/7vmujMKGREpAjARwMEARgIYJyIjYza7EcA/VXU7ANcA+Ht2R5nn3nvPGmicfXbTL8+q1k6+Rw/bD771ljXlGDfOpg5efHHTdV077WTVsJ/+FLj2WgtmgAWxdvn59YfShOGMQiw//zotXGjnp7j1VjvD/eWX53pE/pYts7nuhx5qZ7h3Vqyw86VccYV1Cxo+3HY0nToBe+8N/P3vdv4OwHZG990HnHwy8POf23lLjjkGmDjRrldU5Oa95dLatYmDLOW32GmNROEyGsB8VV2gqrUAngJwRMw2IwG8G/n9PZ/7C9trr9n0Q7+/408/DRx0kK0JuvdeOwfVhg1233PPWZXstNOsE+LkycCppyZ+rWHDrFJ2ySVpfxuUxxjOKMTyN5xtvjnw29/akbXrrrPKUjJef91OwPjDD5kZoyrw61/b87/2moWuigq7/Ywz7EvnW29Zy95tt7WjfuecY4t+L70UGDHCTgi533620Hj//S2IHnGEnRDyueesM9Uuu1h73nT78ktb5PzNN+l/7tZ47jk7+efJJ/OPalsVO62RKFzKACz2XC+P3OY1A4A7s+2RAEpFZJMsjC3c1q61/eLYscAf/2gnSAZsv/jGG7afO/54azE/Z44dhHzlFbv+7rs2ZXHHHS20XXABcPDBuX0/lL8YzijEWlxzJiIdAXwAoENk+2dV9UoR2Rx2xHATANMAnBw5iphZDQ02r/y442xqwu23W4A4/XQLFAceaGuyOnYEliyx9raLFwNbbmktcI84ApgyxRb81tRYR7jJkxOfCyXRWFatsukXse6+20LZbbfZ3PfjjwcGDQJGjgRmzbLWuPvtZz+xZsyw865ccIFV1G6/3UKot2vdkUdal6h99rGfDz6wMLVmjU3r6Nq1devS7r3XKnzPPGPnaVG1zlfHHms7R6/GRpueuWCBjXHffTMzZWTSJJvGOmiQhfHqauDJJ7n+rq2pqbH/t1UZzihfXQzgDhE5Fbb/rADQbP69iJwF4CwAGDx4cDbHl1kLF9p+0dsI4/vvrSI2d64dgPz6a2sdP2yY7W9eftna1//979b+vlMnOwA7bJgFOrdfefnl6BdrolS5/4bq6nI7DiI/8c5O7X4ACICukd9LAEwBsCuApwGcELn9bgC/aem5dtppp9afUnvRIjur+z33RG9buVJ17FjV9u3tvo4dVffeW7VzZ7vtJz+x2wDVIUNUe/RQ3XJL1b//3W674orkxlBRofqnP6kOHGiP32wz1d/8RnXDBrt/+XLVTp1UDzxQtaHBbvvmG9Urr1TdeWfV44+P3h5PQ4Pqf/6junp14u2++MLeT3GxjcX9tG+veuutqo2N0W0bG1WnTFFdsCDxc27cqNqrlz3PrrvabR9/HL3ufU5V1RNOaPra226r+sQTqmvXJn4dP59+qjpxompNjV1fvNg+6+23t+ceM0a1slL1llvs+r77qq5Zk/zrpKK+PjuvU+iOPlq1Tx/797399lyPhlIEYKq2sE/Ixx8AuwF4w3P9zwD+nGD7rgDKW3retOwfw+D++1WLimwfctllqq+9pvqvf6mWlal276763nu23apVqoMG2f/nHTqo3nij7Xv8rF5t+9gJE7L2NqiNa2iw//auuirXI6EClWgfmexOqTOALwDsAuAHAMXqs7OK95OWnc/779uw33yz+X3r1qm++qrqH/6gut12quPGqX77rd1XX6/6wguqe+xhAW3hQgsZp55qzzdjRrDXf/tt1d69bedzyCGq112n+otf2HPccott89e/2vU5c1r/foOYPl31wgvtde+808Zx8ME2hrPPth3jhAn2mQA29l//WvX77/2f78UXo0FMRHXFCtVzz42Gr9dei247ebLddt55qh99pProo6ojRkRfZ599VJcsafr8VVWqd92l+tVX0dsaGlT/8Q97DKA6fLjqRRdZwC4uVv35z+2zXrcu+phHHlEtKVEdOdL+PZ3XXlO94ALVZcta97muWWNh8frrLXB26GCfbWw4zaQVK1Tnzcve64XBoYfaARXA/pumvNSGw1kxgAUANgfQHjaFcZuYbXoDaBf5/VoA17T0vHkbzmprbb/77LOqf/yj/u+g2ZFH2v7D7TcGDFCdObPpYz/7TPWXv8zevpLIq1071csvz/UoqEC1OpzB2gVPB7AOwD8iO575nvsHAfi6pedJy87noYds2K35wur9cr1ypQWCSy9N/Jh16+woYLt2qltv3XxnsueeqoMHW/Vs4EDV/fdPfXzpUF+vOn58dMcI2Bfee+5R/f3vLWgMHmxHL2Mdd5wFUFcte+ABu37kkfaYXXaxz7CmRnWLLawK6T3iWV9vR0cvvdTC1QEHWPiqr1e9+WZ7LsBCVV2dPeaMM+y2Y45Rff55C2eAVVESVfreey9aCa2stCDYo4c9tls3C3QrViT32a1fb5+B97PbZRf7NwWsSnvGGRYivAEzVmNj/CPBQTQ0qO6wg2ppacvVTq933okelMhH++2nuttuVu0ePz7Xo6EUtdVwZm8NYwH8F8C3AC6L3HYNgMMjvx8DYF5km/sBdGjpOfMynH39tepOOzX9W3niidG/e4sW2X7k44+zN8OBKKj27W1mDlEOpLNy1gPWeWrPoOEMNp9+KoCpgwcPbv27ueIKOxrXmi+9sfbZR3WrreJXRJ5/3qZkAKonn2yVn1gvvxwNE4BV6cLgq69Uv/zSpmJ639+UKVZ1OuywprevXWtfis8918JBv37R9/7SSxbuAKtOHnOM/f7GG/Ff/+67bZu//MUqjYCFnGuvtd8nTrTPClC9+OLoWGpq4lf2Yr3/voXm44+399Oxox3JHTvWnre42CqJt96q+u9/WzXmwANV77vPXm/OHNXdd1cdNcoqjKNG2X9jl1xiVURXlWtstKk3nTrZ59Kxo72en4YG1SOOsCDvprt6rV/f8vt64gn9XwVyzBg7Qn3ZZapDh9oRZz/z5tn2ffqozpoV6OMLnTFjbFpy376qZ52V69FQitpyOMvET16Fs/p6m1HQvr0dbHvsMauKzZ2b3ZkFRK3RubN97yDKgbSFM3suXAFgfM6mNZ58slWm0mniRPsovv7ari9ZYl+EVVXfesu+7O64o03bi6ehwSpBgFWX8mF90q232nhvuCF629VX220ff2zX3bTPXr0sEG/caEEWsABz9tmJX6Ox0QKMC0kTJ9ptjY2qe+2luskmFnS23751gftvf9P/Hbm9+ebo7TNn2lSboUOj9wPRtQ4/+5lqly4WZnbc0W7r0sWCaKL35P2s/KbEuvWMLph6PfmkBeNHHon/Ghs32pi3394ql4DqsGH6v4pgaanqBx80f9ypp1po3HRT+1znzo3/GmG1884WpocPt/WMlJcYztpoOCsvt4NZgM2mWL481yMiSk23bqrnn5/rUVCBalU4A9AHQI/I750AfAjgUADPxDQE+W1Lz5WWnc+YMfaTTkuWWNC4+mr7wltSYgHkvvtsAfNPfhKsuYWbcnnddekdX6Y0NkYrfTfdZFUiEftC7ALIM8/Y/b/5TfRxdXWq1dXBj5AuX27rCt5/v+ntX35pr1dcbOvmWqOhwdYYjh0bPxgvXGhV0IoK2/72260KNmaMfeFQVZ09O/p7S1atUu3a1V7XaWy0NW9FRVbJO/poOzq3eLHdX1Gh2rOnVfrat28a+CsrrTJ36aWqp59un/vkyfacRx1l/13efbc911Zb2eP33dcazSxZEq2anX++vY9evVQPPzzZTzL3tt3W1nGOGmUhjfISw1kbDWfnnWfT4h97jFUyym+9etl/z0Q5kGgfKXZ/fCKyHYBHIuvO2gF4WlWvEZGhsFb6vQB8CeAkVd0Y/5mAUaNG6dSpUxO+XosGDbLW8Y880rrnibXnnsDy5UBVlbWhb9cOmDfP2gFPmWLt8FtSX28t3o89FujcOb3jy5SNG4GTTgKefdba4G+/vbXl79TJ7l+/3s7LdtVVdsLsdLvzTqBnT2DcuPQ/dxBVVdbuOdXW/5dcAtx0E3DNNcD8+XYunu+/txOLT51qJxPfemv7b/bKK227d9+1n5NPtlbxp51mp3K4/35g5Ur7vaHBHvP229ZWvq7O7hswwF53xQrg2mvt32rmTHsPw4fbue8WLLCW1OPG2X+7Cxak7/PKhq22An76U3u/1dV2ygjKOyIyTVVH5Xoc+SIt+8dMeO89mwOwzz52feut7eRsTcEAACAASURBVDyjkyfndlxErdWvn53k/K67cj0SKkCJ9pEtnixEVWcC2NHn9gUARrd+eEnYuNFO5Lz55ul/7qOPBi680ILZu+8CW2wBPPqonfwySDAD7LwZv/pV+seWSR06AE89Ze/9zTeBF16IBjPAvvQ/+WTmXv+3v83ccwdRWtq6x194oQXMyy+3IL/77nZeuKOOArp1s5+rr7YTrrovM7fcAuy6q51c9aij7HptrZ2o/LrrgFGj7OTl3btbMAMsOLtgBthr3Xqr/T5/PnD++cCrr9q58fr3t9tHjLBzw1VXN/03DbuaGjtPYffuwLJluR4NUeGqrrZzirZvb+cLXbrUzit6xhm5HhlR6xUX8yTUFEr5dSbH77+3I3iZCGfHH2/VuKuvthNFA3Zi60JQVBT9ok/J2XRTOwF3SQnQp4//NpdcAvzyl1bF+uEH4Mwz7fattrITkqtaOOvQIfoYvxObx7PFFhb0Zsywo9rOiBH23PPmAdttl/x7y5WaGvssunfnSaiJcunxx+1vFgB89BGwaJH97qpoRPmM4YxCKr/C2cKFdhm0kpWMAQOA6dPT/7zU9nkrWvEMHGg/fkSaBrNUbb990+sjRtjlnDn5Fc42brTKWceOQGVlrkdDVDhUgb//Hdh5Z2C//YAJE4BttrGp0ZMm2TT3TTZp/reGKB8xnFFI5Vc4++47u8xE5YyordlySwt+33xj19evt3WVQ4fmdlwtcdMaO3SwNYGNjamvCSSi4L7+GrjsMptNcfrptob1n/8EXn4ZeOYZ+39y7735/yO1DSUlDGcUSvn1F3bhQvufqaws1yMhCr9OnazK7MLZ+PEW2O65J6fDSkjVKmduWqOqBTQiyrynnrLgteeewL332vrV44+3n5UrgfJyYN99cz1KovRg5YxCKr/C2SWX2LqdoqJcj4QoP4wYYeFMFXjpJft/55xz7Oh4GNXW2qVrCAJw3RlRNqja1MV997XmUH/8IzBxojUDGTvWmmUBDGfUdjCcUUjlVzjr2RPYsVnjSCKKZ8QIYO5c4KuvrNPpbbfZUfC//S2cFamaGrt0lTOA686IsmHaNODbb+3vQ/v21jn2yCPtvk6dgBNOsCZGW2yR23ESpQvDGYVUfq05I6LkjBhh7bDvvdeuH3KInTNt0iSbPtjaUwmkmwtnHTvaaQgAVs6IsmHSJFs24AJZrIkT7W+GO70HUb5jOKOQYjgjastca/2HHwZ+8hPrGFkc+d8+jDuljZHz2HNaI1H2NDZaODvgAKBXL/9t2re3H6K2orjYDlYShUx+TWskouS4dvrr1wMHHWS/hzmc+U1rZDgjyqybb7aTTJ9ySq5HQpQ9rJxRSDGcEbVlvXtHj4QffLBdlpTYZRh3Sn6VM645I8qcKVOAP//ZpjMee2yuR0OUPQxnFFIMZ0RtmYhVz7p0AfbYw27Lh8oZpzUSZdbcucADD1gDkLIy+53ryaiQMJxRSHHNGVFbd9FFwLJlNlUQiIazMM61905r7NTJft+wIXfjIWqLXnkFOOww+71fP+DFF60bMlEhYTijkGI4I2rrjjqq6fUwV8680xpF7IS4jY25HRNRW/Pvf9sBkC+/tMo6K2ZUiBjOKKQYzogKTZjDmXdaI2DhrKEhd+MhaoumTgW23z7azZWoEDGcUUhxzRlRocmHcOamYBYVMZwRpVNjI/DFF8BOO+V6JES5xXBGIcVwRlRo8qVbI2DhjNMaidJn/nzrgDpqVK5HQpRbDGcUUgxnRIUmHypnnNZIlBlTp9olwxkVOoYzCimGM6JCky/dGgFWzojSbdo0O/gxcmSuR0KUWwxnFFIMZ0SFJsyVs9hpjaycEaXX1KnADjtE/w4QFaqSknDuB6ngMZwRFZowh7PYaY1sCEKUPq4ZCKc0ErFyRqHFcEZUaMLcEMSFMzdGTmskSp///hdYt46dGokAhjMKLYYzokIT5srZxo3RE1ADnNZIlE5sBkIUxXBGIcVwRlRowt4QxDUDAVg5I0qnhx8G+vUDRozI9UiIcq+4OJz7QSp4XBFMVGjyoXLmsHJGlB7/+Q/wzjvATTexGQgRwMoZhRYrZ0SFJszhrKamaThjQxCi9LjmGqBvX+Ccc3I9EqJwKC62mRmcnUEhw3BGVGjCHs680xrbteOOk6i1Pv0UePNN4OKLgc6dcz0aonBw+0IeAKSQYTgjKjRh7tYYO62RlTOi1rv3XqBHD+A3v8n1SIjCI8wHKqmgMZwRFZow75D8pjWyckbUOp9+CowZA3TtmuuREIVHmPeFVNAYzogKTT51a2RDEKLWWbsW+OYbYPToXI+EKFwYziikWgxnIjJIRN4TkdkiMktE/hC5/SoRqRCR6ZGfsZkfLhG1Wph3SJzWSJRe06YBqgxnRLHCvC+kghakn249gItU9QsRKQUwTUTeitw3QVVvzNzwiCjtwrxDqqkBeveOXmdDEKLW+ewzu+SJp4maCvO+kApai+FMVZcCWBr5vUpE5gAoy/TAiChDwrxD8jsJNStnRKmbMgUYPhzo1SvXIyEKlzDvC6mgJbXmTESGANgRwJTITeeJyEwReVBEeqZ5bESUCUVFdhnGHZLftEZWzohS99lnnNJI5IfhjEIqcDgTka4A/gXgfFWtBHAXgGEAdoBV1m6K87izRGSqiExduXJlGoZMRK0iYjulsDYE8YYzNgQhSl1FBbBkCcMZkR+GMwqpQOFMREpgwexxVX0OAFR1uao2qGojgPsA+P71V9V7VXWUqo7q06dPusZNRK1RXJz7HdJ33wEPPND0Nk5rJEoft96M4YyoOYYzCqkg3RoFwAMA5qjqzZ7b+3s2OxLA1+kfHhFlRBjC2b33AmecAUydGr0tdlojG4JQCInIQSIyV0Tmi8iffO4fHOly/GVk6n9uuhl/9pn9v77DDjl5eaJQKymxy1zvC4liBKmc7QHgZAD7xLTNv15EvhKRmQD2BnBBJgdKRGkUhnC2ZIldTpwYvc3vJNSsnFGIiEgRgIkADgYwEsA4ERkZs9nlAJ5W1R0BnADgzuyOMuLzz4Httmv6/xQRGVbOKKSCdGv8CID43DU5/cMhoqwoKcn9DmnpUrt86ingxhuB7t0tiMVOa8z1OImaGg1gvqouAAAReQrAEQBme7ZRAN0iv3cHsCSrIwTs3GbTpwO/+EXWX5ooL7hwFsb111TQkurWSERtRBgqZ0uXAltuadWyBx+0KY0AG4JQ2JUBWOy5Xo7mp5e5CsBJIlIOO5D5O78nymjDrCVLgFWrOKWRKB5WziikGM6IClEYujUuWQLssw/ws58Bd90FbNhgt3NaI+W/cQAeVtWBAMYCeFREmu1vM9owa/p0u9x++/Q+L1FbwXBGIcVwRlSIcl05q621o/r9+wPnngssXAg8/7zd553WyIYgFD4VAAZ5rg+M3OZ1OoCnAUBVPwHQEUDvrIzOmTHDLrfbLqsvS5Q3GM4opBjOiApRrsPZsmV2OWAAcOSRFtImTLDbWDmjcPscwHAR2VxE2sMafrwUs833APYFABHZGhbOsnuizxkzgM03t7WcRNQcwxmFFMMZUSHKdThzzUD697fmJGedBXzzjd0W2xCElTMKEVWtB3AegDcAzIF1ZZwlIteIyOGRzS4CcKaIzADwJIBTVVWzOtDp0zmlkSgRhjMKqRa7NRJRG5TNbo133QUMHAgcdlj0NtdGv3/kdIlnnQVce62NiQ1BKORUdTJiOhar6hWe32fDTkOTG+vXA/PmAePG5WwIRKHHcEYhxcoZUSHKZuXsuuuAX/0KWL06epu3cgbY9MajjrLfOa2RqHW+/tpa6bNTI1F8DGcUUgxnRIUom90aq6qANWuAv/41etvSpVYV69s3etuFFwKdOgGbbRa9jQ1BiJLHTo1ELWM4o5BiOCMqRNmsnK1bZ693xx3A/Pl229KlFsyKiqLb7bKLBbkRI6K3sXJGlLwZM4Bu3YAhQ3I9EqLwYjijkGI4IypE2QpntbVWoTv7bKB9e+DKK+32JUtsKmMsb1hz11k5I0rOjBlWNRPJ9UiIwovhjEKK4YyoEGWrIci6dXY5fDhwwgnAa69Z2Fq6NLreLBE2BCFK3rJlwKBBLW9HVMgYziikGM6IClG2KmdVVXbZtSvws5/Z2rNZs4KHM05rJEpedbWt3ySi+BjOKKTYSp+oEGWrIYirnJWWAjvvbL+/9x6wYkXwyhmnNRIlh+GMqGUMZxRSrJwRFaJsVc5cOOva1ZoTlJUBzz5rbb5ZOSPKjJoahjOilpSU2CXDGYUMwxlRIcpFOBOxqY0ffWS3BQ1nrJwRBadq4cx7vkAiao6VMwophjOiQpSLNWcAMGaMfXkE/Ls1xmJDEKLk1NTYJStnRIm5cJatc34SBcRwRlSIst2tsbTULseMid7HaY1E6VddbZcMZ0SJsXJGIcVwRlSIcjGtEQBGjgR69rTf+/Vr+fFsCEKUHIYzomDceTUZzihkGM6IClG2uzW6cNaunVXP+va1k1K3hJUzouRwWiNRMO3a2Q/DGYUMW+kTFaJsrznr0iV62w03AIsXB3s8G4IQJYeVM6LgsrUvJEoCwxlRIcrmtMYuXezopLPllvYTBBuCECXHhTN2ayRqGcMZhRCnNRIVotbukBobgeXLW95u3brolMZUcFojUXJYOSMKjuGMQojhjKgQtbZb4403AsOHR9e3xNPacMaGIETJYTgjCo7hjEKI0xqJClFrG4L885+2nmzFCmDw4PjbVVW1vnIGWEBrx2NJRC1iOCMKLh/C2bRpdjqaoMsBUlFVBTz0ELBxo+2zTz+95aZdCxbYd4Bdd03+9WbMsIPEI0emNl4A+OILoHNnYMQIu/7998DTT9u5VAcNAk44If5jJ08GZs2y38eOBbbZxn+7devsc6mpsdc64wygQ4fUxxwQwxlRIWrNDmnWrOgftZUrE4ezdeui5zhLBcMZUXLYrZEouHwIZ2eeaTNVJk3K3Gs8+yzwhz9Er2+5JbDvvokfc/XVwIcfWkhL1rnnWgh8/fXkH+ucdhowdCjw/PN2/bbbgJtuit5/wAFAr17NH6cKHHNM9EDWp58C//qX/2u8+CLw+99Hrw8aBBx+eOpjDojfdogKUXGx/YFKZcrgM89Ef1+5MvG26ZjWCHDdGVFQbAhCFFw+hLMNG+wnk77/3i4/+sgu16xp+TGrV9tPKiorU3+ss2hR9HQ9ALB+PdC7N3DPPXb9xx/9H/fDD/Z38oYbgN12S/xe3efy9dd2GbTTdCsxnBEVouJI0TyVndIzz0SrZStWNL9/3ToLfu73dExrZDgjCobTGomCy4dwVlcH1NZm9jUqKuz8o2Vldt2dBieRqir7cfv7ZFRXB3uNeNatA9autWmYzsaNdlCqd+/o+PxUVNjl5psDPXokHkdFBdCzp02dLCqKPjbDGM6IClFJiV0mu1OaNQuYPRs45xy7Hls5mz3b/sA/95xdb+2aM1c5Y1MQomAYzoiCy4dwVl/fujXiQZSXAwMHAt262fXKypYfU1lp++ZUqnrV1cFeIx4XkmLDWYcOLb8H99iyMts20TjKy227oiKgf3+GMyLKoJYqZyec4D+//fHHARGb692+ffPK2fjx9kd3zhy7nq41Z6ycEQXDcEYUXD6Es2xVzsrKovvroOEs6Lax8iWcVVRYaAXsMizhTEQGich7IjJbRGaJyB8it/cSkbdEZF7ksmfmh0tEaeHCmd/RuEWLLJjdeGPT25cutQW3Rx4JbLop0KdP08rZ229bByQAWLbMpjqka1ojK2dEwdTUWMXZVceJKL58CWfZqJyVldnfjY4dg09r9F4mY8MG+36Q6r69vNwuvaF140Y7aOwCZqJpje3a2feY0tLE43efC2CXYQlnAOoBXKSqIwHsCuBcERkJ4E8A3lHV4QDeiVwnonyQqHL2wQd2OXVq0y5MV1xhfwivu86u9+0brZw1NAAXXQQMGQIMG2bhrLbWnp8NQYiyp7raqmYiuR4JUfiVlGQ++LRWfX1mK2fV1dacw1WIWqomOalWzlSjXWW9DT2S4Vc5q60NXjnr18/+7bt1s0Yift8x6uqA5cujn0uYwpmqLlXVLyK/VwGYA6AMwBEAHols9giAX2RqkESUZonC2YcfRqdEuc6MX30FPPigtb8dPtxu81bOPv0UmDnTWusOHmzhzB2NYkMQouyprmanRqKgWDkDliyxS1chChLO6uqiASvZcOYel8pjndZOa/S+V8C/euZmAHkrZ64JSoYlteZMRIYA2BHAFAD9VHVp5K5lAPqldWRElDkthbN99gFGj7YTOm7cCJx9NtC9O/B//xfdzls5mz/fLnfbzaYKLF8ePSLGhiBE2eMqZ0TUsnwIZ5munLkpgt7KWUsBxHt/smHFrYsFUg9nbsx+4axLF5s5ECScJZoC6V7DG87c4zMscDgTka4A/gXgfFVt8o5VVQH49tIUkbNEZKqITF3Z0jmRiCg74nVrXLEC+OYbYMwY4LjjgC++sDVmn3wC3H130xM6eitnCxfaH8PBgy2cLVsWDWdsCEKUPQxnRMHlQzjLdOXM2yADsH12S6HJe3+yAcsbzlKtQiWqnLVrZweFE605i62c+b0H9xreaY3e2zMoUDgTkRJYMHtcVSM9srFcRPpH7u8PwOeER4Cq3quqo1R1VJ8+fdIxZiJqrXiVM3cCyjFjgGOOsd9few246ioLa159+9pc7Q0bLJyVldkfxk03tWC2bJltx4YgRNlTU8NwRhRU2MNZY6P9ZLJyFhvOgkxrTFc4a+20xtiGIB062O/x3oNbX5dMOMtB5ay4pQ1ERAA8AGCOqt7sueslAL8CcF3k8sWMjJCI0i9et8YPP7T1KqNGWdejE0+0o2hXXNH8OdzBlpUrLZxtvrld7xeZ4fztt3bJhiBE2cPKGVFwYQ9nbmyZrJyVl9t+3gWVIOHMW5XKdjirq7ODv+3aWSBTtZk7tbX2vQWI/x5i19clOnVAebl9H3IzhsIUzgDsAeBkAF+JyPTIbZfCQtnTInI6gEUAjovzeCIKm3iVsw8+AHbdNfoH7rHH4j+HC2crVlg422cfu77ppnbp1qGxIQhR9jCcEQWXL+Es05UzFzyAltvLA03DTLbXnLlGHYMH26l/6ursO4u3chbvPcSuI0vUEMR9Lq7zbefOQI8e4QhnqvoRgHg9efdN73CIKCv8wtmGDcD06cCllwZ7jr597bK83P5YucpZbDhrzZozNgQhSk51NdC7d65HQZQfwh7OXMUs05Uzt64KyO60xlTWnLmANXSohTN3frMg0xr9pnAC8Stn3tDqHheWNWdE1Mb4NQRZtcpC0GabBXsOVzmbNs2OYsULZ6ycEWUPK2dEweVLOMtm5axbNws6iV7ThaqSkuTD2YYN0d9TqZy5cDR0qF26piCphLNE0xorKpqGVvc4hjMiygi/ylmyre9d5ezzz+1yyBC77N3bKl7pWHPGhiBEyWE4Iwou7OHMja2+3g6CpltDA7B0afNwBiSuarkwM2BA9qc1unA0bJhduhAZZFpjRYV9J3HvMV4rfdXmoRVgOCOiDPJrCOL+OAWdhti1q/0h/Owzu+4qZ0VFVlVzf4A7d059nGwIQpQcdmskCi7s4cy7j87E1Mbly23/6q0QJaomOe6+/v1zM62xQwd7bSDaFMRNbwQSV868gaukxP5exm67apU9n184W7Ys4//NMJwRFaJ0VM5ErHr244/2B877R8xNbezaNRqwUsFpjUTJYeWMKLiwhzPv2DIRzmKn+QGJ12E5VVW2f+/ZM/Vw1r596pWzsjLrpAhYiGposIAWO60xttroVw3zO69b7DnOnLIym8mzfHny404CwxlRIUpHOAOi684GD44GKaBpOGsNNgQhSk51dfRLCxElFvZwlunKmWuuEdsQBGh5WmNpabDOjrFcOOvXL7Vw5hp1uCrZxo3RdWfeaY2NjU3XtwH+4axbt+bvIbaro5OldvoMZ0SFKF3hzK07c1ManXSFM1bOiIJT5bRGomSEPZx5x9ZSUxBV4J13/A9mzp7tHyj8KmdBpzV269ZyZ8f3328eKv3C2erV1lzMaWy09+K3zs416nBBzC+c+QXMxkY7z5lfOEumcua9P0MYzogKkV+3xmTXnAHRylmmwxkrZxQiInKQiMwVkfki8ief+yeIyPTIz39F5MesDKymxi4ZzoiCCXs4S6ZyNn06sN9+wJtvNr/vyCOB8eOb315RYd8H3L4cCD6tsaVwNn8+sPfewNNPN73dhbO+faPfO264IXquVMBC3X77AVOnNn2st1GHC2K1tfHDmXdsq1fbv7X7fuJ9v37hrF275tu6cOYqaxkS5CTURNTWZKty1ppznAFsCEKhIyJFACYC2B9AOYDPReQlVZ3ttlHVCzzb/w7AjlkZHMMZUXKKizN7DrHWSqZytmKFXS5c2PT2xkbgu++AXr2aP6a83DoueteGB53W6MLZ+vW2j/YubfCOI3Y81dU2JbFHD2DuXLttwYLoGjERW8vuHrvzztHHeht1BKmc+Z2PrUePpuMpLQUWL256W3m5VfaKY2JSnz4WOmOrb2nGyhlRIfLr1ujCWZcuwZ8nXuWsXz+75LRGantGA5ivqgtUtRbAUwCOSLD9OABPZmVk7og0wxlRMCUlbady5sJUbFXnhx8s2PlVe+I1yABantbo1pwB0e8PXu71YqcAVldbF2dvIw63rbctvt978U439IYz9zi3Ds2vRb57LRfcnHiVs9gpjYCF2GHDMr6ul+GMqBDFq5x16tT86FcimV5zxoYgFD5lALyHWcsjtzUjIpsB2BzAu1kYF8MZUbLyaVpjS5Wz2KDjuOtLlzZ/r+XlzUOI228HndYYb1v3urHjcR1lvY04goYzb6OORA1B/MYVb+mGXzhzTUdyhOGMqBD5hbOqquSnIR52GHD55cBOOzW9nQ1BiADgBADPqqrvf8AicpaITBWRqStXrmz9q7lwxm6NRMGEPZwl00o/Xjhz1aaGhqYt4OOdaLldu5a7MHqnNQL+28arnG3YEA1nNTUWrJYssftcyHIhLWjlLJlpjbGVM7/3Gq9yliUMZ0SFyK8hyLp1yYep3r2Bv/yl+bzsdK85Y+WMwqMCwCDP9YGR2/ycgARTGlX1XlUdpaqj+ngX5KeKlTOi5BQX2/4lrPuYVCpnsWHIG3C8961da0HJL4QkavSh2nxaY7wTPvuNx1s5A2wNl/su4kKWu4x9bEWFrUnbdNPEDUGSndboDXjr19uaN1bOiCir4k1rbG2ly+nRA+jfHxgypHXPw8oZhc/nAIaLyOYi0h4WwF6K3UhERgDoCeCTrI2MDUGIkuP2hWHdxyRTOfNOEfS2oPeGM7/f/UKI34mZnY0bbVxBpzWuWBENPkA0nLkANWdO0+f2XvpNa+zXzw4wp6tyFlv98zu9QJYxnBEVongNQdIVzkSsC9Pvfte652E4o5BR1XoA5wF4A8AcAE+r6iwRuUZEDvdsegKAp1T9TtSTIaycESXH70BlmKRSOVu/3qpiTkVFtNGXXxXNL4T4nZg59nWCTGt0f4uWLo3eHls5SxTOlixpuv/3Tjf0C2duHVrHjvZvG2TNWWyVLd45zrKI4YyoEKVrzVkipaXNpzsmi9MaKYRUdbKqbqmqw1T12shtV6jqS55trlLVZudAyyiGM6LkhD2cpbLmDGheIdt2WwsufuEs2WmN7vbS0viVs+pqa3s/alTz8cSGs9mzo/fFhrP6+ugpAtyYXZj0NgRxwdUFNpHma8kqK+322I7Use+BlTMiyolMT2tMF1bOiIJjOCNKTtjDWTKVs6oqCx9A07VariNjWVnz2wE7z1msRNMaXeDp1i3+mjPX4GOXXZqPJ5lpjX7vxYWmRNMa3fhipzWWljY9p5vbzvseEk33zBKGM6JClC/hjJUzouDYrZEoOWEPZ8lWztw6bxcwVKPhbODA5pWzvn2jFSivoNMa/RpveF8/UThzocidiBpo3krf+1yuUYer9Llx+zUEceOLndboNzvIb1pjjx7JnfM1zRjOiApRvoQzVs6IgmPljCg5YQ9nya4522or+90FmspKCzV+4SzRubyCTGvs1s0ac3Tq5H+eMADYZhs74XSiaY01NdF9vbeVvrsttiW/G7OIBbRkKmexzUDcdt73leNznAEMZ0SFScT+8GVyzVk6MJwRBcdujUTJCXs4S7ZbY+/e1s3QBRnvFD03rdH1KPI7x5njgo1fP6PYxhp+UyC969kGDkxcOQOAwYPt0jutcdNNLfzFtuT3rpHr0MG/IYgbV+yasyDhLMfnOAMYzogKV3Fx9I99ba39HrbKGac1EgXHyhlRcsIezpKtnHXr1rRC5i5dSNq40Rp1AIlDSGmpHRR1f1NiXweIhhq/Klt5eXTaY+xatw0brJrm/b4xbJhdesNZx4722HiVM6B5OGvNtEZvOGPljIhyorg4ukNat84uwxbOWDkjCq662g5ouJPME1Fi3nD24IPAd9/ldDjNeMNZkDVnLgzFBhoXzgC7r6YG+OGHxJUzwH/dmV8481tz5l7POx7VaOWsXbvod46hQ+3SG846dGj6WL9GHW5aY2y3RjeuINMa3Riqquy/g2XLGM6IKEfyIZyxckYUXHW1HW12HduIKDEXzpYuBU4/Hbj77tyOJ5a3opeocuYCSrzK2YABTcOZ66YYr3KW6OTSVVW2b3YV+niVMxdwBg6012tsjIYv72MB/3DWvn3T91JRAXTv3vR7SocO8RuCBJ3W2K5ddGrmsmU2Tk5rJKKc8IYz9wcsbOGMlTOi4NwRaSIKxoWzmTPt8ttvczcWP0ErZ9729gMHAmvW2PTB8vJoR0YXlioqWm4XH69FvrutW7foQaB4a868lbO6OmDlyuZTr93ruGmN3m6NHTpE16u5rpOx4/VOaywubtomv1s3O/Dsvj+4ymK891tZGYo2pcjzJgAAIABJREFU+gDDGVHhKilpXjljQxCi/FVTw3BGlAwXzmbMsMsFC3I3Fj9BG4J4TwztQlFFRdOQtOmmFl7KyxOfgBpoeVqjtwIVO62xrs4qke65veOJDWeJKmcunFVXW9j0WyPnDWfeqpn3udets3BXVeVfOfO+h5Y+lyxhOCMqVN6GIJzWSJT/WDkjSk5s5Sxs4SxoQxDvOjDv9EXv2q/iYqB//6bhrKU1Z/GmNXoP5MZOa1y2zMKQt3IGxA9nItHzs3lb6btw5t6LX6MObziLPV+b9/xlGzbY94hE4ayysuXPJUsYzogKVT6sOWPljCg4hjOi5LjmOV9/bZc//gisXp278cSqr49O1ws6rdEFizPPBObMaRo0ysqA558Hbr7Z9vfxwooLNhdcAOy6K/Duu9H7YitnpaXWXGT0aPs5+ODoa3kvy8v9pzX26xf97uHXEAQAjjvOqnGxocnbECRe5Wzt2uZNTPze73/+A/zjH/Y8m2ziv12WFOf01Ykod/JhzRkrZ0TBMZwRJcdVzjZssHOE/fCDVc969crtuJy6OguQjY3BK2fDhllzkyVLgBEjgBNPjG533nnAk0/a77vvHv/5Nt8cOPVUYPly4J13gBdeAPbZx+5bsSJ6XjIAOOooYPbspgdRR46MPn+/fnag1a9yduaZwP77R0NybDjbYQcb/+rVwJZbAkcf3XScHTrYdG6/aY29e9vlypXR54+3dOOMM6KVt9Gjc95UieGMqFD5Vc645owof7lujUQUTLHna/DYscA//2lNQUaNyt2YvFzlDAi+5qyoCLj/fv/tTj7ZflpSXAw89JD9vvXWTc9TVlEB7LZb9PouuwAvvxz/uYqKbDqlXzgbOza6nauCAdFpip06AY89Fv+5O3SwyphfOPNOp3QHnuNVzk44wX5CgtMaiQqVX0OQsFXOGM6IgmPljCg53nB2yCF2GaZ1Z65yVlISvHKWbt6TSG/cmPj8aPG4lvix4czLtcV3rxMbtvwkagjiDWeZ/HwyoMVwJiIPisgKEfnac9tVIlIhItMjP2MTPQcRhZBf5axz59yNxw+nNRIFx26NRMnxhrPRo20KXpja6dfV2Rjbtw++5izdvOHMnR8t2XDmnmPDBrseL5zFTmtsSUsNQUpLm4azsM0OiiNI5exhAAf53D5BVXeI/ExO77CIKOO83RqrqiyYuUpVWLByRhQcK2dEyXHhrHNnW0c1dGi4Kmf19cErZyJAly7pH8PAgdaMo6Eh9W6GZWVNK2d+B4JTCWduKmS87V0ozGR4zYAWw5mqfgAgRK1riCgtYitnYTyixMoZUXAMZ0TJceFs661tfzNsWLjCWdDKmTvBciYaWZSVWTBbsSL1kzQPHGgBacUKu95S5cyv+6IfNxUy3vYunLW1aY0JnCciMyPTHnumbURElB2x4Sxs680AVs6IksGGIETJceFs5Ei7HDoUWLw4cZUqm4JWzhKdYLm1vGu3WlM5A4D58+0yE9Mag4SzMB6E9pFqOLsLwDAAOwBYCuCmeBuKyFkiMlVEpq5cuTLFlyOitGM4I2pbWDkjSo4LZ9tsY5dDh9pMjUWLcjcmr2QrZ5kQG846dwa6d0/uOdzJpIOEs/p6+zdIVzhbutQ6OhYX583Bq5TCmaouV9UGVW0EcB+A0Qm2vVdVR6nqqD59+qQ6TiJKN2+3xqqqcIYzN0WD0xqJWvbQQ8C4cbkeBVH+GDzYujQefrhdHzbMLsPSFCSZNWfZqpyVlSU/fTJI5cy7fsxdb0mQcFZfb6/brVvOz18WVErnOROR/qq6NHL1SABfJ9qeiEIotnK2ySa5HU88RUWsnBEFEaLz9BDlhY4dgVdeiV4fOtQuw7LuzLXSD1I5y1Q469s3ehJpF86SNWCAXX73nb0fv+Zjbv2YC2dBG4LU19usAb8w58Y6Z07erDcDgrXSfxLAJwC2EpFyETkdwPUi8pWIzASwN4ALMjxOIko3b7fGsE5rBGyRNitnRESUaf37W2ALU+WsuDjYmrNMTWv0nkQ61XDWqZMdAG5oiD/12lsFc9db4rZZty5+5QwA5s3Lm/VmQIDKmar6zZF4IANjIaJsyoc1ZwArZ0RElB0iQO/ewJo1uR6J8Z6E2rWh95PJyhkQbYW/ZElq4cw9x6pVicPZ6tWphbPKysThrK6ubVXOiKiN8oazsK45AxjOiIgoe9z0ujDwNgTJ1ZozwELOzJk2hlTDmWsKkonKWX29//b9+kWnUDKcEVHouYYgquGunHFaIxERZUtLQSibvA1B4q05U83stEbAApnruN6ayhnQcjhzn30y4Sze9kVFwKab2u95NK2R4YyoULnKWW2tXYb1DxcrZ0RElC1hCmdBKmcbNtgBzExXzvx+T+U54oWzVLs1eh+f6HVZOSOi0HMNQdats+usnBERUaELUzgLUjlzJ1gOezhz0xo7d/a/P9Vujd7H+2E4I6K84SpnVVV2PazhjJUzIiLKFlfBCYMgJ6F2+/BMT2sErGGKmyaY6nNkYs1Zou3d64Z1dpAPhjOiQuXCWdgrZwxnRESULWGtnMUbUzYrZ/362Vha8xy5CmesnBFR6Llwtny5Xe/dO7fjiYfTGomIKFvCFM6CVM6yGc5SndIIZLZbY6LtGc6IKG+4bo3z59v1LbbI7XjiYeWMiIiyJTacvf46cPfdyT3HjTcCH3zQ+rEkqpxNnw4cdhgwfrxdz+S0vS5dgO7dWxfOevSwYJYonDU2WoMTd70lyTQE4bRGIgo9Vzn79lv7A+eOaoUNK2dERJQtseHswQctbCXj6quBRx9t/VjcSaj9KmfPPgu8+qrtyw86CNhqq9a/XiIXXgicckrqjxcBLr4YOPpo//u9J5T2Xk8kSEOQnXcGjj8eGDMm+FhzrDjXAyCiHHHdGufPB4YOtRAURqycERFRtsSehNo71S6IxkZby+0adbSGm9boVzmrqAAGDACmTGn96wRxxRWtf45rrol/nwta7nNLtpV+vHBWWgo89VSw8YVESL+NEVHGFRfbTmTePGDYsFyPJj6GMyIiypbYylmy4cw12XIVoNZw0xrbt7f9oHcWSUVF66YZho0LVy6cpWvNWR5iOCMqVMWRwvm8eeFdbwZwWiMREWVPa8OZC2XpCGfeypm77pSXh3c5QipSmdbIcEZEbYoLZxs3hjucsXJGRETZEnues9ra5Lo3uspPOqY1eitnQNNw1lYrZwxnDGdEBct7rpIwT2tk5YyIiLIlXuVMNdjjM1k5c+OqqrLnb8vhLMiaM+82QbbPEwxnRIWq2NMPiJUzIiIi/3CmalWsINIVzlRt3+dXOauosMu2Oq2xpCRYkzJWzoioTXHhrKgI2Gyz3I4lEYYzIiLKFte23lXK3BTHoOvO3HTGysrg1TY/Lgz6Vc5cOGtLlTMXQCsrg1fBGM6IqE1x4WyzzZpOcQwbTmukkBGRg0RkrojMF5E/xdnmOBGZLSKzROSJbI+RiFIUW6VKNpy5ill9fXKNRGK5cOZOQu0dU3m5XbalcObt1hg0aBUXRytsbSic8TxnRIXKhbMwT2kEWDmjUBGRIgATAewPoBzA5yLykqrO9mwzHMCfAeyhqmtEpG9uRktESXPhrLa26RTHoE1BvNMZKyuBjh1TG4cLYsXFTccEtM3KWSrhzD2uurpNhTNWzogKlTsSF/ZwxsoZhctoAPNVdYGq1gJ4CsARMducCWCiqq4BAFVdkeUxElGq3Jd8F4RSndYItG7dmQtnfpWzigqgZ0+gc+fUnz9svGvOkg1nABuCEFEbwMoZUSrKACz2XC+P3Oa1JYAtReQ/IvKpiByUtdERUevEVqlSndYItK6dvndaY+yY2to5zoDUw5n7bNpQ5YzTGokKlQtnYW6jDzCcUT4qBjAcwF4ABgL4QES2VdUfvRuJyFkAzgKAwYMHZ3uMROQnneEsHZUzv5NQt7VznAHRcKWaWuWsDYUzVs6ICtXQoUC3bsBPf5rrkSTGaY0ULhUABnmuD4zc5lUO4CVVrVPVhQD+CwtrTajqvao6SlVH9enTJ2MDJqIkuHC2caMdGHQHB7M9rTFR5awth7PY34M+LsyNzZLEcEZUqHbaCfjxx/BPjWDljMLlcwDDRWRzEWkP4AQAL8Vs8wKsagYR6Q2b5rggm4MkohR5g5A3kCVTOXNrwTJROaurA5YvD/++O1mpnlC6Qwf7EUn/mHKE4YyokOXDHzNWzihEVLUewHkA3gAwB8DTqjpLRK4RkcMjm70BYJWIzAbwHoDxqroqNyMmoqR4w5m3Q2My3RpdcEr3mrO6OmDpUpv6x8pZdNs2NKUR4JozIgo7Vs4oZFR1MoDJMbdd4fldAVwY+SGifNLayllVlQWn//43/ZWz2troOc7aWuUs1XDWvn2b6tQIsHJGRGHHcEZERNmSjmmN/frZrI90rzmrq2ub5zgDWDnzYDgjonDjtEYiIsqWdISz7t2t4VZrpjXGq5y11XDWrl20izTDGRFRiLFyRkRE2eI9CXWQcFZfD1xxBbAqsqy0stKCWbduwStntbXA5ZcDa9c2fV6geeWsvBzo2BHo1Sv4e8oXqbTFZzgjIsoyVs6IiChbkm0IMmsW8Je/AC+8YOGppgYoLbWfoOFsyhTg2muBt9+O3paoclZWlh8NvZLlPvtk1pAdeihwzDGZGU+OtNgQREQeBHAogBWq+pPIbb0ATAIwBMB3AI5T1TWZGyYRFSxWzoiIKFu85zkLUjlzAayiIjqN0VXOgk5rdFMVva/hwpnfmrO2NqXRSaVydtZZmRlLDgWpnD0M4KCY2/4E4B1VHQ7gnch1IqL0a9eO4YyIiLIj2TVn3nDmfk92WqPrwOitznmnNcZ2a2xrnRqdVMJZG9RiOFPVDwCsjrn5CACPRH5/BMAv0jwuIiJTVMRpjURElB2phrPy8qaVs2SmNbpw5lc5Ky5uOiZWztq8VNec9VPVpZHflwHol6bxEBE1xWmNRESULcmGMxfIysujYay0NLXKmfc1/CpnS5fauFg5a9Na3RAkcrJNjXe/iJwlIlNFZOrKlStb+3JEVGjYEISIiLIl2YYg3spZ7LTGdKw58zYEWbjQLlk5a9NSDWfLRaQ/AEQuV8TbUFXvVdVRqjqqT58+Kb4cERUsVs6IiChbUp3WuHo1sCLyddhNa6yqCnZwsaXKWbt2ti9kOCsIqYazlwD8KvL7rwC8mJ7hEBHFYEMQIiLKllTDGQDMmWOXblqjKrB+feLXq6+36Yqxr+GtnAEW0lw4a6vTGlNppd8GtRjORORJAJ8A2EpEykXkdADXAdhfROYB2C9ynYgo/dgQhIiIssUvnBUVtbzmDABmz7ZLN60x9n4/y5dHD0DG69boxlVZaQcsN9002HvJN6ycAQhwnjNVHRfnrn3TPBYiouY4rZGIiLJFxAKRN5yVliaunLVvb9u7ylnXrvYYd/+AAfFfz603A1qunAEWzIpb/PqenxjOAKShIQgRUUaxIQgREf1/e/ceZWdd33v8/c2EmVxMjDGRA0mQiIBQKpYTLlYP9Q6CBbuwa6VVTynHhdri0WOVgrqs9JQFXtqiLUsWtXVxvKAcLiVeEKhKqbhMEzjlfosBDolyCGFJIklIAr/zx+952HuGuew9s2fv55n9fq01a/Zt9v7OM0x+fOb7e767mwYHc1AqO1kThbNDDsmXN27MwWxgoNE5m2hiY3m+GYz9JtRlTTBzzzcDw1nBcCap2uycSZK6qeyENXfOxprWuH077LcfvPjF+Q+JZces3XA2Z87YA0GaPxvOZjzDmaRqcyCIJKmbmsPZwADMmzd+52zhwsaQjjKUlSFtonPONm3Kr7f//uNvayw7ZzN1GAgYzgqGM0nV5kAQSVI3NYezoaH8MV44W7DgheGs1c7Z5s35a0e+Rj92zpzWCLQwEESSesptjZKkbmo3nC1cmNcqmNy2xmXLcoetlc7ZTA5nds4AO2eSqs6BIJKkbirD2e7d+XI5IGSklHKoWriwEZoms62x7JyNHKU/MJCnR0Kjc+a2xhnPcCap2uycSZK6abTO2WgDQXbsaAwBGbmtcWio8d5kY0kpb2tctuyF3bk9e4aPzLdz1jcMZ5KqbdasvICl1OtKJEn9oAxjE21rLIPXaANBysvjhbOtW/PzjnXOWdktg/4458xwBnjOmaSqK/fxP/dc47IkSdOl3MY4UTgrtyw2h7NyO2N5eWQ4e/rpxh8bH3wwfy7D2RNPNB43Wuds0SKYP39q31uVGc4AO2eSqq4MZG5tlCR1w3gDQW64IYep7dsbwWvBAlixIp8ftnhx43kWLhx+ztmXvpTfpHrBgvzx27+db1+xYvRtjc2ds/nz4YADpuf7rYoy2M7kANoCO2eSqm1W8Tckh4JIkrphcDCHqnIgSHNwuuOOfJ7Yxo3DtzUuWgTXXQdHH914nnnz8nlppfvuy8HjM59p3LZoEaxa9cKhI3v3Du+cXXAB7NzZ8W+1Ulavzu/3tmRJryvpKcOZpGqzcyZJ6qaRnbPyOjQC2ebNjdvK88xOOGH488ydOzyc7diRO2sf+9gLX3Pk0JGRnbNXvWpq31MdLFgAJ5/c6yp6zm2Nkqqt7JwZziRJ3TDetsZym+LmzY3LzeeZNZs7d3i3a+fOfNtoJhoIor5hOJNUbc0DQSRJmm6jhbM9e/I61Nw5a97WOJqphLORA0HUN/ypS6o2tzVKkrpptHAG+bbmzll5+3SEMztnfcvOmaRqcyCIJKmbmsNZORAE8vWRnbPZs8ce/T6ZcFaO2bdz1rcMZ5Kqzc6ZJKmbyuEcu3eP3znbvj13zSJGf55581oPZ4ODOZjt3Zuv2znrW4YzSdXmQBBJUjeNfBPqwcF8+2ids7G2NEL7nTNoTGy0c9a3DGeSqs2BIJKkbhrrnLNnnml0zrZuhS1bxp7UCDmI7d3b6Ia1Es7K885GjtJX3zCcSao2tzVKkrppcDAHql27XhjOtm3LbyQN+U2lJ+qcQaN71k44G/km1OobhjNJ1eZAEElSN5XbGHfvfuFAkO3bG28I/cgj0xfO7Jz1LcOZpGqzcyZJ6qYynMHwztlTT+WO1mGH5esptR/O5s0b/bF2zlQwnEmqNgeCSJK6aWQ4K68/8UT+XIYzmPicM8ihbO/e3A2zc6YJGM4kVZsDQSRJ3TRW56wMZ8uXNzpgrXTOduxodM/GG6UPwztnhrO+ZDiTVG1ua5QkddNY4WzLlvx54UJYtqxxeSzNnbOJwpmj9FUwnEmqNgeCSJK6qQxKMHwgSNk5aw5nrW5rbDWc2Tnre4YzSdVm50wVExEnRsT9EbEhIs4Z5f7TI2JLRPxH8fG+XtQpaZIm6pwtWDB9nbPmc87snPUlf+qSqs2BIKqQiBgALgbeCmwC1kXEmpTSPSMe+u2U0lldL1DS1E10zlmr2xrL89ImG87snPUlO2eSqs2BIKqWY4ANKaWNKaXdwLeAU3tck6ROmmhaY3PnbDq3Ndo560tTCmcR8XBE3Fls21jfqaIk6Xlua1S1LAMebbq+qbhtpNMi4o6IuDIiVnSnNEkd0cpAkBXFr/WiRWM/TzvhbOS0RjtnfasTnbM3ppRek1Ja1YHnkqThHAii+vkOcGBK6dXAjcBloz0oIs6MiPURsX5L+T99knqvOZyNHAgSAfPnw0knwZe/DMccM/bzTHZaY0rw9NP5ddR33NYoqdrsnKlaNgPNnbDlxW3PSyltTSkVf/7mK8B/Hu2JUkqXppRWpZRWLV26dFqKlTQJY3XOdu3K2xgj8m0f+EBjjRrNaOGsPA9tpOZtjTt25D9Ijnc+m2asqYazBNwQEbdGxJmdKEiShnEgiKplHXBwRKyMiEFgNbCm+QERsV/T1VOAe7tYn6SpGhnOZs/OgQzaC0yDg/nr2j3nbPv2fHm889k0Y031TMPXp5Q2R8TLgBsj4r6U0s3NDyhC25kABxxwwBRfTlLfcSCIKiSltDcizgKuBwaAf0op3R0RfwmsTymtAf57RJwC7AWeBE7vWcGS2jcynEXk2555pr3AFJHDWLvhbNu2fNnOWV+aUjhLKW0uPj8eEdeQp1jdPOIxlwKXAqxatSpN5fUk9SG3NapiUkrfB74/4rZPN10+Fzi323VJ6pDmN6EuLw8N5eDUbmBqNZw1DwQxnPW1SW9rjIj5EbGgvAy8DbirU4VJEuBAEElSd40cCAKNkNbuVsO5c/M5ZDt2NK6PZtasPJ3RbY19byqds32BayLvwZ0NfDOl9IOOVCVJJTtnkqRuGrmtsfnzVDpn5SCR8V7Xzlnfm3Q4SyltBI7sYC2S9EIOBJEkddN44WwynbMynM2Z0xgsMpqhoTxK33DW1xylL6naHAgiSeqm6eqcjbWlsfm13NbY9wxnkqrNbY2SpG4a7Zyz8nO7gWnevPbDmZ2zvmY4k1RtDgSRJHXTPvs0PpfbELvZOdu2Lb+32pw57b2WZgTDmaRqs3MmSeqmiBzMRhupP5VwNm/e+I9t3ta4YMH456dpxjKcSao2B4JIkrptcHD0cDaVgSATdc6apzW6pbFvGc4kVZsDQSRJ3TY01PnOWSvbGstpjYazvmU4k1RtbmuUJHXbyM7ZZAeCTHZao5Ma+5bhTFK1ORBEktRtg4Ojj9Tv1kAQO2d9y3AmqdrsnEmSuq2T55zt3g2//rXhTC2Z3esCJGlcDgSRJHXbWOFsMp0zgCefbD2c/frXbmvsY3bOJFWbA0EkSd3Wyc4Z5PPI7JypBYYzSdXmtkZJUrcNDQ1/E+g5c/J6NNF7lY3UHMhaGaW/a1funBnO+pbbGiVVmwNBJEnddt55wweCnHEGHHZY+28M3RzmWumcbd2aLxvO+pbhTFK12TmTJHXbCScMv37oofmjXc2BbKKu29AQ7N2bL3vOWd9yW6OkanMgiCSprtrZ1th8jpuds75lOJNUbQ4EkSTVleFMbTKcSao2O2eSpLqabDhzW2PfMpxJqjY7Z5Kkump3WmPJzlnfMpxJqjY7Z5KkunJbo9pkOJNUbRH5w3AmSaobtzWqTYYzSdU3MOC2RklS/RjO1CbDmaTqmzXLzpkkqX4mE87mzBl+/pn6iuFMUvX1c+fs2Wfhsstg9+5eVyJJatecOY3LrYYzu2Z9zXAmqfoGBvq3c7ZmDZx+Onz9672uRJLUrohGKJs3b/zHluHMYSB9zXAmqfrquq1x1y44/3z46U8n/xzXX58/X3ttZ2qSJHVXGc5aHaVvOOtrhjNJ1VfXbY2XXQaf+hS87nXw2tfCAw+09/UpNcLZjTfCjh2dr1GSNL1aDWduaxSGM0l1UMfOWUpw8cVw5JHw938P990HH/xgvr3ZLbfAd787+nM8+CA8/DCcdhrs3Ak33DC5Wnbtgn/4B/jVryb39ZKkyStDWfP5Z6NxW6MwnEmqg250zh56CP76r2Hr1va+7qmn4CMfgRNOgOuua4Svn/wE7rwTzjoL/vRP4bzz4Ec/yo8p/fSn8Ja3wO/+Lrz3vfm5mpVds/PPh0WLJr+18fzz4cwz4ZhjckiUJHXP3Lk5mEWM/zjDmTCcSaqDciDIk0/C3Xc3Okq/+AU8/XTrz/Pss3D22fDnf567SaV77slbDz/2MXjFK+CCC1rbQnjVVfCqV8Hf/V0OYiedBK9/Pdx6a+6WLVoEf/iH+bEf+AC88pX59Z99Fu69N4ey5cvhE5+Ayy+Hgw7KIeqmm/LXXH99vu3QQ+Hkk+E738l1r1s3PMg9/HAOl6N55BH4whfg+ONz5+zYYxvPP9Jjj8E3vpG/H0lSZ8ydO/GWRjCcCZhiOIuIEyPi/ojYEBHndKooSRpm1iy44gpYuhSOOAIOOQRWroRly/Le/N/4DTjjDPjmN2HzZnj00dwh2ru38Rx79sB73gOf/zx87nO5i3T55XDRRfA7v5M7c9dcA294Qw5Lr3xlDlhXXZW3J/7+78PixXDccfDtb+fXe9e7YP/9Ye3aHJAuuQR+/nM4+mi48kr44z9uTOcaHMyh7+67Yd994fDDYfZs+MEPcmfrllvgrW/NNb3xjfn5b7opd+QA3vnO3NVbujTXfsQRcPPNebvi4Yfn7ZP/9m/5sdu3w2235SB39tn5r7Vf+xqsX5/D4Mkn58du3gwf/3j+nl/+cthvv3yMLrrohdsvJUmT024485yzvjZ7sl8YEQPAxcBbgU3AuohYk1K6p1PFSRKQw84DD8Dv/R785m/m0LV7dw5cjz2WO0nXXgtf/erwr1uyJHenhoZyN2vduhyQjjwyj6cvu1oHHZS3Gx58cA5BP/lJ7q596EON51q2LD/XLbfA6tU5MH7qU/DpT8M+++THvP/9+b6/+Au4+uq8pbHZaafBhz+cO1iHHZavH3RQvu/YY3Mw27kT/uqvcp0pwdvelu9/+9tzaFuxInfBLrwwh0qAN78ZNm3KQe4978nhcdu2XNeePbnGAw7Ij/3hD3MYO/HEfByfey6HveOPh1e/Oj/Xa14z8fYbSVJrWg1nTmsUEGmSfx2NiNcCn0kpnVBcPxcgpXTBWF+zatWqtH79+km9niSN69lnc7do7dq8CA4M5AEa3/teDinLl8Of/EneNgg5IG3cmMPOkiUvDCMpwe235xD20pfmDllEfp0bbsjdr6OOmr7v5+abc9fuwgtHX9S3b8/hcMUK+OhH4YkncpC7667c5XvHO/LlLVvgi1+E+fMbX/uLX8Af/EHeknnOObkL2WERcWtKaVXHn3iGcn2UZrD3vz//gfHHPx7/cTt25LXlkkvg3e/uTm3qifHWyKmEs3cBJ6aU3ldcfy9wbErprLG+xsVHkqbRzp25Y7bvvr2uxHDWJtdHaQbbuTP/Ye9FL5r4sU8+mc9XnuVYiJlsvDVy0tsa23jxM4EzAQ4ot9VIkjqv1a0zkqTuaeff5cWLp68O1cJUYvlmYEXT9eXFbcOklC5NKa1KKa1aunTpFF5OkiSziauhAAAHzUlEQVRJkmauqYSzdcDBEbEyIgaB1cCazpQlSZIkSf1l0uEspbQXOAu4HrgXuCKldHenCpMkqYpafRuZiDgtIlJEeO6dJKklUzrnLKX0feD7HapFkqRKa/VtZCJiAfBhYG33q5Qk1ZWjYCRJat0xwIaU0saU0m7gW8CpozzufwKfBXZ1szhJUr0ZziRJat0y4NGm65uK254XEUcBK1JK3+tmYZKk+jOcSZLUIRExC/gb4M9aeOyZEbE+ItZv2bJl+ouTJFWe4UySpNZN9DYyC4AjgJsi4mHgOGDNaENBfKsZSdJIhjNJklo37tvIpJSeSiktSSkdmFI6EPgZcEpKaX1vypUk1YnhTJKkFo31NjIR8ZcRcUpvq5Mk1V2klLr3YhFbgEem+DRLgCc6UE431KXWutQJ9anVOjuvLrXWpU6Y3lpfnlJyr16LOrQ+Qn3++6tLnVCfWutSJ9SnVuvsvLrUOt11jrlGdjWcdUJErE8p1eINPetSa13qhPrUap2dV5da61In1KtWtaYuP9O61An1qbUudUJ9arXOzqtLrb2s022NkiRJklQBhjNJkiRJqoA6hrNLe11AG+pSa13qhPrUap2dV5da61In1KtWtaYuP9O61An1qbUudUJ9arXOzqtLrT2rs3bnnEmSJEnSTFTHzpkkSZIkzTi1CmcRcWJE3B8RGyLinF7XU4qIFRHx44i4JyLujogPF7cvjogbI+LB4vNLel0rQEQMRMT/iYjvFtdXRsTa4rh+u3hj1Z6LiEURcWVE3BcR90bEa6t4TCPifxQ/97si4vKImFOVYxoR/xQRj0fEXU23jXoMI/tSUfMdEXFUj+v8fPGzvyMiromIRU33nVvUeX9EnNCtOseqtem+P4uIFBFLiuuVOqbF7R8qjuvdEfG5ptt7dkw1dVVdH8E1crq4RnakNtfILtTadJ9rZCtSSrX4AAaAnwOvAAaB24HDe11XUdt+wFHF5QXAA8DhwOeAc4rbzwE+2+tai1o+CnwT+G5x/QpgdXH5EuCDva6xqOUy4H3F5UFgUdWOKbAMeAiY23QsT6/KMQWOB44C7mq6bdRjCJwEXAcEcBywtsd1vg2YXVz+bFOdhxe//0PAyuLfhYFe1lrcvoL8xsSPAEsqekzfCPwLMFRcf1kVjqkfU/5ZV3Z9LOpzjZyeOl0jp16fa2QXai1ud41s8aNOnbNjgA0ppY0ppd3At4BTe1wTACmlX6aUbisubwfuJf+DdCr5H0+Kz+/sTYUNEbEcOBn4SnE9gDcBVxYPqUqdLyb/4vwjQEppd0rpV1TwmAKzgbkRMRuYB/ySihzTlNLNwJMjbh7rGJ4K/K+U/QxYFBH79arOlNINKaW9xdWfAcub6vxWSumZlNJDwAbyvw9dMcYxBfhb4Gyg+UTeSh1T4IPAhSmlZ4rHPN5UZ8+OqaassusjuEZOB9fIznCN7E6tBdfIFtUpnC0DHm26vqm4rVIi4kDgt4C1wL4ppV8Wdz0G7NujsppdRP7leK64/lLgV02/4FU5riuBLcBXi+0lX4mI+VTsmKaUNgNfAP4vecF5CriVah7T0ljHsMq/Y2eQ/7oGFawzIk4FNqeUbh9xV9VqPQT4L8V2on+NiKOL26tWp9pTm5+fa2THuEZOH9fIDnONbE+dwlnlRcSLgKuAj6SUtjXfl3JftKejMSPiHcDjKaVbe1lHi2aT281fTin9FvA0eXvB8ypyTF9C/ovKSmB/YD5wYi9rakcVjuFEIuKTwF7gG72uZTQRMQ/4BPDpXtfSgtnAYvL2kY8DVxSdAWnauUZ2lGtkF1ThGE7ENbKjKrFG1imcbSbvVy0tL26rhIjYh7zofCOldHVx8/8r27PF58fH+voueR1wSkQ8TN728ibgi+Q28uziMVU5rpuATSmltcX1K8kLUdWO6VuAh1JKW1JKe4Cryce5ise0NNYxrNzvWEScDrwDeHexSEL16jyI/D8etxe/W8uB2yLiP1G9WjcBVxdbSP6d3B1YQvXqVHsq//Nzjew418jp4xrZWa6RbapTOFsHHBx5ws8gsBpY0+OagOf3pP8jcG9K6W+a7loD/FFx+Y+Aa7tdW7OU0rkppeUppQPJx+9HKaV3Az8G3lU8rOd1AqSUHgMejYhDi5veDNxDxY4peavGcRExr/jvoKyzcse0yVjHcA3wX4vpSccBTzVt7ei6iDiRvL3olJTSjqa71gCrI2IoIlYCBwP/3osaAVJKd6aUXpZSOrD43dpEHn7wGBU7psA/k094JiIOIQ8ReIKKHVO1rbLrI7hGTgfXyGnlGtlBrpGTkLo0FaUTH+SpLg+Qp6R8stf1NNX1enLb+w7gP4qPk8h71X8IPEie/rK417U21fwGGpOoXlH8R7YB+N8UU2p6/QG8BlhfHNd/Bl5SxWMKnAfcB9wFfI08zacSxxS4nLzPfw/5H8T/NtYxJE9Lurj4/boTWNXjOjeQ93iXv1OXND3+k0Wd9wNv7/UxHXH/wzQmUVXtmA4CXy/+W70NeFMVjqkfHfl5V3J9LGpzjZyeGl0jp16ba2QXah1xv2vkBB9RvKAkSZIkqYfqtK1RkiRJkmYsw5kkSZIkVYDhTJIkSZIqwHAmSZIkSRVgOJMkSZKkCjCcSZIkSVIFGM4kSZIkqQIMZ5IkSZJUAf8fI5KnU5S0Y+EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRnTDanPuAsS",
        "cellView": "code"
      },
      "source": [
        "#@title Default title text\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "\n",
        "from keras import initializers, regularizers"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG56_TlBwRfZ"
      },
      "source": [
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\t# Print the process or not\n",
        "\t\tself.verbose = True\n",
        "\n",
        "\t\t# Name of base network\n",
        "\t\tself.network = 'vgg'\n",
        "\n",
        "\t\t# Setting for data augmentation\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\t# Anchor box scales\n",
        "    # Note that if im_size is smaller, anchor_box_scales should be scaled\n",
        "    # Original anchor_box_scales in the paper is [128, 256, 512]\n",
        "\t\tself.anchor_box_scales = [64, 128, 256] \n",
        "\n",
        "\t\t# Anchor box ratios\n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "\t\t# Size to resize the smallest side of the image\n",
        "\t\t# Original setting in paper is 600. Set to 300 in here to save training time\n",
        "\t\tself.im_size = 300\n",
        "\n",
        "\t\t# image channel-wise mean to subtract\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "    \n",
        "\t\t# number of ROIs at once\n",
        "\t\tself.num_rois = 4\n",
        "\n",
        "\t\t# stride at the RPN (this depends on the network configuration)\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\t# scaling the stdev\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\t# overlaps for RPN\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\t# overlaps for classifier ROIs\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\n",
        "\t\t# placeholder for the class mapping, automatically generated by the parser\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\tself.model_path = None"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzbQ2I72wff8"
      },
      "source": [
        "def get_data(input_path):\n",
        "\t\"\"\"Parser the data from annotation file\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tinput_path: annotation file path\n",
        "\n",
        "\tReturns:\n",
        "\t\tall_data: list(filepath, width, height, list(bboxes))\n",
        "\t\tclasses_count: dict{key:class_name, value:count_num} \n",
        "\t\t\te.g. {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745}\n",
        "\t\tclass_mapping: dict{key:class_name, value: idx}\n",
        "\t\t\te.g. {'Car': 0, 'Mobile phone': 1, 'Person': 2}\n",
        "\t\"\"\"\n",
        "\tfound_bg = False\n",
        "\tall_imgs = {}\n",
        "\n",
        "\tclasses_count = {}\n",
        "\n",
        "\tclass_mapping = {}\n",
        "\n",
        "\tvisualise = True\n",
        "\n",
        "\ti = 1\n",
        "\t\n",
        "\twith open(input_path,'r') as f:\n",
        "\n",
        "\t\tprint('Parsing annotation files')\n",
        "\n",
        "\t\tfor line in f:\n",
        "\n",
        "\t\t\t# Print process\n",
        "\t\t\tsys.stdout.write('\\r'+'idx=' + str(i))\n",
        "\t\t\ti += 1\n",
        "\n",
        "\t\t\tline_split = line.strip().split(',')\n",
        "\n",
        "\t\t\t# Make sure the info saved in annotation file matching the format (path_filename, x1, y1, x2, y2, class_name)\n",
        "\t\t\t# Note:\n",
        "\t\t\t#\tOne path_filename might has several classes (class_name)\n",
        "\t\t\t#\tx1, y1, x2, y2 are the pixel value of the origial image, not the ratio value\n",
        "\t\t\t#\t(x1, y1) top left coordinates; (x2, y2) bottom right coordinates\n",
        "\t\t\t#   x1,y1-------------------\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t---------------------x2,y2\n",
        "\n",
        "\t\t\t(filename,x1,y1,x2,y2,class_name) = line_split\n",
        "\n",
        "\t\t\tif class_name not in classes_count:\n",
        "\t\t\t\tclasses_count[class_name] = 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tclasses_count[class_name] += 1\n",
        "\n",
        "\t\t\tif class_name not in class_mapping:\n",
        "\t\t\t\tif class_name == 'bg' and found_bg == False:\n",
        "\t\t\t\t\tprint('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
        "\t\t\t\t\tfound_bg = True\n",
        "\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "\t\t\tif filename not in all_imgs:\n",
        "\t\t\t\tall_imgs[filename] = {}\n",
        "\t\t\t\t\n",
        "\t\t\t\timg = cv2.imread(filename)\n",
        "\t\t\t\t(rows,cols) = img.shape[:2]\n",
        "\t\t\t\tall_imgs[filename]['filepath'] = filename\n",
        "\t\t\t\tall_imgs[filename]['width'] = cols\n",
        "\t\t\t\tall_imgs[filename]['height'] = rows\n",
        "\t\t\t\tall_imgs[filename]['bboxes'] = []\n",
        "\t\t\t\t# if np.random.randint(0,6) > 0:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'trainval'\n",
        "\t\t\t\t# else:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'test'\n",
        "\n",
        "\t\t\tall_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
        "\n",
        "\n",
        "\t\tall_data = []\n",
        "\t\tfor key in all_imgs:\n",
        "\t\t\tall_data.append(all_imgs[key])\n",
        "\t\t\n",
        "\t\t# make sure the bg class is last in the list\n",
        "\t\tif found_bg:\n",
        "\t\t\tif class_mapping['bg'] != len(class_mapping) - 1:\n",
        "\t\t\t\tkey_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
        "\t\t\t\tval_to_switch = class_mapping['bg']\n",
        "\t\t\t\tclass_mapping['bg'] = len(class_mapping) - 1\n",
        "\t\t\t\tclass_mapping[key_to_switch] = val_to_switch\n",
        "\t\t\n",
        "\t\treturn all_data, classes_count, class_mapping"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo6oI2Vpxqfu"
      },
      "source": [
        "from tensorflow.keras.layers import Layer, InputSpec"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0NqlHVU2Rq"
      },
      "source": [
        "from keras.backend import image_data_format\n",
        "if(K.image_data_format() == 'th'):\n",
        "  input_tensor = Input(shape=(3, 299, 299))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qgHkai5w6HU"
      },
      "source": [
        "class RoiPoolingConv(Layer):\n",
        "    '''ROI pooling layer for 2D inputs.\n",
        "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
        "    K. He, X. Zhang, S. Ren, J. Sun\n",
        "    # Arguments\n",
        "        pool_size: int\n",
        "            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n",
        "        num_rois: number of regions of interest to be used\n",
        "    # Input shape\n",
        "        list of two 4D tensors [X_img,X_roi] with shape:\n",
        "        X_img:\n",
        "        `(1, rows, cols, channels)`\n",
        "        X_roi:\n",
        "        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "    # Output shape\n",
        "        3D tensor with shape:\n",
        "        `(1, num_rois, channels, pool_size, pool_size)`\n",
        "    '''\n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "\n",
        "        self.dim_ordering = K.image_data_format()\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]   \n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert(len(x) == 2)\n",
        "\n",
        "        # x[0] is image with shape (rows, cols, channels)\n",
        "        img = x[0]\n",
        "\n",
        "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
        "        rois = x[1]\n",
        "\n",
        "        input_shape = K.shape(img)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for roi_idx in range(self.num_rois):\n",
        "\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "\n",
        "            x = K.cast(x, 'int32')\n",
        "            y = K.cast(y, 'int32')\n",
        "            w = K.cast(w, 'int32')\n",
        "            h = K.cast(h, 'int32')\n",
        "\n",
        "            # Resized roi of the image to pooling size (7x7)\n",
        "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "            outputs.append(rs)\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "\n",
        "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
        "        # Might be (1, 4, 7, 7, 3)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "\n",
        "        # permute_dimensions is similar to transpose\n",
        "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size,\n",
        "                  'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18YcTkzozux9"
      },
      "source": [
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        return input_length//16\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)    \n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "\n",
        "\n",
        "    input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    bn_axis = 3\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "    \n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t69X_JzYz5z_"
      },
      "source": [
        "def rpn_layer(base_layers, num_anchors):\n",
        "    \"\"\"Create a rpn layer\n",
        "        Step1: Pass through the feature map from base layer to a 3x3 512 channels convolutional layer\n",
        "                Keep the padding 'same' to preserve the feature map's size\n",
        "        Step2: Pass the step1 to two (1,1) convolutional layer to replace the fully connected layer\n",
        "                classification layer: num_anchors (9 in here) channels for 0, 1 sigmoid activation output\n",
        "                regression layer: num_anchors*4 (36 in here) channels for computing the regression of bboxes with linear activation\n",
        "    Args:\n",
        "        base_layers: vgg in here\n",
        "        num_anchors: 9 in here\n",
        "\n",
        "    Returns:\n",
        "        [x_class, x_regr, base_layers]\n",
        "        x_class: classification for whether it's an object\n",
        "        x_regr: bboxes regression\n",
        "        base_layers: vgg in here\n",
        "    \"\"\"\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuguqarDz_XT"
      },
      "source": [
        "def classifier_layer(base_layers, input_rois, num_rois, nb_classes = 4):\n",
        "    \"\"\"Create a classifier layer\n",
        "    \n",
        "    Args:\n",
        "        base_layers: vgg\n",
        "        input_rois: `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "        num_rois: number of rois to be processed in one time (4 in here)\n",
        "\n",
        "    Returns:\n",
        "        list(out_class, out_regr)\n",
        "        out_class: classifier layer output\n",
        "        out_regr: regression layer output\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = (num_rois,7,7,512)\n",
        "\n",
        "    pooling_regions = 7\n",
        "\n",
        "    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n",
        "    # num_rois (4) 7x7 roi pooling\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "\n",
        "    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n",
        "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "    # There are two output layer\n",
        "    # out_class: softmax acivation function for classify the class name of the object\n",
        "    # out_regr: linear activation function for bboxes coordinates regression\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    # note: no regression target for bg class\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "    \n",
        "    return [out_class, out_regr]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTX10MPJ0IVY"
      },
      "source": [
        "def union(au, bu, area_intersection):\n",
        "\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "\tarea_union = area_a + area_b - area_intersection\n",
        "\treturn area_union\n",
        "\n",
        "\n",
        "def intersection(ai, bi):\n",
        "\tx = max(ai[0], bi[0])\n",
        "\ty = max(ai[1], bi[1])\n",
        "\tw = min(ai[2], bi[2]) - x\n",
        "\th = min(ai[3], bi[3]) - y\n",
        "\tif w < 0 or h < 0:\n",
        "\t\treturn 0\n",
        "\treturn w*h\n",
        "\n",
        "\n",
        "def iou(a, b):\n",
        "\t# a and b should be (x1,y1,x2,y2)\n",
        "  \n",
        "\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "\t\treturn 0.0\n",
        "\n",
        "\tarea_i = intersection(a, b)\n",
        "\tarea_u = union(a, b, area_i)\n",
        "\n",
        "\treturn float(area_i) / float(area_u + 1e-6)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxt-DgoA2naI"
      },
      "source": [
        "def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "\t\"\"\"(Important part!) Calculate the rpn for all anchors \n",
        "\t\tIf feature map has shape 38x50=1900, there are 1900x9=17100 potential anchors\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tC: config\n",
        "\t\timg_data: augmented image data\n",
        "\t\twidth: original image width (e.g. 600)\n",
        "\t\theight: original image height (e.g. 800)\n",
        "\t\tresized_width: resized image width according to C.im_size (e.g. 300)\n",
        "\t\tresized_height: resized image height according to C.im_size (e.g. 400)\n",
        "\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n",
        "\n",
        "\tReturns:\n",
        "\t\ty_rpn_cls: list(num_bboxes, y_is_box_valid + y_rpn_overlap)\n",
        "\t\t\ty_is_box_valid: 0 or 1 (0 means the box is invalid, 1 means the box is valid)\n",
        "\t\t\ty_rpn_overlap: 0 or 1 (0 means the box is not an object, 1 means the box is an object)\n",
        "\t\ty_rpn_regr: list(num_bboxes, 4*y_rpn_overlap + y_rpn_regr)\n",
        "\t\t\ty_rpn_regr: x1,y1,x2,y2 bunding boxes coordinates\n",
        "\t\"\"\"\n",
        "\tdownscale = float(C.rpn_stride) \n",
        "\tanchor_sizes = C.anchor_box_scales   # 128, 256, 512\n",
        "\tanchor_ratios = C.anchor_box_ratios  # 1:1, 1:2*sqrt(2), 2*sqrt(2):1\n",
        "\tnum_anchors = len(anchor_sizes) * len(anchor_ratios) # 3x3=9\n",
        "\n",
        "\t# calculate the output map size based on the network architecture\n",
        "\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "\n",
        "\tn_anchratios = len(anchor_ratios)    # 3\n",
        "\t\n",
        "\t# initialise empty output objectives\n",
        "\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "\tnum_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n",
        "\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n",
        "\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n",
        "\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n",
        "\n",
        "\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\tgta = np.zeros((num_bboxes, 4))\n",
        "\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "\t\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n",
        "\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "\t\n",
        "\t# rpn ground truth\n",
        "\n",
        "\tfor anchor_size_idx in range(len(anchor_sizes)):\n",
        "\t\tfor anchor_ratio_idx in range(n_anchratios):\n",
        "\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n",
        "\t\t\t\n",
        "\t\t\tfor ix in range(output_width):\t\t\t\t\t\n",
        "\t\t\t\t# x-coordinates of the current anchor box\t\n",
        "\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n",
        "\t\t\t\t\n",
        "\t\t\t\t# ignore boxes that go across image boundaries\t\t\t\t\t\n",
        "\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tfor jy in range(output_height):\n",
        "\n",
        "\t\t\t\t\t# y-coordinates of the current anchor box\n",
        "\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\n",
        "\t\t\t\t\t# ignore boxes that go across image boundaries\n",
        "\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t\t# bbox_type indicates whether an anchor should be a target\n",
        "\t\t\t\t\t# Initialize with 'negative'\n",
        "\t\t\t\t\tbbox_type = 'neg'\n",
        "\n",
        "\t\t\t\t\t# this is the best IOU for the (x,y) coord and the current anchor\n",
        "\t\t\t\t\t# note that this is different from the best IOU for a GT bbox\n",
        "\t\t\t\t\tbest_iou_for_loc = 0.0\n",
        "\n",
        "\t\t\t\t\tfor bbox_num in range(num_bboxes):\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t# get IOU of the current GT box and the current anchor box\n",
        "\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\t\t\t\t\t\t# calculate the regression targets if they will be needed\n",
        "\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n",
        "\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "\t\t\t\t\t\t\t# x,y are the center point of ground-truth bbox\n",
        "\t\t\t\t\t\t\t# xa,ya are the center point of anchor bbox (xa=downscale * (ix + 0.5); ya=downscale * (iy+0.5))\n",
        "\t\t\t\t\t\t\t# w,h are the width and height of ground-truth bbox\n",
        "\t\t\t\t\t\t\t# wa,ha are the width and height of anchor bboxe\n",
        "\t\t\t\t\t\t\t# tx = (x - xa) / wa\n",
        "\t\t\t\t\t\t\t# ty = (y - ya) / ha\n",
        "\t\t\t\t\t\t\t# tw = log(w / wa)\n",
        "\t\t\t\t\t\t\t# th = log(h / ha)\n",
        "\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n",
        "\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "\n",
        "\t\t\t\t\t\t\t# all GT boxes should be mapped to an anchor box, so we keep track of which anchor box was best\n",
        "\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n",
        "\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n",
        "\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n",
        "\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n",
        "\n",
        "\t\t\t\t\t\t\t# we set the anchor to positive if the IOU is >0.7 (it does not matter if there was another better box, it just indicates overlap)\n",
        "\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tbbox_type = 'pos'\n",
        "\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n",
        "\t\t\t\t\t\t\t\t# we update the regression layer target if this IOU is the best for the current (x,y) and anchor position\n",
        "\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n",
        "\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n",
        "\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n",
        "\n",
        "\t\t\t\t\t\t\t# if the IOU is >0.3 and <0.7, it is ambiguous and no included in the objective\n",
        "\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\t# gray zone between neg and pos\n",
        "\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n",
        "\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n",
        "\n",
        "\t\t\t\t\t# turn on or off outputs depending on IOUs\n",
        "\t\t\t\t\tif bbox_type == 'neg':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'neutral':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'pos':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "\t# we ensure that every bbox has at least one positive RPN region\n",
        "\n",
        "\tfor idx in range(num_anchors_for_bbox.shape[0]):\n",
        "\t\tif num_anchors_for_bbox[idx] == 0:\n",
        "\t\t\t# no box with an IOU greater than zero ...\n",
        "\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_is_box_valid[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\ty_rpn_overlap[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n",
        "\t\t\ty_rpn_regr[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n",
        "\n",
        "\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "\tnum_pos = len(pos_locs[0])\n",
        "\n",
        "\t# one issue is that the RPN has many more negative than positive regions, so we turn off some of the negative\n",
        "\t# regions. We also limit it to 256 regions.\n",
        "\tnum_regions = 256\n",
        "\n",
        "\tif len(pos_locs[0]) > num_regions/2:\n",
        "\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n",
        "\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "\t\tnum_pos = num_regions/2\n",
        "\n",
        "\tif len(neg_locs[0]) + num_pos > num_regions:\n",
        "\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n",
        "\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foL6rVvX2pd5"
      },
      "source": [
        "def get_new_img_size(width, height, img_min_side=300):\n",
        "\tif width <= height:\n",
        "\t\tf = float(img_min_side) / width\n",
        "\t\tresized_height = int(f * height)\n",
        "\t\tresized_width = img_min_side\n",
        "\telse:\n",
        "\t\tf = float(img_min_side) / height\n",
        "\t\tresized_width = int(f * width)\n",
        "\t\tresized_height = img_min_side\n",
        "\n",
        "\treturn resized_width, resized_height\n",
        "\n",
        "def augment(img_data, config, augment=True):\n",
        "\tassert 'filepath' in img_data\n",
        "\tassert 'bboxes' in img_data\n",
        "\tassert 'width' in img_data\n",
        "\tassert 'height' in img_data\n",
        "\n",
        "\timg_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "\timg = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "\tif augment:\n",
        "\t\trows, cols = img.shape[:2]\n",
        "\n",
        "\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\tbbox['x1'] = cols - x2\n",
        "\n",
        "\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\tbbox['y1'] = rows - y2\n",
        "\n",
        "\t\tif config.rot_90:\n",
        "\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n",
        "\t\t\tif angle == 270:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\telif angle == 180:\n",
        "\t\t\t\timg = cv2.flip(img, -1)\n",
        "\t\t\telif angle == 90:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\telif angle == 0:\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tif angle == 270:\n",
        "\t\t\t\t\tbbox['x1'] = y1\n",
        "\t\t\t\t\tbbox['x2'] = y2\n",
        "\t\t\t\t\tbbox['y1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = cols - x1\n",
        "\t\t\t\telif angle == 180:\n",
        "\t\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\t\tbbox['x1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = rows - y2\n",
        "\t\t\t\telif angle == 90:\n",
        "\t\t\t\t\tbbox['x1'] = rows - y2\n",
        "\t\t\t\t\tbbox['x2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = x1\n",
        "\t\t\t\t\tbbox['y2'] = x2        \n",
        "\t\t\t\telif angle == 0:\n",
        "\t\t\t\t\tpass\n",
        "\n",
        "\timg_data_aug['width'] = img.shape[1]\n",
        "\timg_data_aug['height'] = img.shape[0]\n",
        "\treturn img_data_aug, img"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cMr6KVJ2vDk"
      },
      "source": [
        "def get_anchor_gt(all_img_data, C, img_length_calc_function, mode='train'):\n",
        "\t\"\"\" Yield the ground-truth anchors as Y (labels)\n",
        "\t\t\n",
        "\tArgs:\n",
        "\t\tall_img_data: list(filepath, width, height, list(bboxes))\n",
        "\t\tC: config\n",
        "\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n",
        "\t\tmode: 'train' or 'test'; 'train' mode need augmentation\n",
        "\n",
        "\tReturns:\n",
        "\t\tx_img: image data after resized and scaling (smallest size = 300px)\n",
        "\t\tY: [y_rpn_cls, y_rpn_regr]\n",
        "\t\timg_data_aug: augmented image data (original image with augmentation)\n",
        "\t\tdebug_img: show image for debug\n",
        "\t\tnum_pos: show number of positive anchors for debug\n",
        "\t\"\"\"\n",
        "\twhile True:\n",
        "\n",
        "\t\tfor img_data in all_img_data:\n",
        "\t\t\ttry:\n",
        "\n",
        "\t\t\t\t# read in image, and optionally add augmentation\n",
        "\n",
        "\t\t\t\tif mode == 'train':\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=False)\n",
        "\n",
        "\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
        "\t\t\t\t(rows, cols, _) = x_img.shape\n",
        "\n",
        "\t\t\t\tassert cols == width\n",
        "\t\t\t\tassert rows == height\n",
        "\n",
        "\t\t\t\t# get image dimensions for resizing\n",
        "\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\t\t\t\t# resize the image so that smalles side is length = 300px\n",
        "\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t\t\t\tdebug_img = x_img.copy()\n",
        "\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ty_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# Zero-center by mean pixel, and preprocess image\n",
        "\n",
        "\t\t\t\tx_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n",
        "\t\t\t\tx_img = x_img.astype(np.float32)\n",
        "\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n",
        "\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n",
        "\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n",
        "\t\t\t\tx_img /= C.img_scaling_factor\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n",
        "\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n",
        "\n",
        "\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug, debug_img, num_pos\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yJ0U28P23_t"
      },
      "source": [
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "\t# code used from here: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
        "\t# if there are no boxes, return an empty list\n",
        "  \n",
        "    # Process explanation:\n",
        "    #   Step 1: Sort the probs list\n",
        "    #   Step 2: Find the larget prob 'Last' in the list and save it to the pick list\n",
        "    #   Step 3: Calculate the IoU with 'Last' box and other boxes in the list. If the IoU is larger than overlap_threshold, delete the box from list\n",
        "    #   Step 4: Repeat step 2 and step 3 until there is no item in the probs list \n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        "\n",
        "\t# grab the coordinates of the bounding boxes\n",
        "\tx1 = boxes[:, 0]\n",
        "\ty1 = boxes[:, 1]\n",
        "\tx2 = boxes[:, 2]\n",
        "\ty2 = boxes[:, 3]\n",
        "\n",
        "\tnp.testing.assert_array_less(x1, x2)\n",
        "\tnp.testing.assert_array_less(y1, y2)\n",
        "\n",
        "\t# if the bounding boxes integers, convert them to floats --\n",
        "\t# this is important since we'll be doing a bunch of divisions\n",
        "\tif boxes.dtype.kind == \"i\":\n",
        "\t\tboxes = boxes.astype(\"float\")\n",
        "\n",
        "\t# initialize the list of picked indexes\t\n",
        "\tpick = []\n",
        "\n",
        "\t# calculate the areas\n",
        "\tarea = (x2 - x1) * (y2 - y1)\n",
        "\n",
        "\t# sort the bounding boxes \n",
        "\tidxs = np.argsort(probs)\n",
        "\n",
        "\t# keep looping while some indexes still remain in the indexes\n",
        "\t# list\n",
        "\twhile len(idxs) > 0:\n",
        "\t\t# grab the last index in the indexes list and add the\n",
        "\t\t# index value to the list of picked indexes\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        "\n",
        "\t\t# find the intersection\n",
        "\n",
        "\t\txx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "\t\tyy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "\t\txx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "\t\tyy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "\t\tww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "\t\thh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "\t\tarea_int = ww_int * hh_int\n",
        "\n",
        "\t\t# find the union\n",
        "\t\tarea_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "\t\t# compute the ratio of overlap\n",
        "\t\toverlap = area_int/(area_union + 1e-6)\n",
        "\n",
        "\t\t# delete all indexes from the index list that have\n",
        "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
        "\t\t\tnp.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "\t\tif len(pick) >= max_boxes:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t# return only the bounding boxes that were picked using the integer data type\n",
        "\tboxes = boxes[pick].astype(\"int\")\n",
        "\tprobs = probs[pick]\n",
        "\treturn boxes, probs\n",
        "\n",
        "def apply_regr_np(X, T):\n",
        "\t\"\"\"Apply regression layer to all anchors in one feature map\n",
        "\n",
        "\tArgs:\n",
        "\t\tX: shape=(4, 18, 25) the current anchor type for all points in the feature map\n",
        "\t\tT: regression layer shape=(4, 18, 25)\n",
        "\n",
        "\tReturns:\n",
        "\t\tX: regressed position and size for current anchor\n",
        "\t\"\"\"\n",
        "\ttry:\n",
        "\t\tx = X[0, :, :]\n",
        "\t\ty = X[1, :, :]\n",
        "\t\tw = X[2, :, :]\n",
        "\t\th = X[3, :, :]\n",
        "\n",
        "\t\ttx = T[0, :, :]\n",
        "\t\tty = T[1, :, :]\n",
        "\t\ttw = T[2, :, :]\n",
        "\t\tth = T[3, :, :]\n",
        "\n",
        "\t\tcx = x + w/2.\n",
        "\t\tcy = y + h/2.\n",
        "\t\tcx1 = tx * w + cx\n",
        "\t\tcy1 = ty * h + cy\n",
        "\n",
        "\t\tw1 = np.exp(tw.astype(np.float64)) * w\n",
        "\t\th1 = np.exp(th.astype(np.float64)) * h\n",
        "\t\tx1 = cx1 - w1/2.\n",
        "\t\ty1 = cy1 - h1/2.\n",
        "\n",
        "\t\tx1 = np.round(x1)\n",
        "\t\ty1 = np.round(y1)\n",
        "\t\tw1 = np.round(w1)\n",
        "\t\th1 = np.round(h1)\n",
        "\t\treturn np.stack([x1, y1, w1, h1])\n",
        "\texcept Exception as e:\n",
        "\t\tprint(e)\n",
        "\t\treturn X\n",
        "    \n",
        "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
        "    # Apply regression to x, y, w and h\n",
        "\ttry:\n",
        "\t\tcx = x + w/2.\n",
        "\t\tcy = y + h/2.\n",
        "\t\tcx1 = tx * w + cx\n",
        "\t\tcy1 = ty * h + cy\n",
        "\t\tw1 = math.exp(tw) * w\n",
        "\t\th1 = math.exp(th) * h\n",
        "\t\tx1 = cx1 - w1/2.\n",
        "\t\ty1 = cy1 - h1/2.\n",
        "\t\tx1 = int(round(x1))\n",
        "\t\ty1 = int(round(y1))\n",
        "\t\tw1 = int(round(w1))\n",
        "\t\th1 = int(round(h1))\n",
        "\n",
        "\t\treturn x1, y1, w1, h1\n",
        "\n",
        "\texcept ValueError:\n",
        "\t\treturn x, y, w, h\n",
        "\texcept OverflowError:\n",
        "\t\treturn x, y, w, h\n",
        "\texcept Exception as e:\n",
        "\t\tprint(e)\n",
        "\t\treturn x, y, w, h"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0KSv0SM3Ah_"
      },
      "source": [
        "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
        "\t\"\"\"Convert rpn layer to roi bboxes\n",
        "\n",
        "\tArgs: (num_anchors = 9)\n",
        "\t\trpn_layer: output layer for rpn classification \n",
        "\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n",
        "\t\t\tMight be (1, 18, 25, 9) if resized image is 400 width and 300\n",
        "\t\tregr_layer: output layer for rpn regression\n",
        "\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n",
        "\t\t\tMight be (1, 18, 25, 36) if resized image is 400 width and 300\n",
        "\t\tC: config\n",
        "\t\tuse_regr: Wether to use bboxes regression in rpn\n",
        "\t\tmax_boxes: max bboxes number for non-max-suppression (NMS)\n",
        "\t\toverlap_thresh: If iou in NMS is larger than this threshold, drop the box\n",
        "\n",
        "\tReturns:\n",
        "\t\tresult: boxes from non-max-suppression (shape=(300, 4))\n",
        "\t\t\tboxes: coordinates for bboxes (on the feature map)\n",
        "\t\"\"\"\n",
        "\tregr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "\tanchor_sizes = C.anchor_box_scales   # (3 in here)\n",
        "\tanchor_ratios = C.anchor_box_ratios  # (3 in here)\n",
        "\n",
        "\tassert rpn_layer.shape[0] == 1\n",
        "\n",
        "\t(rows, cols) = rpn_layer.shape[1:3]\n",
        "\n",
        "\tcurr_layer = 0\n",
        "\n",
        "\t# A.shape = (4, feature_map.height, feature_map.width, num_anchors) \n",
        "\t# Might be (4, 18, 25, 9) if resized image is 400 width and 300\n",
        "\t# A is the coordinates for 9 anchors for every point in the feature map \n",
        "\t# => all 18x25x9=4050 anchors cooridnates\n",
        "\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
        "\n",
        "\tfor anchor_size in anchor_sizes:\n",
        "\t\tfor anchor_ratio in anchor_ratios:\n",
        "\t\t\t# anchor_x = (128 * 1) / 16 = 8  => width of current anchor\n",
        "\t\t\t# anchor_y = (128 * 2) / 16 = 16 => height of current anchor\n",
        "\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\t\t\t\n",
        "\t\t\t# curr_layer: 0~8 (9 anchors)\n",
        "\t\t\t# the Kth anchor of all position in the feature map (9th in total)\n",
        "\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] # shape => (18, 25, 4)\n",
        "\t\t\tregr = np.transpose(regr, (2, 0, 1)) # shape => (4, 18, 25)\n",
        "\n",
        "\t\t\t# Create 18x25 mesh grid\n",
        "\t\t\t# For every point in x, there are all the y points and vice versa\n",
        "\t\t\t# X.shape = (18, 25)\n",
        "\t\t\t# Y.shape = (18, 25)\n",
        "\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\n",
        "\t\t\t# Calculate anchor position and size for each feature map point\n",
        "\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2 # Top left x coordinate\n",
        "\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2 # Top left y coordinate\n",
        "\t\t\tA[2, :, :, curr_layer] = anchor_x       # width of current anchor\n",
        "\t\t\tA[3, :, :, curr_layer] = anchor_y       # height of current anchor\n",
        "\n",
        "\t\t\t# Apply regression to x, y, w and h if there is rpn regression layer\n",
        "\t\t\tif use_regr:\n",
        "\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
        "\n",
        "\t\t\t# Avoid width and height exceeding 1\n",
        "\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\t# Convert (x, y , w, h) to (x1, y1, x2, y2)\n",
        "\t\t\t# x1, y1 is top left coordinate\n",
        "\t\t\t# x2, y2 is bottom right coordinate\n",
        "\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
        "\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
        "\n",
        "\t\t\t# Avoid bboxes drawn outside the feature map\n",
        "\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
        "\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\tcurr_layer += 1\n",
        "\n",
        "\tall_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  # shape=(4050, 4)\n",
        "\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                   # shape=(4050,)\n",
        "\n",
        "\tx1 = all_boxes[:, 0]\n",
        "\ty1 = all_boxes[:, 1]\n",
        "\tx2 = all_boxes[:, 2]\n",
        "\ty2 = all_boxes[:, 3]\n",
        "\n",
        "\t# Find out the bboxes which is illegal and delete them from bboxes list\n",
        "\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "\n",
        "\tall_boxes = np.delete(all_boxes, idxs, 0)\n",
        "\tall_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "\t# Apply non_max_suppression\n",
        "\t# Only extract the bboxes. Don't need rpn probs in the later process\n",
        "\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "\n",
        "\treturn result"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEPItwKN3ExJ"
      },
      "source": [
        "base_path = '/content/drive/My Drive/Parasite/New/Newlabel'\n",
        "\n",
        "test_path = '/content/drive/My Drive/Parasite/New/Newlabel/test_annotations.txt' # Test data (annotation file)\n",
        "\n",
        "test_base_path = '/content/drive/My Drive/Parasite/New/Newlabel' # Directory to save the test images\n",
        "\n",
        "config_output_filename = '/content/drive/My Drive/Parasite/New/Newlabel/model_vgg_config.pickle'\n",
        "\n",
        "record_path = '/content/drive/My Drive/Parasite/New/Newlabel/record.csv'"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwECiIA0lyyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b60f3f0-e309-4566-9bb7-1ab5c8c6713c"
      },
      "source": [
        "import pickle\n",
        "print(\"t\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDCS3OsZ3ISl"
      },
      "source": [
        "with open(config_output_filename, 'rb+') as f_in:\n",
        "\tC = pickle.load(f_in)\n",
        "\n",
        "# turn off any data augmentation at test time\n",
        "C.use_horizontal_flips = False\n",
        "C.use_vertical_flips = False\n",
        "C.rot_90 = False"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFqV-7t3ucI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6665313f-a4a0-4fd4-b434-be65bd08e693"
      },
      "source": [
        "# Load the records\n",
        "record_df = pd.read_csv(record_path)\n",
        "\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
        "plt.title('mean_overlapping_bboxes')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
        "plt.title('class_acc')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
        "plt.title('loss_rpn_cls')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
        "plt.title('loss_rpn_regr')\n",
        "plt.show()\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "plt.title('loss_class_cls')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
        "plt.title('loss_class_regr')\n",
        "plt.show()\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "plt.title('total_loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['elapsed_time'], 'r')\n",
        "plt.title('elapsed_time')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wrErm6bTi-F"
      },
      "source": [
        "#Test"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9i_nuRP5ymm"
      },
      "source": [
        "def format_img_size(img, C):\n",
        "\t\"\"\" formats the image size based on config \"\"\"\n",
        "\timg_min_side = float(C.im_size)\n",
        "\t(height,width,_) = img.shape\n",
        "\t\t\n",
        "\tif width <= height:\n",
        "\t\tratio = img_min_side/width\n",
        "\t\tnew_height = int(ratio * height)\n",
        "\t\tnew_width = int(img_min_side)\n",
        "\telse:\n",
        "\t\tratio = img_min_side/height\n",
        "\t\tnew_width = int(ratio * width)\n",
        "\t\tnew_height = int(img_min_side)\n",
        "\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\treturn img, ratio\t\n",
        "\n",
        "def format_img_channels(img, C):\n",
        "\t\"\"\" formats the image channels based on config \"\"\"\n",
        "\timg = img[:, :, (2, 1, 0)]\n",
        "\timg = img.astype(np.float32)\n",
        "\timg[:, :, 0] -= C.img_channel_mean[0]\n",
        "\timg[:, :, 1] -= C.img_channel_mean[1]\n",
        "\timg[:, :, 2] -= C.img_channel_mean[2]\n",
        "\timg /= C.img_scaling_factor\n",
        "\timg = np.transpose(img, (2, 0, 1))\n",
        "\timg = np.expand_dims(img, axis=0)\n",
        "\treturn img\n",
        "\n",
        "def format_img(img, C):\n",
        "\t\"\"\" formats an image for model prediction based on config \"\"\"\n",
        "\timg, ratio = format_img_size(img, C)\n",
        "\timg = format_img_channels(img, C)\n",
        "\treturn img, ratio\n",
        "\n",
        "# Method to transform the coordinates of the bounding box to its original size\n",
        "def get_real_coordinates(ratio, x1, y1, x2, y2):\n",
        "\n",
        "\treal_x1 = int(round(x1 // ratio))\n",
        "\treal_y1 = int(round(y1 // ratio))\n",
        "\treal_x2 = int(round(x2 // ratio))\n",
        "\treal_y2 = int(round(y2 // ratio))\n",
        "\n",
        "\treturn (real_x1, real_y1, real_x2 ,real_y2)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV_xkn8hQDgq"
      },
      "source": [
        "WEIGHTS_PATH = ('https://storage.googleapis.com/tensorflow/keras-applications/'\n",
        "                'vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lG0-nKMQDgr"
      },
      "source": [
        "C.model_path = data_utils.get_file(\n",
        "          'vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "          WEIGHTS_PATH,\n",
        "          cache_subdir='models',\n",
        "          file_hash='64373286793e3c8b2b4e3219cbf3544b')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSdVdCDtIknq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7667ffb-1f74-49c4-9019-e9b10c42d9d1"
      },
      "source": [
        "num_features = 512\n",
        "\n",
        "input_shape_img = (None, None, 3)\n",
        "input_shape_features = (None, None, num_features)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(C.num_rois, 4))\n",
        "feature_map_input = Input(shape=input_shape_features)\n",
        "\n",
        "# define the base network (VGG here, can be Resnet50, Inception, etc)\n",
        "shared_layers = nn_base(img_input, trainable=True)\n",
        "\n",
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn_layers = rpn_layer(shared_layers, num_anchors) \n",
        "\n",
        "classifier = classifier_layer(feature_map_input, roi_input, C.num_rois, nb_classes=len(C.class_mapping))\n",
        "\n",
        "model_rpn = Model(img_input, rpn_layers)\n",
        "model_classifier_only = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "model_classifier = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "print('Loading weights from {}'.format(C.model_path))\n",
        "model_rpn.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "\n",
        "model_rpn.compile(optimizer='sgd', loss='mse')\n",
        "model_classifier.compile(optimizer='sgd', loss='mse')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from /root/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOSYRrCeToGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34f55c3-7201-49af-c3ce-eb18f7d1e819"
      },
      "source": [
        "# Switch key value for class mapping\n",
        "class_mapping = C.class_mapping\n",
        "class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "print(class_mapping)\n",
        "class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Echinostoma', 1: 'Ov', 2: 'Taenia', 3: 'Hookworm', 4: 'Ascaris', 5: 'Mif', 6: 'bg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qvaSudNTub2"
      },
      "source": [
        "test_imgs = os.listdir(test_base_path)\n",
        "\n",
        "imgs_path = []\n",
        "for i in range(12):\n",
        "\tidx = np.random.randint(len(test_imgs))\n",
        "\timgs_path.append(test_imgs[idx])\n",
        "\n",
        "all_imgs = []\n",
        "\n",
        "classes = {}"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_urWS_0UUs0"
      },
      "source": [
        "# If the box classification value is less than this, we ignore this box\n",
        "bbox_threshold = 0.7\n",
        "\n",
        "for idx, img_name in enumerate(imgs_path):\n",
        "    if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
        "        continue\n",
        "    print(img_name)\n",
        "    st = time.time()\n",
        "    filepath = os.path.join(test_base_path, img_name)\n",
        "\n",
        "    img = cv2.imread(filepath)\n",
        "\n",
        "    X, ratio = format_img(img, C)\n",
        "    \n",
        "    X = np.transpose(X, (0, 2, 3, 1))\n",
        "\n",
        "    # get output layer Y1, Y2 from the RPN and the feature maps F\n",
        "    # Y1: y_rpn_cls\n",
        "    # Y2: y_rpn_regr\n",
        "    [Y1, Y2, F] = model_rpn.predict(X)\n",
        "\n",
        "    # Get bboxes by applying NMS \n",
        "    # R.shape = (300, 4)\n",
        "    R = rpn_to_roi(Y1, Y2, C, K.image_data_format(), overlap_thresh=0.7)\n",
        "\n",
        "    # convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
        "    R[:, 2] -= R[:, 0]\n",
        "    R[:, 3] -= R[:, 1]\n",
        "\n",
        "    # apply the spatial pyramid pooling to the proposed regions\n",
        "    bboxes = {}\n",
        "    probs = {}\n",
        "\n",
        "    for jk in range(R.shape[0]//C.num_rois + 1):\n",
        "        ROIs = np.expand_dims(R[C.num_rois*jk:C.num_rois*(jk+1), :], axis=0)\n",
        "        if ROIs.shape[1] == 0:\n",
        "            break\n",
        "\n",
        "        if jk == R.shape[0]//C.num_rois:\n",
        "            #pad R\n",
        "            curr_shape = ROIs.shape\n",
        "            target_shape = (curr_shape[0],C.num_rois,curr_shape[2])\n",
        "            ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
        "            ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
        "            ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
        "            ROIs = ROIs_padded\n",
        "\n",
        "        [P_cls, P_regr] = model_classifier_only.predict([F, ROIs])\n",
        "\n",
        "        # Calculate bboxes coordinates on resized image\n",
        "        for ii in range(P_cls.shape[1]):\n",
        "            # Ignore 'bg' class\n",
        "            if np.max(P_cls[0, ii, :]) < bbox_threshold or np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
        "                continue\n",
        "\n",
        "            cls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
        "\n",
        "            if cls_name not in bboxes:\n",
        "                bboxes[cls_name] = []\n",
        "                probs[cls_name] = []\n",
        "\n",
        "            (x, y, w, h) = ROIs[0, ii, :]\n",
        "\n",
        "            cls_num = np.argmax(P_cls[0, ii, :])\n",
        "            try:\n",
        "                (tx, ty, tw, th) = P_regr[0, ii, 4*cls_num:4*(cls_num+1)]\n",
        "                tx /= C.classifier_regr_std[0]\n",
        "                ty /= C.classifier_regr_std[1]\n",
        "                tw /= C.classifier_regr_std[2]\n",
        "                th /= C.classifier_regr_std[3]\n",
        "                x, y, w, h = apply_regr(x, y, w, h, tx, ty, tw, th)\n",
        "            except:\n",
        "                pass\n",
        "            bboxes[cls_name].append([C.rpn_stride*x, C.rpn_stride*y, C.rpn_stride*(x+w), C.rpn_stride*(y+h)])\n",
        "            probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
        "\n",
        "    all_dets = []\n",
        "\n",
        "    for key in bboxes:\n",
        "        bbox = np.array(bboxes[key])\n",
        "\n",
        "        new_boxes, new_probs = non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.2)\n",
        "        for jk in range(new_boxes.shape[0]):\n",
        "            (x1, y1, x2, y2) = new_boxes[jk,:]\n",
        "\n",
        "            # Calculate real coordinates on original image\n",
        "            (real_x1, real_y1, real_x2, real_y2) = get_real_coordinates(ratio, x1, y1, x2, y2)\n",
        "\n",
        "            cv2.rectangle(img,(real_x1, real_y1), (real_x2, real_y2), (int(class_to_color[key][0]), int(class_to_color[key][1]), int(class_to_color[key][2])),4)\n",
        "\n",
        "            textLabel = '{}: {}'.format(key,int(100*new_probs[jk]))\n",
        "            all_dets.append((key,100*new_probs[jk]))\n",
        "\n",
        "            (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,1,1)\n",
        "            textOrg = (real_x1, real_y1-0)\n",
        "\n",
        "            cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 1)\n",
        "            cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
        "            cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 1)\n",
        "\n",
        "    print('Elapsed time = {}'.format(time.time() - st))\n",
        "    print(all_dets)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.grid()\n",
        "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1o49C67YwUF"
      },
      "source": [
        "def get_map(pred, gt, f):\n",
        "\tT = {}\n",
        "\tP = {}\n",
        "\tfx, fy = f\n",
        "\n",
        "\tfor bbox in gt:\n",
        "\t\tbbox['bbox_matched'] = False\n",
        "\n",
        "\tpred_probs = np.array([s['prob'] for s in pred])\n",
        "\tbox_idx_sorted_by_prob = np.argsort(pred_probs)[::-1]\n",
        "\n",
        "\tfor box_idx in box_idx_sorted_by_prob:\n",
        "\t\tpred_box = pred[box_idx]\n",
        "\t\tpred_class = pred_box['class']\n",
        "\t\tpred_x1 = pred_box['x1']\n",
        "\t\tpred_x2 = pred_box['x2']\n",
        "\t\tpred_y1 = pred_box['y1']\n",
        "\t\tpred_y2 = pred_box['y2']\n",
        "\t\tpred_prob = pred_box['prob']\n",
        "\t\tif pred_class not in P:\n",
        "\t\t\tP[pred_class] = []\n",
        "\t\t\tT[pred_class] = []\n",
        "\t\tP[pred_class].append(pred_prob)\n",
        "\t\tfound_match = False\n",
        "\n",
        "\t\tfor gt_box in gt:\n",
        "\t\t\tgt_class = gt_box['class']\n",
        "\t\t\tgt_x1 = gt_box['x1']/fx\n",
        "\t\t\tgt_x2 = gt_box['x2']/fx\n",
        "\t\t\tgt_y1 = gt_box['y1']/fy\n",
        "\t\t\tgt_y2 = gt_box['y2']/fy\n",
        "\t\t\tgt_seen = gt_box['bbox_matched']\n",
        "\t\t\tif gt_class != pred_class:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif gt_seen:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tiou_map = iou((pred_x1, pred_y1, pred_x2, pred_y2), (gt_x1, gt_y1, gt_x2, gt_y2))\n",
        "\t\t\tif iou_map >= 0.5:\n",
        "\t\t\t\tfound_match = True\n",
        "\t\t\t\tgt_box['bbox_matched'] = True\n",
        "\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\tT[pred_class].append(int(found_match))\n",
        "\n",
        "\tfor gt_box in gt:\n",
        "\t\tif not gt_box['bbox_matched']:# and not gt_box['difficult']:\n",
        "\t\t\tif gt_box['class'] not in P:\n",
        "\t\t\t\tP[gt_box['class']] = []\n",
        "\t\t\t\tT[gt_box['class']] = []\n",
        "\n",
        "\t\t\tT[gt_box['class']].append(1)\n",
        "\t\t\tP[gt_box['class']].append(0)\n",
        "\n",
        "\t#import pdb\n",
        "\t#pdb.set_trace()\n",
        "\treturn T, P\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcQ_IDNDY6YR"
      },
      "source": [
        "def format_img_map(img, C):\n",
        "\t\"\"\"Format image for mAP. Resize original image to C.im_size (300 in here)\n",
        "\n",
        "\tArgs:\n",
        "\t\timg: cv2 image\n",
        "\t\tC: config\n",
        "\n",
        "\tReturns:\n",
        "\t\timg: Scaled and normalized image with expanding dimension\n",
        "\t\tfx: ratio for width scaling\n",
        "\t\tfy: ratio for height scaling\n",
        "\t\"\"\"\n",
        "\n",
        "\timg_min_side = float(C.im_size)\n",
        "\t(height,width,_) = img.shape\n",
        "\t\n",
        "\tif width <= height:\n",
        "\t\tf = img_min_side/width\n",
        "\t\tnew_height = int(f * height)\n",
        "\t\tnew_width = int(img_min_side)\n",
        "\telse:\n",
        "\t\tf = img_min_side/height\n",
        "\t\tnew_width = int(f * width)\n",
        "\t\tnew_height = int(img_min_side)\n",
        "\tfx = width/float(new_width)\n",
        "\tfy = height/float(new_height)\n",
        "\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t# Change image channel from BGR to RGB\n",
        "\timg = img[:, :, (2, 1, 0)]\n",
        "\timg = img.astype(np.float32)\n",
        "\timg[:, :, 0] -= C.img_channel_mean[0]\n",
        "\timg[:, :, 1] -= C.img_channel_mean[1]\n",
        "\timg[:, :, 2] -= C.img_channel_mean[2]\n",
        "\timg /= C.img_scaling_factor\n",
        "\t# Change img shape from (height, width, channel) to (channel, height, width)\n",
        "\timg = np.transpose(img, (2, 0, 1))\n",
        "\t# Expand one dimension at axis 0\n",
        "\t# img shape becames (1, channel, height, width)\n",
        "\timg = np.expand_dims(img, axis=0)\n",
        "\treturn img, fx, fy"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WV0zrdmY718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30c465e-484f-4c7f-a2ca-3752d375888f"
      },
      "source": [
        "print(class_mapping)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Echinostoma', 1: 'Ov', 2: 'Taenia', 3: 'Hookworm', 4: 'Ascaris', 5: 'Mif', 6: 'bg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc3kIWEdY_3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aaea0c5-7eea-4689-b64f-9ad07f7326c4"
      },
      "source": [
        "# This might takes a while to parser the data\n",
        "test_imgs, _, _ = get_data(test_path)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing annotation files\n",
            "idx=126"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mx3EiArZD8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b6d8a0-97ee-488e-a180-d1d8cd1c8b67"
      },
      "source": [
        "T = {}\n",
        "P = {}\n",
        "mAPs = []\n",
        "for idx, img_data in enumerate(test_imgs):\n",
        "    print('{}/{}'.format(idx,len(test_imgs)))\n",
        "    st = time.time()\n",
        "    filepath = img_data['filepath']\n",
        "\n",
        "    img = cv2.imread(filepath)\n",
        "\n",
        "    X, fx, fy = format_img_map(img, C)\n",
        "\n",
        "    # Change X (img) shape from (1, channel, height, width) to (1, height, width, channel)\n",
        "    X = np.transpose(X, (0, 2, 3, 1))\n",
        "\n",
        "    # get the feature maps and output from the RPN\n",
        "    [Y1, Y2, F] = model_rpn.predict(X)\n",
        "\n",
        "\n",
        "    R = rpn_to_roi(Y1, Y2, C, K.image_data_format(), overlap_thresh=0.7)\n",
        "\n",
        "    # convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
        "    R[:, 2] -= R[:, 0]\n",
        "    R[:, 3] -= R[:, 1]\n",
        "\n",
        "    # apply the spatial pyramid pooling to the proposed regions\n",
        "    bboxes = {}\n",
        "    probs = {}\n",
        "\n",
        "    for jk in range(R.shape[0] // C.num_rois + 1):\n",
        "        ROIs = np.expand_dims(R[C.num_rois * jk:C.num_rois * (jk + 1), :], axis=0)\n",
        "        if ROIs.shape[1] == 0:\n",
        "            break\n",
        "\n",
        "        if jk == R.shape[0] // C.num_rois:\n",
        "            # pad R\n",
        "            curr_shape = ROIs.shape\n",
        "            target_shape = (curr_shape[0], C.num_rois, curr_shape[2])\n",
        "            ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
        "            ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
        "            ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
        "            ROIs = ROIs_padded\n",
        "\n",
        "        [P_cls, P_regr] = model_classifier_only.predict([F, ROIs])\n",
        "\n",
        "        # Calculate all classes' bboxes coordinates on resized image (300, 400)\n",
        "        # Drop 'bg' classes bboxes\n",
        "        for ii in range(P_cls.shape[1]):\n",
        "\n",
        "            # If class name is 'bg', continue\n",
        "            if np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
        "                continue\n",
        "\n",
        "            # Get class name\n",
        "            cls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
        "\n",
        "            if cls_name not in bboxes:\n",
        "                bboxes[cls_name] = []\n",
        "                probs[cls_name] = []\n",
        "\n",
        "            (x, y, w, h) = ROIs[0, ii, :]\n",
        "\n",
        "            cls_num = np.argmax(P_cls[0, ii, :])\n",
        "            try:\n",
        "                (tx, ty, tw, th) = P_regr[0, ii, 4 * cls_num:4 * (cls_num + 1)]\n",
        "                tx /= C.classifier_regr_std[0]\n",
        "                ty /= C.classifier_regr_std[1]\n",
        "                tw /= C.classifier_regr_std[2]\n",
        "                th /= C.classifier_regr_std[3]\n",
        "                x, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
        "            except:\n",
        "                pass\n",
        "            bboxes[cls_name].append([16 * x, 16 * y, 16 * (x + w), 16 * (y + h)])\n",
        "            probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
        "\n",
        "    all_dets = []\n",
        "\n",
        "    for key in bboxes:\n",
        "        bbox = np.array(bboxes[key])\n",
        "\n",
        "        # Apply non-max-suppression on final bboxes to get the output bounding boxe\n",
        "        new_boxes, new_probs = non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n",
        "        for jk in range(new_boxes.shape[0]):\n",
        "            (x1, y1, x2, y2) = new_boxes[jk, :]\n",
        "            det = {'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'class': key, 'prob': new_probs[jk]}\n",
        "            all_dets.append(det)\n",
        "\n",
        "\n",
        "    print('Elapsed time = {}'.format(time.time() - st))\n",
        "    t, p = get_map(all_dets, img_data['bboxes'], (fx, fy))\n",
        "    for key in t.keys():\n",
        "        if key not in T:\n",
        "            #print(key)\n",
        "            T[key] = []\n",
        "            P[key] = []\n",
        "        T[key].extend(t[key])\n",
        "        P[key].extend(p[key])\n",
        "    all_aps = []\n",
        "    for key in T.keys():\n",
        "        if key != 'bg' and key != 'leukocyte':\n",
        "            #print(key)\n",
        "            ap = average_precision_score(T[key], P[key])\n",
        "            print('{} AP: {}'.format(key, ap))\n",
        "            all_aps.append(ap)\n",
        "    print('mAP = {}'.format(np.mean(np.array(all_aps))))\n",
        "    mAPs.append(np.mean(np.array(all_aps)))\n",
        "    #print(T)\n",
        "    #print(P)\n",
        "    \n",
        "print()\n",
        "print('mean average precision:', np.mean(np.array(mAPs)))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/107\n",
            "Elapsed time = 15.306304931640625\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "mAP = nan\n",
            "1/107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time = 14.536460638046265\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "2/107\n",
            "Elapsed time = 15.151074409484863\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "3/107\n",
            "Elapsed time = 14.166215419769287\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "4/107\n",
            "Elapsed time = 14.61729884147644\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "5/107\n",
            "Elapsed time = 14.125332832336426\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "6/107\n",
            "Elapsed time = 14.10250473022461\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "7/107\n",
            "Elapsed time = 14.987008571624756\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "8/107\n",
            "Elapsed time = 15.580138921737671\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "9/107\n",
            "Elapsed time = 14.9436514377594\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "10/107\n",
            "Elapsed time = 14.107709169387817\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "11/107\n",
            "Elapsed time = 13.9851553440094\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "12/107\n",
            "Elapsed time = 13.595796585083008\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "13/107\n",
            "Elapsed time = 13.834997653961182\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "14/107\n",
            "Elapsed time = 15.62084174156189\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "15/107\n",
            "Elapsed time = 14.976486206054688\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "16/107\n",
            "Elapsed time = 13.340503215789795\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "17/107\n",
            "Elapsed time = 13.383866310119629\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "18/107\n",
            "Elapsed time = 13.732994794845581\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "19/107\n",
            "Elapsed time = 13.418923139572144\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "20/107\n",
            "Elapsed time = 12.946344375610352\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "21/107\n",
            "Elapsed time = 13.73257040977478\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "22/107\n",
            "Elapsed time = 13.624517440795898\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "23/107\n",
            "Elapsed time = 13.660915851593018\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "24/107\n",
            "Elapsed time = 13.554807662963867\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "25/107\n",
            "Elapsed time = 13.413248538970947\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "26/107\n",
            "Elapsed time = 13.737666606903076\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "27/107\n",
            "Elapsed time = 13.697482109069824\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "28/107\n",
            "Elapsed time = 13.597005605697632\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "29/107\n",
            "Elapsed time = 12.40852665901184\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "30/107\n",
            "Elapsed time = 12.407580137252808\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "31/107\n",
            "Elapsed time = 12.363019943237305\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "32/107\n",
            "Elapsed time = 12.4917471408844\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "mAP = nan\n",
            "33/107\n",
            "Elapsed time = 12.423292875289917\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "34/107\n",
            "Elapsed time = 12.4258131980896\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "35/107\n",
            "Elapsed time = 12.680335760116577\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "36/107\n",
            "Elapsed time = 15.25962519645691\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "37/107\n",
            "Elapsed time = 12.698590278625488\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "38/107\n",
            "Elapsed time = 12.624531030654907\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "39/107\n",
            "Elapsed time = 12.648618936538696\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "40/107\n",
            "Elapsed time = 12.741847515106201\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "41/107\n",
            "Elapsed time = 13.161460876464844\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "42/107\n",
            "Elapsed time = 13.137748003005981\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "43/107\n",
            "Elapsed time = 13.089156866073608\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "mAP = nan\n",
            "44/107\n",
            "Elapsed time = 13.493279218673706\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "45/107\n",
            "Elapsed time = 13.468600749969482\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "46/107\n",
            "Elapsed time = 13.647376775741577\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "47/107\n",
            "Elapsed time = 13.433670997619629\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "48/107\n",
            "Elapsed time = 13.797948360443115\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "49/107\n",
            "Elapsed time = 13.561368942260742\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "50/107\n",
            "Elapsed time = 13.934306383132935\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "51/107\n",
            "Elapsed time = 15.092728614807129\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "52/107\n",
            "Elapsed time = 14.597593307495117\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "53/107\n",
            "Elapsed time = 15.124170541763306\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "54/107\n",
            "Elapsed time = 15.165325164794922\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "55/107\n",
            "Elapsed time = 15.202211618423462\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "56/107\n",
            "Elapsed time = 14.85047698020935\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "57/107\n",
            "Elapsed time = 14.95291543006897\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "58/107\n",
            "Elapsed time = 14.931533098220825\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "59/107\n",
            "Elapsed time = 15.02986741065979\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "60/107\n",
            "Elapsed time = 14.532766103744507\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "61/107\n",
            "Elapsed time = 14.642300128936768\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "62/107\n",
            "Elapsed time = 15.395055532455444\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "63/107\n",
            "Elapsed time = 14.981923818588257\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "64/107\n",
            "Elapsed time = 14.724722146987915\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "65/107\n",
            "Elapsed time = 14.78505539894104\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "66/107\n",
            "Elapsed time = 15.32319974899292\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "67/107\n",
            "Elapsed time = 13.923757076263428\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "68/107\n",
            "Elapsed time = 13.848141431808472\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "69/107\n",
            "Elapsed time = 15.444891452789307\n",
            "Echinostoma AP: nan\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = nan\n",
            "70/107\n",
            "Elapsed time = 14.162694454193115\n",
            "Echinostoma AP: 4.697702823319397e-05\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000093954056468\n",
            "71/107\n",
            "Elapsed time = 13.643344402313232\n",
            "Echinostoma AP: 6.9484119051709e-05\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000138968238103\n",
            "72/107\n",
            "Elapsed time = 14.369683980941772\n",
            "Echinostoma AP: 0.00010659983520556482\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000213199670412\n",
            "73/107\n",
            "Elapsed time = 14.273673057556152\n",
            "Echinostoma AP: 0.0001464638938070605\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000292927787613\n",
            "74/107\n",
            "Elapsed time = 14.58158254623413\n",
            "Echinostoma AP: 0.0001867429450051417\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000373485890011\n",
            "75/107\n",
            "Elapsed time = 14.589012861251831\n",
            "Echinostoma AP: 0.00022668933122261774\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000453378662445\n",
            "76/107\n",
            "Elapsed time = 14.938669204711914\n",
            "Echinostoma AP: 0.00026600676696411543\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000532013533928\n",
            "77/107\n",
            "Elapsed time = 14.885858297348022\n",
            "Echinostoma AP: 0.00030456687244370006\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000609133744888\n",
            "78/107\n",
            "Elapsed time = 16.64273190498352\n",
            "Echinostoma AP: 0.0003423147768539999\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000684629553708\n",
            "79/107\n",
            "Elapsed time = 14.334402322769165\n",
            "Echinostoma AP: 0.00037923143525268833\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000758462870505\n",
            "80/107\n",
            "Elapsed time = 14.751140117645264\n",
            "Echinostoma AP: 0.00041531656262429605\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000830633125249\n",
            "81/107\n",
            "Elapsed time = 14.368172645568848\n",
            "Echinostoma AP: 0.0004505801535046807\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "mAP = 0.8000901160307009\n",
            "82/107\n",
            "Elapsed time = 14.37058401107788\n",
            "Echinostoma AP: 0.00044515102283259093\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334075251704721\n",
            "83/107\n",
            "Elapsed time = 14.77731966972351\n",
            "Echinostoma AP: 0.000439851167861323\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334066418613103\n",
            "84/107\n",
            "Elapsed time = 14.674837827682495\n",
            "Echinostoma AP: 0.0004346760255463716\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334057793375912\n",
            "85/107\n",
            "Elapsed time = 14.549647808074951\n",
            "Echinostoma AP: 0.0004296212450949954\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334049368741825\n",
            "86/107\n",
            "Elapsed time = 14.100643873214722\n",
            "Echinostoma AP: 0.00042471522359203843\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.833404119203932\n",
            "87/107\n",
            "Elapsed time = 14.427898406982422\n",
            "Echinostoma AP: 0.0004198881677259928\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.833403314694621\n",
            "88/107\n",
            "Elapsed time = 13.750545501708984\n",
            "Echinostoma AP: 0.00041521626226273057\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334025360437104\n",
            "89/107\n",
            "Elapsed time = 13.637815475463867\n",
            "Echinostoma AP: 0.00041060153768011936\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334017669229468\n",
            "90/107\n",
            "Elapsed time = 14.436235904693604\n",
            "Echinostoma AP: 0.00040608826193604775\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334010147103227\n",
            "91/107\n",
            "Elapsed time = 14.749230146408081\n",
            "Echinostoma AP: 0.000401673126067054\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334002788543445\n",
            "92/107\n",
            "Elapsed time = 14.523060321807861\n",
            "Echinostoma AP: 0.00039735296346682516\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8333995588272445\n",
            "93/107\n",
            "Elapsed time = 13.788364887237549\n",
            "Echinostoma AP: 0.00039312474231210595\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8333988541237187\n",
            "94/107\n",
            "Elapsed time = 13.620525121688843\n",
            "Echinostoma AP: 0.0003889855584670903\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8333981642597444\n",
            "95/107\n",
            "Elapsed time = 13.42727518081665\n",
            "Echinostoma AP: 0.00045394897842180785\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334089914964036\n",
            "96/107\n",
            "Elapsed time = 14.07929015159607\n",
            "Echinostoma AP: 0.0004492682763653485\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334082113793942\n",
            "97/107\n",
            "Elapsed time = 13.589939832687378\n",
            "Echinostoma AP: 0.0004446831153202856\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334074471858868\n",
            "98/107\n",
            "Elapsed time = 13.85945463180542\n",
            "Echinostoma AP: 0.0004401905996100297\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334066984332683\n",
            "99/107\n",
            "Elapsed time = 13.490371465682983\n",
            "Echinostoma AP: 0.0004357879494046375\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334059646582341\n",
            "100/107\n",
            "Elapsed time = 13.870070457458496\n",
            "Echinostoma AP: 0.0004314724949848696\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334052454158307\n",
            "101/107\n",
            "Elapsed time = 13.615005016326904\n",
            "Echinostoma AP: 0.0004272416713437123\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334045402785573\n",
            "102/107\n",
            "Elapsed time = 13.399485349655151\n",
            "Echinostoma AP: 0.000423093013102425\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334038488355171\n",
            "103/107\n",
            "Elapsed time = 14.22404932975769\n",
            "Echinostoma AP: 0.0004190241497199415\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.83340317069162\n",
            "104/107\n",
            "Elapsed time = 14.096149682998657\n",
            "Echinostoma AP: 0.0004150328009760624\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334025054668294\n",
            "105/107\n",
            "Elapsed time = 13.953247308731079\n",
            "Echinostoma AP: 0.0004111167727103578\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334018527954518\n",
            "106/107\n",
            "Elapsed time = 14.866092920303345\n",
            "Echinostoma AP: 0.0004072739528000471\n",
            "Ov AP: 1.0\n",
            "Taenia AP: 1.0\n",
            "Mif AP: 1.0\n",
            "Ascaris AP: 1.0\n",
            "Hookworm AP: 1.0\n",
            "mAP = 0.8334012123254667\n",
            "\n",
            "mean average precision: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tc7DKV1ZXpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ed7f4f-ae44-4661-949d-7bb0afbbf4b7"
      },
      "source": [
        "mAP = [mAP for mAP in mAPs if str(mAP)!='nan']\n",
        "mean_average_prec = round(np.mean(np.array(mAP)), 3)\n",
        "print('After training %dk batches, the mean average precision is %0.3f'%(len(record_df), mean_average_prec))\n",
        "\n",
        "# record_df.loc[len(record_df)-1, 'mAP'] = mean_average_prec\n",
        "# record_df.to_csv(C.record_path, index=0)\n",
        "# print('Save mAP to {}'.format(C.record_path))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After training 164k batches, the mean average precision is 0.823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ezl8xgRdhf7",
        "outputId": "9c926afb-ab49-429a-e1fb-9f61e7a29bff"
      },
      "source": [
        "T.keys()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Echinostoma', 'Ov', 'Taenia', 'Mif', 'Ascaris', 'Hookworm'])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "CBxr3KIRDRNs",
        "outputId": "480af380-85ba-4c10-e5ef-cda1c3fa643b"
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(T, P)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-ca1e46f5aa63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m     80\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 241\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0msparse_pandas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SparseSeries'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SparseArray'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got {'Echinostoma': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrF7tXsQWa-i"
      },
      "source": [
        "# Recall\n",
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_true, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6s-8_fuWdrK"
      },
      "source": [
        "# Precision\n",
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_true, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3B5qHD1DYRl"
      },
      "source": [
        "# Method 1: sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_true, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nutsudapenpong/DPDM/blob/master/projecttrymydata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pEoHjnXaqlE"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from keras import initializers, regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAsZHL5PiptM"
      },
      "source": [
        "#Config setting\n",
        "#This is a config class where we initiate the base model to use, anchor_box_scales-adjusted as per the bounding boxes of the objects in the image, number of rois(region of interests) to return at once, image augmentation and various other parameters."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l40u_wP_i1IK"
      },
      "source": [
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\t# Print the process or not\n",
        "\t\tself.verbose = True\n",
        "\n",
        "\t\t# Name of base network\n",
        "\t\tself.network = 'vgg'\n",
        "\n",
        "\t\t# Setting for data augmentation\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\t# Anchor box scales\n",
        "    # Note that if im_size is smaller, anchor_box_scales should be scaled\n",
        "    # Original anchor_box_scales in the paper is [128, 256, 512]\n",
        "\t\tself.anchor_box_scales = [8,16,32] \n",
        "\n",
        "\t\t# Anchor box ratios\n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "\t\t# Size to resize the smallest side of the image\n",
        "\t\t# Original setting in paper is 600. Set to 300 in here to save training time\n",
        "\t\tself.im_size = 300\n",
        "\n",
        "\t\t# image channel-wise mean to subtract\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "\n",
        "\t\t# number of ROIs at once\n",
        "\t\tself.num_rois = 4\n",
        "\n",
        "\t\t# stride at the RPN (this depends on the network configuration)\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\t# scaling the stdev\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\t# overlaps for RPN\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\t# overlaps for classifier ROIs\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\n",
        "\t\t# placeholder for the class mapping, automatically generated by the parser\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\tself.model_path = None"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccRFoL7EjFcH"
      },
      "source": [
        "#Parse the data from annotation file\n",
        "#Based on the annotation file input, number of classes and the bounding box information will be extracted."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc0Gsd0WjJtm"
      },
      "source": [
        "def get_data(input_path):\n",
        "\t\"\"\"Parse the data from annotation file\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tinput_path: annotation file path\n",
        "\n",
        "\tReturns:\n",
        "\t\tall_data: list(filepath, width, height, list(bboxes))\n",
        "\t\tclasses_count: dict{key:class_name, value:count_num} \n",
        "\t\t\te.g. {'red blood cell': 77420, 'trophozoite': 1473, 'difficult': 441, 'ring': 353,'schizont':179, 'gametocyte':144,\n",
        "            'leukocyte':103}\n",
        "\t\tclass_mapping: dict{key:class_name, value: idx}\n",
        "\t\t\te.g. {'red blood cell': 0, 'trophozoite': 1, 'difficult': 2, 'ring': 3,'schizont':4, 'gametocyte':5,\n",
        "            'leukocyte':6}\n",
        "\t\"\"\"\n",
        "\tfound_bg = False\n",
        "\tall_imgs = {}\n",
        "\n",
        "\tclasses_count = {}\n",
        "\n",
        "\tclass_mapping = {}\n",
        "\n",
        "\tvisualise = True\n",
        "\n",
        "\ti = 1\n",
        "\t\n",
        "\twith open(input_path,'r') as f:\n",
        "\n",
        "\t\tprint('Parsing annotation files')\n",
        "\n",
        "\t\tfor line in f:\n",
        "\n",
        "\t\t\t# Print process\n",
        "\t\t\tsys.stdout.write('\\r'+'idx=' + str(i))\n",
        "\t\t\ti += 1\n",
        "\n",
        "\t\t\tline_split = line.strip().split(',')\n",
        "   \t\t\n",
        "      # Make sure the info saved in annotation file matching the format (path_filename, x1, y1, x2, y2, class_name)\n",
        "\t\t\t# Note:\n",
        "\t\t\t#\tOne path_filename might has several classes (class_name)\n",
        "\t\t\t#\tx1, y1, x2, y2 are the pixel value of the origial image, not the ratio value\n",
        "\t\t\t#\t(x1, y1) top left coordinates; (x2, y2) bottom right coordinates\n",
        "\t\t\t#   x1,y1-------------------\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t|\t\t\t\t\t\t|\n",
        "\t\t\t#\t---------------------x2,y2\n",
        "\n",
        "\t\t\t(filename,x1,y1,x2,y2,class_name) = line_split\n",
        "\n",
        "\t\t\tif class_name not in classes_count:\n",
        "\t\t\t\tclasses_count[class_name] = 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tclasses_count[class_name] += 1\n",
        "\n",
        "\t\t\tif class_name not in class_mapping:\n",
        "\t\t\t\tif class_name == 'bg' and found_bg == False:\n",
        "\t\t\t\t\tprint('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
        "\t\t\t\t\tfound_bg = True\n",
        "\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "\t\t\tif filename not in all_imgs:\n",
        "\t\t\t\tall_imgs[filename] = {}\n",
        "\t\t\t\t\n",
        "\t\t\t\timg = cv2.imread(filename)\n",
        "\t\t\t\t(rows,cols) = img.shape[:2]\n",
        "\t\t\t\tall_imgs[filename]['filepath'] = filename\n",
        "\t\t\t\tall_imgs[filename]['width'] = cols\n",
        "\t\t\t\tall_imgs[filename]['height'] = rows\n",
        "\t\t\t\tall_imgs[filename]['bboxes'] = []\n",
        "\t\t\t\t# if np.random.randint(0,6) > 0:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'trainval'\n",
        "\t\t\t\t# else:\n",
        "\t\t\t\t# \tall_imgs[filename]['imageset'] = 'test'\n",
        "\n",
        "\t\t\tall_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
        "   \n",
        "\n",
        "\t\tall_data = []\n",
        "\t\tfor key in all_imgs:\n",
        "\t\t\tall_data.append(all_imgs[key])\n",
        "\t\t\n",
        "\t\t# make sure the bg class is last in the list\n",
        "\t\tif found_bg:\n",
        "\t\t\tif class_mapping['bg'] != len(class_mapping) - 1:\n",
        "\t\t\t\tkey_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
        "\t\t\t\tval_to_switch = class_mapping['bg']\n",
        "\t\t\t\tclass_mapping['bg'] = len(class_mapping) - 1\n",
        "\t\t\t\tclass_mapping[key_to_switch] = val_to_switch\n",
        "\t\t\n",
        "\t\treturn all_data, classes_count, class_mapping"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7AUTfh1jqm4"
      },
      "source": [
        "#Define ROI Pooling Convolutional Layer\n",
        "#Region-based convolutional neural network (R-CNN) is the final step in Faster R-CNN’s pipeline. After getting a convolutional feature map from the image, using it to get object proposals with the RPN and finally extracting features for each of those proposals (via RoI Pooling), we finally need to use these features for classification. R-CNN tries to mimic the final stages of classification CNNs where a fully-connected layer is used to output a score for each possible object class."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpnpHS3djwys"
      },
      "source": [
        "class RoiPoolingConv(Layer):\n",
        "    '''ROI pooling layer for 2D inputs.\n",
        "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
        "    K. He, X. Zhang, S. Ren, J. Sun\n",
        "    # Arguments\n",
        "        pool_size: int\n",
        "            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n",
        "        num_rois: number of regions of interest to be used\n",
        "    # Input shape\n",
        "        list of two 4D tensors [X_img,X_roi] with shape:\n",
        "        X_img:\n",
        "        `(1, rows, cols, channels)`\n",
        "        X_roi:\n",
        "        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "    # Output shape\n",
        "        3D tensor with shape:\n",
        "        `(1, num_rois, channels, pool_size, pool_size)`\n",
        "    '''\n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "\n",
        "        self.dim_ordering = K.image_data_format()\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]   \n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert(len(x) == 2)\n",
        "\n",
        "        # x[0] is image with shape (rows, cols, channels)\n",
        "        img = x[0]\n",
        "\n",
        "        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n",
        "        rois = x[1]\n",
        "\n",
        "        input_shape = K.shape(img)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for roi_idx in range(self.num_rois):\n",
        "\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "\n",
        "            x = K.cast(x, 'int32')\n",
        "            y = K.cast(y, 'int32')\n",
        "            w = K.cast(w, 'int32')\n",
        "            h = K.cast(h, 'int32')\n",
        "\n",
        "            # Resized roi of the image to pooling size (7x7)\n",
        "            rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "            outputs.append(rs)\n",
        "                \n",
        "\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n",
        "        # Might be (1, 4, 7, 7, 3)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "\n",
        "        # permute_dimensions is similar to transpose\n",
        "        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size,\n",
        "                  'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19rQB2MgkUOG"
      },
      "source": [
        "#Vgg-16 model\n",
        "#VGG-16 trained on imagenet is used as base model for detecting objects using Faster R-CNN"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g5e_HraoHyn"
      },
      "source": [
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        return input_length//16\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)    \n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "\n",
        "\n",
        "    input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    bn_axis = 3\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVJ2syboWg8"
      },
      "source": [
        "#RPN layer\n",
        "#The RPN takes all the reference boxes (anchors) and outputs a set of good proposals for objects. It does this by having two different outputs for each of the anchors.\n",
        "\n",
        "#The first one is the probability that an anchor is an object. An “objectness score”, if you will. Note that the RPN doesn’t care what class of object it is, only that it does in fact look like an object (and not background). We are going to use this objectness score to filter out the bad predictions for the second stage. The second output is the bounding box regression for adjusting the anchors to better fit the object it’s predicting.\n",
        "\n",
        "#The RPN is implemented efficiently in a fully convolutional way, using the convolutional feature map returned by the base network as an input. First, we use a convolutional layer with 512 channels and 3x3 kernel size and then we have two parallel convolutional layers using a 1x11x1 kernel, whose number of channels depends on the number of anchors per point."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h67HkMvooc6V"
      },
      "source": [
        "def rpn_layer(base_layers, num_anchors):\n",
        "    \"\"\"Create a rpn layer\n",
        "        Step1: Pass through the feature map from base layer to a 3x3 512 channels convolutional layer\n",
        "                Keep the padding 'same' to preserve the feature map's size\n",
        "        Step2: Pass the step1 to two (1,1) convolutional layer to replace the fully connected layer\n",
        "                classification layer: num_anchors (9 in here) channels for 0, 1 sigmoid activation output\n",
        "                regression layer: num_anchors*4 (36 in here) channels for computing the regression of bboxes with linear activation\n",
        "    Args:\n",
        "        base_layers: vgg in here\n",
        "        num_anchors: 9 in here\n",
        "\n",
        "    Returns:\n",
        "        [x_class, x_regr, base_layers]\n",
        "        x_class: classification for whether it's an object\n",
        "        x_regr: bboxes regression\n",
        "        base_layers: vgg in here\n",
        "    \"\"\"\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIsP0rm7oiEz"
      },
      "source": [
        "#Classifier layer\n",
        "#For the classification layer, we output two predictions per anchor: the score of it being background (not an object) and the score of it being foreground (an actual object).\n",
        "\n",
        "#For the regression, or bounding box adjustment layer, we output 4 predictions: the deltas \\Delta{x{center}}, \\Delta{y{center}}, \\Delta{width}, \\Delta{height}Δxcenter,Δycenter,Δwidth,Δheight which we will apply to the anchors to get the final proposals.\n",
        "\n",
        "#Using the final proposal coordinates and their “objectness” score we then have a good set of proposals for objects."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8OtwoNPopqN"
      },
      "source": [
        "def classifier_layer(base_layers, input_rois, num_rois, nb_classes = 4):\n",
        "    \"\"\"Create a classifier layer\n",
        "    \n",
        "    Args:\n",
        "        base_layers: vgg\n",
        "        input_rois: `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "        num_rois: number of rois to be processed in one time (4 in here)\n",
        "\n",
        "    Returns:\n",
        "        list(out_class, out_regr)\n",
        "        out_class: classifier layer output\n",
        "        out_regr: regression layer output\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = (num_rois,7,7,512)\n",
        "\n",
        "    pooling_regions = 7\n",
        "\n",
        "    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n",
        "    # num_rois (4) 7x7 roi pooling\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "\n",
        "    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n",
        "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "    # There are two output layer\n",
        "    # out_class: softmax acivation function for classify the class name of the object\n",
        "    # out_regr: linear activation function for bboxes coordinates regression\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    # note: no regression target for bg class\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "\n",
        "    return [out_class, out_regr]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAAnhp5Eoxba"
      },
      "source": [
        "#Calculate IoU (Intersection of Union)\n",
        "#IoU is to find the overlap score between anchors and ground truth bounding boxes."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp518mKMo0dg"
      },
      "source": [
        "def union(au, bu, area_intersection):\n",
        "\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "\tarea_union = area_a + area_b - area_intersection\n",
        "\treturn area_union\n",
        "\n",
        "\n",
        "def intersection(ai, bi):\n",
        "\tx = max(ai[0], bi[0])\n",
        "\ty = max(ai[1], bi[1])\n",
        "\tw = min(ai[2], bi[2]) - x\n",
        "\th = min(ai[3], bi[3]) - y\n",
        "\tif w < 0 or h < 0:\n",
        "\t\treturn 0\n",
        "\treturn w*h\n",
        "\n",
        "\n",
        "def iou(a, b):\n",
        "\t# a and b should be (x1,y1,x2,y2)\n",
        "\n",
        "\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "\t\treturn 0.0\n",
        "\n",
        "\tarea_i = intersection(a, b)\n",
        "\tarea_u = union(a, b, area_i)\n",
        "\n",
        "\treturn float(area_i) / float(area_u + 1e-6)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zygRxlH8o3mW"
      },
      "source": [
        "#Calculate the rpn for all anchors of all images"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ05yOQfpyz9"
      },
      "source": [
        "def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "\t\"\"\"(Important part!) Calculate the rpn for all anchors \n",
        "\t\tIf feature map has shape 38x50=1900, there are 1900x9=17100 potential anchors\n",
        "\t\n",
        "\tArgs:\n",
        "\t\tC: config\n",
        "\t\timg_data: augmented image data\n",
        "\t\twidth: original image width (e.g. 600)\n",
        "\t\theight: original image height (e.g. 800)\n",
        "\t\tresized_width: resized image width according to C.im_size (e.g. 300)\n",
        "\t\tresized_height: resized image height according to C.im_size (e.g. 400)\n",
        "\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n",
        "\n",
        "\tReturns:\n",
        "\t\ty_rpn_cls: list(num_bboxes, y_is_box_valid + y_rpn_overlap)\n",
        "\t\t\ty_is_box_valid: 0 or 1 (0 means the box is invalid, 1 means the box is valid)\n",
        "\t\t\ty_rpn_overlap: 0 or 1 (0 means the box is not an object, 1 means the box is an object)\n",
        "\t\ty_rpn_regr: list(num_bboxes, 4*y_rpn_overlap + y_rpn_regr)\n",
        "\t\t\ty_rpn_regr: x1,y1,x2,y2 bunding boxes coordinates\n",
        "\t\"\"\"\n",
        "\tdownscale = float(C.rpn_stride) \n",
        "\tanchor_sizes = C.anchor_box_scales   # 128, 256, 512\n",
        "\tanchor_ratios = C.anchor_box_ratios  # 1:1, 1:2*sqrt(2), 2*sqrt(2):1\n",
        "\tnum_anchors = len(anchor_sizes) * len(anchor_ratios) # 3x3=9\n",
        "\n",
        "\t# calculate the output map size based on the network architecture\n",
        "\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "\n",
        "\tn_anchratios = len(anchor_ratios)    # 3\n",
        "\t\n",
        "\t# initialise empty output objectives\n",
        "\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "\tnum_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n",
        "\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n",
        "\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n",
        "\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n",
        "\n",
        "\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\tgta = np.zeros((num_bboxes, 4))\n",
        "\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "\t\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n",
        "\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "\t\n",
        "\t# rpn ground truth\n",
        "\n",
        "\tfor anchor_size_idx in range(len(anchor_sizes)):\n",
        "\t\tfor anchor_ratio_idx in range(n_anchratios):\n",
        "\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n",
        "\t\t\t\n",
        "\t\t\tfor ix in range(output_width):\t\t\t\t\t\n",
        "\t\t\t\t# x-coordinates of the current anchor box\t\n",
        "\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n",
        "\t\t\t\t\n",
        "\t\t\t\t# ignore boxes that go across image boundaries\t\t\t\t\t\n",
        "\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tfor jy in range(output_height):\n",
        "\n",
        "\t\t\t\t\t# y-coordinates of the current anchor box\n",
        "\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\n",
        "\t\t\t\t\t# ignore boxes that go across image boundaries\n",
        "\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t\t# bbox_type indicates whether an anchor should be a target\n",
        "\t\t\t\t\t# Initialize with 'negative'\n",
        "\t\t\t\t\tbbox_type = 'neg'\n",
        "\n",
        "\t\t\t\t\t# this is the best IOU for the (x,y) coord and the current anchor\n",
        "\t\t\t\t\t# note that this is different from the best IOU for a GT bbox\n",
        "\t\t\t\t\tbest_iou_for_loc = 0.0\n",
        "\n",
        "\t\t\t\t\tfor bbox_num in range(num_bboxes):\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t# get IOU of the current GT box and the current anchor box\n",
        "\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\t\t\t\t\t\t# calculate the regression targets if they will be needed\n",
        "\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n",
        "\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "\t\t\t\t\t\t\t# x,y are the center point of ground-truth bbox\n",
        "\t\t\t\t\t\t\t# xa,ya are the center point of anchor bbox (xa=downscale * (ix + 0.5); ya=downscale * (iy+0.5))\n",
        "\t\t\t\t\t\t\t# w,h are the width and height of ground-truth bbox\n",
        "\t\t\t\t\t\t\t# wa,ha are the width and height of anchor bboxe\n",
        "\t\t\t\t\t\t\t# tx = (x - xa) / wa\n",
        "\t\t\t\t\t\t\t# ty = (y - ya) / ha\n",
        "\t\t\t\t\t\t\t# tw = log(w / wa)\n",
        "\t\t\t\t\t\t\t# th = log(h / ha)\n",
        "\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n",
        "\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "\n",
        "\t\t\t\t\t\t\t# all GT boxes should be mapped to an anchor box, so we keep track of which anchor box was best\n",
        "\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n",
        "\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n",
        "\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n",
        "\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n",
        "\n",
        "\t\t\t\t\t\t\t# we set the anchor to positive if the IOU is >0.7 (it does not matter if there was another better box, it just indicates overlap)\n",
        "\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tbbox_type = 'pos'\n",
        "\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n",
        "\t\t\t\t\t\t\t\t# we update the regression layer target if this IOU is the best for the current (x,y) and anchor position\n",
        "\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n",
        "\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n",
        "\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n",
        "\n",
        "\t\t\t\t\t\t\t# if the IOU is >0.3 and <0.7, it is ambiguous and no included in the objective\n",
        "\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\t# gray zone between neg and pos\n",
        "\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n",
        "\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n",
        "\n",
        "\t\t\t\t\t# turn on or off outputs depending on IOUs\n",
        "\t\t\t\t\tif bbox_type == 'neg':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'neutral':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'pos':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "\t# we ensure that every bbox has at least one positive RPN region\n",
        "\n",
        "\tfor idx in range(num_anchors_for_bbox.shape[0]):\n",
        "\t\tif num_anchors_for_bbox[idx] == 0:\n",
        "\t\t\t# no box with an IOU greater than zero ...\n",
        "\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_is_box_valid[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\ty_rpn_overlap[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n",
        "\t\t\ty_rpn_regr[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n",
        "\n",
        "\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "\tnum_pos = len(pos_locs[0])\n",
        "\n",
        "\t# one issue is that the RPN has many more negative than positive regions, so we turn off some of the negative\n",
        "\t# regions. We also limit it to 256 regions.\n",
        "\tnum_regions = 256\n",
        "\n",
        "\tif len(pos_locs[0]) > num_regions/2:\n",
        "\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n",
        "\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "\t\tnum_pos = num_regions/2\n",
        "\n",
        "\tif len(neg_locs[0]) + num_pos > num_regions:\n",
        "\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n",
        "\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOQtotwUqMB4"
      },
      "source": [
        "#Get new image size and augment the image"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdTME5AjqRV-"
      },
      "source": [
        "def get_new_img_size(width, height, img_min_side=300):\n",
        "\tif width <= height:\n",
        "\t\tf = float(img_min_side) / width\n",
        "\t\tresized_height = int(f * height)\n",
        "\t\tresized_width = img_min_side\n",
        "\telse:\n",
        "\t\tf = float(img_min_side) / height\n",
        "\t\tresized_width = int(f * width)\n",
        "\t\tresized_height = img_min_side\n",
        "\n",
        "\treturn resized_width, resized_height\n",
        "\n",
        "def augment(img_data, config, augment=True):\n",
        "\tassert 'filepath' in img_data\n",
        "\tassert 'bboxes' in img_data\n",
        "\tassert 'width' in img_data\n",
        "\tassert 'height' in img_data\n",
        "\n",
        "\timg_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "\timg = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "\tif augment:\n",
        "\t\trows, cols = img.shape[:2]\n",
        "\n",
        "\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\tbbox['x1'] = cols - x2\n",
        "\n",
        "\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\tbbox['y1'] = rows - y2\n",
        "\n",
        "\t\tif config.rot_90:\n",
        "\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n",
        "\t\t\tif angle == 270:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\telif angle == 180:\n",
        "\t\t\t\timg = cv2.flip(img, -1)\n",
        "\t\t\telif angle == 90:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\telif angle == 0:\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tif angle == 270:\n",
        "\t\t\t\t\tbbox['x1'] = y1\n",
        "\t\t\t\t\tbbox['x2'] = y2\n",
        "\t\t\t\t\tbbox['y1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = cols - x1\n",
        "\t\t\t\telif angle == 180:\n",
        "\t\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\t\tbbox['x1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = rows - y2\n",
        "\t\t\t\telif angle == 90:\n",
        "\t\t\t\t\tbbox['x1'] = rows - y2\n",
        "\t\t\t\t\tbbox['x2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = x1\n",
        "\t\t\t\t\tbbox['y2'] = x2        \n",
        "\t\t\t\telif angle == 0:\n",
        "\t\t\t\t\tpass\n",
        "\n",
        "\timg_data_aug['width'] = img.shape[1]\n",
        "\timg_data_aug['height'] = img.shape[0]\n",
        "\treturn img_data_aug, img"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2DSI_UMqbHR"
      },
      "source": [
        "#Generate the ground_truth anchors"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV9tLLqgqfEW"
      },
      "source": [
        "def get_anchor_gt(all_img_data, C, img_length_calc_function, mode='train'):\n",
        "\t\"\"\" Yield the ground-truth anchors as Y (labels)\n",
        "\t\t\n",
        "\tArgs:\n",
        "\t\tall_img_data: list(filepath, width, height, list(bboxes))\n",
        "\t\tC: config\n",
        "\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n",
        "\t\tmode: 'train' or 'test'; 'train' mode need augmentation\n",
        "\n",
        "\tReturns:\n",
        "\t\tx_img: image data after resized and scaling (smallest size = 300px)\n",
        "\t\tY: [y_rpn_cls, y_rpn_regr]\n",
        "\t\timg_data_aug: augmented image data (original image with augmentation)\n",
        "\t\tdebug_img: show image for debug\n",
        "\t\tnum_pos: show number of positive anchors for debug\n",
        "\t\"\"\"\n",
        "\twhile True:\n",
        "\n",
        "\t\tfor img_data in all_img_data:\n",
        "\t\t\ttry:\n",
        "\n",
        "\t\t\t\t# read in image, and optionally add augmentation\n",
        "\n",
        "\t\t\t\tif mode == 'train':\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=False)\n",
        "\n",
        "\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
        "\t\t\t\t(rows, cols, _) = x_img.shape\n",
        "\n",
        "\t\t\t\tassert cols == width\n",
        "\t\t\t\tassert rows == height\n",
        "\n",
        "\t\t\t\t# get image dimensions for resizing\n",
        "\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\t\t\t\t# resize the image so that smalles side is length = 300px\n",
        "\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\t\t\t\tdebug_img = x_img.copy()\n",
        "\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ty_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# Zero-center by mean pixel, and preprocess image\n",
        "\n",
        "\t\t\t\tx_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n",
        "\t\t\t\tx_img = x_img.astype(np.float32)\n",
        "\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n",
        "\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n",
        "\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n",
        "\t\t\t\tx_img /= C.img_scaling_factor\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n",
        "\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n",
        "\n",
        "\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug, debug_img, num_pos\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059WQjXrqkrV"
      },
      "source": [
        "#Define loss functions for all four outputs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26vd7_1qp_R"
      },
      "source": [
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp6s0Zr3qrGO"
      },
      "source": [
        "def rpn_loss_regr(num_anchors):\n",
        "    \"\"\"Loss function for rpn regression\n",
        "    Args:\n",
        "        num_anchors: number of anchors (9 in here)\n",
        "    Returns:\n",
        "        Smooth L1 loss function \n",
        "                           0.5*x*x (if x_abs < 1)\n",
        "                           x_abx - 0.5 (otherwise)\n",
        "    \"\"\"\n",
        "    def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "\n",
        "        # x is the difference between true value and predicted vaue\n",
        "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
        "\n",
        "        # absolute value of x\n",
        "        x_abs = K.abs(x)\n",
        "\n",
        "        # If x_abs <= 1.0, x_bool = 1\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
        "\n",
        "        return lambda_rpn_regr * K.sum(\n",
        "            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
        "\n",
        "    return rpn_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "    \"\"\"Loss function for rpn classification\n",
        "    Args:\n",
        "        num_anchors: number of anchors (9 in here)\n",
        "        y_true[:, :, :, :9]: [0,1,0,0,0,0,0,1,0] means only the second and the eighth box is valid which contains pos or neg anchor => isValid\n",
        "        y_true[:, :, :, 9:]: [0,1,0,0,0,0,0,0,0] means the second box is pos and eighth box is negative\n",
        "    Returns:\n",
        "        lambda * sum((binary_crossentropy(isValid*y_pred,y_true))) / N\n",
        "    \"\"\"\n",
        "    def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "\n",
        "            return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
        "\n",
        "    return rpn_loss_cls_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "    \"\"\"Loss function for rpn regression\n",
        "    Args:\n",
        "        num_anchors: number of anchors (9 in here)\n",
        "    Returns:\n",
        "        Smooth L1 loss function \n",
        "                           0.5*x*x (if x_abs < 1)\n",
        "                           x_abx - 0.5 (otherwise)\n",
        "    \"\"\"\n",
        "    def class_loss_regr_fixed_num(y_true, y_pred):\n",
        "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
        "        x_abs = K.abs(x)\n",
        "        x_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n",
        "        return lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n",
        "    return class_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_cls(y_true, y_pred):\n",
        "    return lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49BXVVvcqwIB"
      },
      "source": [
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "    # code used from here: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
        "    # if there are no boxes, return an empty list\n",
        "\n",
        "    # Process explanation:\n",
        "    #   Step 1: Sort the probs list\n",
        "    #   Step 2: Find the larget prob 'Last' in the list and save it to the pick list\n",
        "    #   Step 3: Calculate the IoU with 'Last' box and other boxes in the list. If the IoU is larger than overlap_threshold, delete the box from list\n",
        "    #   Step 4: Repeat step 2 and step 3 until there is no item in the probs list \n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # grab the coordinates of the bounding boxes\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    np.testing.assert_array_less(x1, x2)\n",
        "    np.testing.assert_array_less(y1, y2)\n",
        "\n",
        "    # if the bounding boxes integers, convert them to floats --\n",
        "    # this is important since we'll be doing a bunch of divisions\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    # initialize the list of picked indexes\t\n",
        "    pick = []\n",
        "\n",
        "    # calculate the areas\n",
        "    area = (x2 - x1) * (y2 - y1)\n",
        "\n",
        "    # sort the bounding boxes \n",
        "    idxs = np.argsort(probs)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes\n",
        "    # list\n",
        "    while len(idxs) > 0:\n",
        "        # grab the last index in the indexes list and add the\n",
        "        # index value to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # find the intersection\n",
        "\n",
        "        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        ww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "        hh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "        area_int = ww_int * hh_int\n",
        "\n",
        "        # find the union\n",
        "        area_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "        # compute the ratio of overlap\n",
        "        overlap = area_int/(area_union + 1e-6)\n",
        "\n",
        "        # delete all indexes from the index list that have\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "            np.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "        if len(pick) >= max_boxes:\n",
        "            break\n",
        "\n",
        "    # return only the bounding boxes that were picked using the integer data type\n",
        "    boxes = boxes[pick].astype(\"int\")\n",
        "    probs = probs[pick]\n",
        "    return boxes, probs\n",
        "\n",
        "def apply_regr_np(X, T):\n",
        "    \"\"\"Apply regression layer to all anchors in one feature map\n",
        "\n",
        "    Args:\n",
        "        X: shape=(4, 18, 25) the current anchor type for all points in the feature map\n",
        "        T: regression layer shape=(4, 18, 25)\n",
        "\n",
        "    Returns:\n",
        "        X: regressed position and size for current anchor\n",
        "    \"\"\"\n",
        "    try:\n",
        "        x = X[0, :, :]\n",
        "        y = X[1, :, :]\n",
        "        w = X[2, :, :]\n",
        "        h = X[3, :, :]\n",
        "\n",
        "        tx = T[0, :, :]\n",
        "        ty = T[1, :, :]\n",
        "        tw = T[2, :, :]\n",
        "        th = T[3, :, :]\n",
        "\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "\n",
        "        w1 = np.exp(tw.astype(np.float64)) * w\n",
        "        h1 = np.exp(th.astype(np.float64)) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "\n",
        "        x1 = np.round(x1)\n",
        "        y1 = np.round(y1)\n",
        "        w1 = np.round(w1)\n",
        "        h1 = np.round(h1)\n",
        "        return np.stack([x1, y1, w1, h1])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return X\n",
        "    \n",
        "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
        "    # Apply regression to x, y, w and h\n",
        "    try:\n",
        "        cx = x + w/2.\n",
        "        cy = y + h/2.\n",
        "        cx1 = tx * w + cx\n",
        "        cy1 = ty * h + cy\n",
        "        w1 = math.exp(tw) * w\n",
        "        h1 = math.exp(th) * h\n",
        "        x1 = cx1 - w1/2.\n",
        "        y1 = cy1 - h1/2.\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        w1 = int(round(w1))\n",
        "        h1 = int(round(h1))\n",
        "\n",
        "        return x1, y1, w1, h1\n",
        "\n",
        "    except ValueError:\n",
        "        return x, y, w, h\n",
        "    except OverflowError:\n",
        "        return x, y, w, h\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return x, y, w, h\n",
        "\n",
        "def calc_iou(R, img_data, C, class_mapping):\n",
        "    \"\"\"Converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "\n",
        "    Args:\n",
        "        R: bboxes, probs\n",
        "    \"\"\"\n",
        "    bboxes = img_data['bboxes']\n",
        "    (width, height) = (img_data['width'], img_data['height'])\n",
        "    # get image dimensions for resizing\n",
        "    (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "    gta = np.zeros((len(bboxes), 4))\n",
        "\n",
        "    for bbox_num, bbox in enumerate(bboxes):\n",
        "        # get the GT box coordinates, and resize to account for image resizing\n",
        "        # gta[bbox_num, 0] = (40 * (600 / 800)) / 16 = int(round(1.875)) = 2 (x in feature map)\n",
        "        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
        "        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
        "        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
        "\n",
        "    x_roi = []\n",
        "    y_class_num = []\n",
        "    y_class_regr_coords = []\n",
        "    y_class_regr_label = []\n",
        "    IoUs = [] # for debugging only\n",
        "\n",
        "    # R.shape[0]: number of bboxes (=300 from non_max_suppression)\n",
        "    for ix in range(R.shape[0]):\n",
        "        (x1, y1, x2, y2) = R[ix, :]\n",
        "        x1 = int(round(x1))\n",
        "        y1 = int(round(y1))\n",
        "        x2 = int(round(x2))\n",
        "        y2 = int(round(y2))\n",
        "\n",
        "        best_iou = 0.0\n",
        "        best_bbox = -1\n",
        "        # Iterate through all the ground-truth bboxes to calculate the iou\n",
        "        for bbox_num in range(len(bboxes)):\n",
        "            curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
        "\n",
        "            # Find out the corresponding ground-truth bbox_num with larget iou\n",
        "            if curr_iou > best_iou:\n",
        "                best_iou = curr_iou\n",
        "                best_bbox = bbox_num\n",
        "\n",
        "        if best_iou < C.classifier_min_overlap:\n",
        "                continue\n",
        "        else:\n",
        "            w = x2 - x1\n",
        "            h = y2 - y1\n",
        "            x_roi.append([x1, y1, w, h])\n",
        "            IoUs.append(best_iou)\n",
        "\n",
        "            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
        "                # hard negative example\n",
        "                cls_name = 'bg'\n",
        "            elif C.classifier_max_overlap <= best_iou:\n",
        "                cls_name = bboxes[best_bbox]['class']\n",
        "                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
        "                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
        "\n",
        "                cx = x1 + w / 2.0\n",
        "                cy = y1 + h / 2.0\n",
        "\n",
        "                tx = (cxg - cx) / float(w)\n",
        "                ty = (cyg - cy) / float(h)\n",
        "                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
        "                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
        "            else:\n",
        "                print('roi = {}'.format(best_iou))\n",
        "                raise RuntimeError\n",
        "\n",
        "        class_num = class_mapping[cls_name]\n",
        "        class_label = len(class_mapping) * [0]\n",
        "        class_label[class_num] = 1\n",
        "        y_class_num.append(copy.deepcopy(class_label))\n",
        "        coords = [0] * 4 * (len(class_mapping) - 1)\n",
        "        labels = [0] * 4 * (len(class_mapping) - 1)\n",
        "        if cls_name != 'bg':\n",
        "            label_pos = 4 * class_num\n",
        "            sx, sy, sw, sh = C.classifier_regr_std\n",
        "            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
        "            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "        else:\n",
        "            y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "            y_class_regr_label.append(copy.deepcopy(labels))\n",
        "\n",
        "    if len(x_roi) == 0:\n",
        "        return None, None, None, None\n",
        "\n",
        "    # bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "    X = np.array(x_roi)\n",
        "    # one hot code for bboxes from above => x_roi (X)\n",
        "    Y1 = np.array(y_class_num)\n",
        "    # corresponding labels and corresponding gt bboxes\n",
        "    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n",
        "\n",
        "    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0), IoUs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B4l_eBHrDev"
      },
      "source": [
        "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
        "\t\"\"\"Convert rpn layer to roi bboxes\n",
        "\n",
        "\tArgs: (num_anchors = 9)\n",
        "\t\trpn_layer: output layer for rpn classification \n",
        "\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n",
        "\t\t\tMight be (1, 18, 25, 18) if resized image is 400 width and 300\n",
        "\t\tregr_layer: output layer for rpn regression\n",
        "\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n",
        "\t\t\tMight be (1, 18, 25, 72) if resized image is 400 width and 300\n",
        "\t\tC: config\n",
        "\t\tuse_regr: Wether to use bboxes regression in rpn\n",
        "\t\tmax_boxes: max bboxes number for non-max-suppression (NMS)\n",
        "\t\toverlap_thresh: If iou in NMS is larger than this threshold, drop the box\n",
        "\n",
        "\tReturns:\n",
        "\t\tresult: boxes from non-max-suppression (shape=(300, 4))\n",
        "\t\t\tboxes: coordinates for bboxes (on the feature map)\n",
        "\t\"\"\"\n",
        "\tregr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "\tanchor_sizes = C.anchor_box_scales   # (3 in here)\n",
        "\tanchor_ratios = C.anchor_box_ratios  # (3 in here)\n",
        "\n",
        "\tassert rpn_layer.shape[0] == 1\n",
        "\n",
        "\t(rows, cols) = rpn_layer.shape[1:3]\n",
        "\n",
        "\tcurr_layer = 0\n",
        "\n",
        "\t# A.shape = (4, feature_map.height, feature_map.width, num_anchors) \n",
        "\t# Might be (4, 18, 25, 18) if resized image is 400 width and 300\n",
        "\t# A is the coordinates for 9 anchors for every point in the feature map \n",
        "\t# => all 18x25x9=4050 anchors cooridnates\n",
        "\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
        "\n",
        "\tfor anchor_size in anchor_sizes:\n",
        "\t\tfor anchor_ratio in anchor_ratios:\n",
        "\t\t\t# anchor_x = (128 * 1) / 16 = 8  => width of current anchor\n",
        "\t\t\t# anchor_y = (128 * 2) / 16 = 16 => height of current anchor\n",
        "\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\t\t\t\n",
        "\t\t\t# curr_layer: 0~8 (9 anchors)\n",
        "\t\t\t# the Kth anchor of all position in the feature map (9th in total)\n",
        "\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] # shape => (18, 25, 4)\n",
        "\t\t\tregr = np.transpose(regr, (2, 0, 1)) # shape => (4, 18, 25)\n",
        "\n",
        "\t\t\t# Create 18x25 mesh grid\n",
        "\t\t\t# For every point in x, there are all the y points and vice versa\n",
        "\t\t\t# X.shape = (18, 25)\n",
        "\t\t\t# Y.shape = (18, 25)\n",
        "\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\n",
        "\t\t\t# Calculate anchor position and size for each feature map point\n",
        "\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2 # Top left x coordinate\n",
        "\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2 # Top left y coordinate\n",
        "\t\t\tA[2, :, :, curr_layer] = anchor_x       # width of current anchor\n",
        "\t\t\tA[3, :, :, curr_layer] = anchor_y       # height of current anchor\n",
        "\n",
        "\t\t\t# Apply regression to x, y, w and h if there is rpn regression layer\n",
        "\t\t\tif use_regr:\n",
        "\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
        "\n",
        "\t\t\t# Avoid width and height exceeding 1\n",
        "\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\t# Convert (x, y , w, h) to (x1, y1, x2, y2)\n",
        "\t\t\t# x1, y1 is top left coordinate\n",
        "\t\t\t# x2, y2 is bottom right coordinate\n",
        "\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
        "\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
        "\n",
        "\t\t\t# Avoid bboxes drawn outside the feature map\n",
        "\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
        "\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\tcurr_layer += 1\n",
        "\n",
        "\tall_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  # shape=(4050, 4)\n",
        "\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                   # shape=(4050,)\n",
        "\n",
        "\tx1 = all_boxes[:, 0]\n",
        "\ty1 = all_boxes[:, 1]\n",
        "\tx2 = all_boxes[:, 2]\n",
        "\ty2 = all_boxes[:, 3]\n",
        "\n",
        "\t# Find out the bboxes which is illegal and delete them from bboxes list\n",
        "\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "\n",
        "\tall_boxes = np.delete(all_boxes, idxs, 0)\n",
        "\tall_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "\t# Apply non_max_suppression\n",
        "\t# Only extract the bboxes. Don't need rpn probs in the later process\n",
        "\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "\n",
        "\treturn result"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOXdLfw7rQMZ"
      },
      "source": [
        "#Start training"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K82dGEVQiM9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bce4c4-172d-4d3c-81c1-6b9c0d7ac642"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isLfHuNrrRcb"
      },
      "source": [
        "base_path = '/content/drive/My Drive/Parasite/New/Newlabel'\n",
        "\n",
        "train_path =  '/content/drive/My Drive/Parasite/New/Newlabel/train_annotations.txt' # Training data (annotation file)\n",
        "\n",
        "num_rois = 4 # Number of RoIs to process at once.\n",
        "\n",
        "# Augmentation flag\n",
        "horizontal_flips = True # Augment with horizontal flips in training. \n",
        "vertical_flips = True   # Augment with vertical flips in training. \n",
        "rot_90 = True           # Augment with 90 degree rotations in training. \n",
        "\n",
        "output_weight_path = os.path.join(base_path, 'model_frcnn_vgg.hdf5')\n",
        "\n",
        "record_path = os.path.join(base_path, 'record.csv') # Record data (used to save the losses, classification accuracy and mean average precision)\n",
        "\n",
        "base_weight_path = os.path.join(base_path, 'vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "config_output_filename = os.path.join(base_path, 'model_vgg_config.pickle')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4hOcEgOrT4q"
      },
      "source": [
        "# Create the config\n",
        "C = Config()\n",
        "\n",
        "C.use_horizontal_flips = horizontal_flips\n",
        "C.use_vertical_flips = vertical_flips\n",
        "C.rot_90 = rot_90\n",
        "\n",
        "C.record_path = record_path\n",
        "C.model_path = output_weight_path\n",
        "C.num_rois = num_rois\n",
        "\n",
        "C.base_net_weights = base_weight_path"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cVv4N488LN2",
        "outputId": "0f237f1e-b422-48ce-84d3-c88f6e827ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "C.model_path = '/content/drive/My Drive/Parasite/New/Newlabel/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "save_path = '/content/drive/My Drive/Parasite/New/Newlabel/savemodel.h5'\n",
        "best_save_path = '/content/drive/My Drive/Parasite/New/Newlabel/bestmodel.h5'"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n",
            "553476096/553467096 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9xVH32LfAY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLzQhkS4rXkT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56661e75-695a-48dc-f15e-65efc94936b7"
      },
      "source": [
        "#--------------------------------------------------------#\n",
        "# This step will spend some time to load the data        #\n",
        "#--------------------------------------------------------#\n",
        "st = time.time()\n",
        "train_imgs, classes_count, class_mapping = get_data(train_path)\n",
        "print()\n",
        "print('Spend %0.2f mins to load the data' % ((time.time()-st)/60) )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing annotation files\n",
            "idx=516\n",
            "Spend 12.47 mins to load the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnL6NPh8icdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c99a70-413b-469a-bc51-9118615b5e8b"
      },
      "source": [
        "if 'bg' not in classes_count:\n",
        "\tclasses_count['bg'] = 0\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "# e.g.\n",
        "#    classes_count: {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745, 'bg': 0}\n",
        "#    class_mapping: {'Person': 0, 'Car': 1, 'Mobile phone': 2, 'bg': 3}\n",
        "C.class_mapping = class_mapping\n",
        "\n",
        "print('Training images per class:')\n",
        "pprint.pprint(classes_count)\n",
        "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
        "print(class_mapping)\n",
        "\n",
        "# Save the configuration\n",
        "with open(config_output_filename, 'wb') as config_f:\n",
        "\tpickle.dump(C,config_f)\n",
        "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images per class:\n",
            "{'Ascaris': 68,\n",
            " 'Echinostoma': 53,\n",
            " 'Hookworm': 87,\n",
            " 'Mif': 52,\n",
            " 'Ov': 110,\n",
            " 'Taenia': 146,\n",
            " 'bg': 0}\n",
            "Num classes (including bg) = 7\n",
            "{'Echinostoma': 0, 'Ov': 1, 'Taenia': 2, 'Hookworm': 3, 'Ascaris': 4, 'Mif': 5, 'bg': 6}\n",
            "Config has been written to /content/drive/My Drive/Parasite/New/Newlabel/model_vgg_config.pickle, and can be loaded when testing to ensure correct results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkiGQA3Ui8F2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9843b3d6-313b-4fc2-e86b-0542f52a08b6"
      },
      "source": [
        "# Shuffle the images with seed\n",
        "random.seed(1)\n",
        "random.shuffle(train_imgs)\n",
        "\n",
        "print('Num train samples (images) {}'.format(len(train_imgs)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num train samples (images) 455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhX570d9NoHp"
      },
      "source": [
        "# Get train data generator which generate X, Y, image_data\n",
        "data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUlAcyK-NyK2"
      },
      "source": [
        "X, Y, image_data, debug_img, debug_num_pos = next(data_gen_train)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfs57GZPOB_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "9ae743f9-73fd-428a-ff37-b8fd9286e9c5"
      },
      "source": [
        "print('Original image: height=%d width=%d'%(image_data['height'], image_data['width']))\n",
        "print('Resized image:  height=%d width=%d C.im_size=%d'%(X.shape[1], X.shape[2], C.im_size))\n",
        "print('Feature map size: height=%d width=%d C.rpn_stride=%d'%(Y[0].shape[1], Y[0].shape[2], C.rpn_stride))\n",
        "print(X.shape)\n",
        "print(str(len(Y))+\" includes 'y_rpn_cls' and 'y_rpn_regr'\")\n",
        "print('Shape of y_rpn_cls {}'.format(Y[0].shape))\n",
        "print('Shape of y_rpn_regr {}'.format(Y[1].shape))\n",
        "print(image_data)\n",
        "\n",
        "print('Number of positive anchors for this image: %d' % (debug_num_pos))\n",
        "if debug_num_pos==0:\n",
        "    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[1]/image_data['width']), image_data['bboxes'][0]['x2']*(X.shape[1]/image_data['width'])\n",
        "    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['y2']*(X.shape[2]/image_data['height'])\n",
        "    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n",
        "\n",
        "    img = debug_img.copy()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    color = (0, 255, 0)\n",
        "    cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n",
        "    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n",
        "    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n",
        "\n",
        "    plt.grid()\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "else:\n",
        "    cls = Y[0][0]\n",
        "    pos_cls = np.where(cls==1)\n",
        "    print(pos_cls)\n",
        "    regr = Y[1][0]\n",
        "    pos_regr = np.where(regr==1)\n",
        "    print(pos_regr)\n",
        "    print('y_rpn_cls for possible pos anchor: {}'.format(cls[pos_cls[0][0],pos_cls[1][0],:]))\n",
        "    print('y_rpn_regr for positive anchor: {}'.format(regr[pos_regr[0][0],pos_regr[1][0],:]))\n",
        "\n",
        "    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[1]/image_data['width']), image_data['bboxes'][0]['x2']*(X.shape[1]/image_data['width'])\n",
        "    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['y2']*(X.shape[2]/image_data['height'])\n",
        "    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n",
        "\n",
        "    img = debug_img.copy()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    color = (0, 255, 0)\n",
        "    #   cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n",
        "    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n",
        "    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n",
        "\n",
        "    # Add text\n",
        "    textLabel = 'gt bbox'\n",
        "    (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,0.5,1)\n",
        "    textOrg = (gt_x1, gt_y1+5)\n",
        "    cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n",
        "    cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
        "    cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1)\n",
        "\n",
        "    # Draw positive anchors according to the y_rpn_regr\n",
        "    for i in range(debug_num_pos):\n",
        "\n",
        "        color = (100+i*(155/4), 0, 100+i*(155/4))\n",
        "\n",
        "        idx = pos_regr[2][i*4]/4\n",
        "        anchor_size = C.anchor_box_scales[int(idx/3)]\n",
        "        anchor_ratio = C.anchor_box_ratios[2-int((idx+1)%3)]\n",
        "\n",
        "        center = (pos_regr[1][i*4]*C.rpn_stride, pos_regr[0][i*4]*C.rpn_stride)\n",
        "        print('Center position of positive anchor: ', center)\n",
        "        cv2.circle(img, center, 3, color, -1)\n",
        "        anc_w, anc_h = anchor_size*anchor_ratio[0], anchor_size*anchor_ratio[1]\n",
        "        cv2.rectangle(img, (center[0]-int(anc_w/2), center[1]-int(anc_h/2)), (center[0]+int(anc_w/2), center[1]+int(anc_h/2)), color, 2)\n",
        "#         cv2.putText(img, 'pos anchor bbox '+str(i+1), (center[0]-int(anc_w/2), center[1]-int(anc_h/2)-5), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n",
        "\n",
        "print('Green bboxes is ground-truth bbox. Others are positive anchors')\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.grid()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image: height=8000 width=6000\n",
            "Resized image:  height=400 width=300 C.im_size=300\n",
            "Feature map size: height=25 width=18 C.rpn_stride=16\n",
            "(1, 400, 300, 3)\n",
            "2 includes 'y_rpn_cls' and 'y_rpn_regr'\n",
            "Shape of y_rpn_cls (1, 25, 18, 18)\n",
            "Shape of y_rpn_regr (1, 25, 18, 72)\n",
            "{'filepath': '/content/drive/My Drive/Parasite/New/Newlabel/Train/IMG_20190722_154305.jpg', 'width': 6000, 'height': 8000, 'bboxes': [{'class': 'Taenia', 'x1': 2140, 'x2': 2722, 'y1': 4091, 'y2': 4755}]}\n",
            "Number of positive anchors for this image: 1\n",
            "(array([ 5, 13, 13]), array([6, 7, 7]), array([ 4,  6, 15]))\n",
            "(array([13, 13, 13, 13]), array([7, 7, 7, 7]), array([24, 25, 26, 27]))\n",
            "y_rpn_cls for possible pos anchor: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "y_rpn_regr for positive anchor: [ 0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  1.          1.          1.          1.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.19374999  0.64375001 -0.37999091  0.1472559   0.          0.\n",
            "  0.          0.          0.          0.          0.          0.        ]\n",
            "Center position of positive anchor:  (112, 208)\n",
            "Green bboxes is ground-truth bbox. Others are positive anchors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxXfY_rwOH3i"
      },
      "source": [
        "input_shape_img = (None, None, 3)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(None, 4))\n",
        "\n",
        "# define the base network (VGG here, can be Resnet50, Inception, etc)\n",
        "shared_layers = nn_base(img_input, trainable=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf77KDXg8l7Y"
      },
      "source": [
        "from keras.utils import data_utils"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmcdTTzOM2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de78fb6-83d9-4ace-b9fe-541f328f627f"
      },
      "source": [
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) # 9\n",
        "rpn = rpn_layer(shared_layers, num_anchors)\n",
        "\n",
        "classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))\n",
        "\n",
        "model_rpn = Model(img_input, rpn[:2])\n",
        "model_classifier = Model([img_input, roi_input], classifier)\n",
        "\n",
        "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
        "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
        "\n",
        "# Because the google colab can only run the session several hours one time (then you need to connect again), \n",
        "# we need to save the model and load the model to continue training\n",
        "\n",
        "# If this is a continued training, load the trained model from before\n",
        "print('Continue training based on previous trained model')\n",
        "print('Loading weights from {}'.format(C.model_path))\n",
        "model_rpn.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "    \n",
        "# Load the records\n",
        "record_df = pd.read_csv(record_path)\n",
        "\n",
        "r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
        "r_class_acc = record_df['class_acc']\n",
        "r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
        "r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
        "r_loss_class_cls = record_df['loss_class_cls']\n",
        "r_loss_class_regr = record_df['loss_class_regr']\n",
        "r_curr_loss = record_df['curr_loss']\n",
        "r_elapsed_time = record_df['elapsed_time']\n",
        "r_mAP = record_df['mAP']\n",
        "\n",
        "print('Already train %dK batches'% (len(record_df)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continue training based on previous trained model\n",
            "Loading weights from /root/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "Already train 9K batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2CUroB75lYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "48630b59-0d5d-435e-8d38-841fb0b2f8c6"
      },
      "source": [
        "record_df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_overlapping_bboxes</th>\n",
              "      <th>class_acc</th>\n",
              "      <th>loss_rpn_cls</th>\n",
              "      <th>loss_rpn_regr</th>\n",
              "      <th>loss_class_cls</th>\n",
              "      <th>loss_class_regr</th>\n",
              "      <th>curr_loss</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>mAP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.844</td>\n",
              "      <td>0.651</td>\n",
              "      <td>1.281</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0.058</td>\n",
              "      <td>2.227</td>\n",
              "      <td>112.049</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.025</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.097</td>\n",
              "      <td>0.532</td>\n",
              "      <td>0.057</td>\n",
              "      <td>1.205</td>\n",
              "      <td>115.333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.697</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.051</td>\n",
              "      <td>1.028</td>\n",
              "      <td>112.334</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30.348</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.926</td>\n",
              "      <td>114.271</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.266</td>\n",
              "      <td>0.834</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.395</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.862</td>\n",
              "      <td>113.325</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_overlapping_bboxes  class_acc  ...  elapsed_time  mAP\n",
              "0                   28.844      0.651  ...       112.049    0\n",
              "1                   31.025      0.780  ...       115.333    0\n",
              "2                   30.697      0.804  ...       112.334    0\n",
              "3                   30.348      0.825  ...       114.271    0\n",
              "4                   30.266      0.834  ...       113.325    0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tn9LmqyT-sJ"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b8mWHe2OgfR"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "optimizer_classifier = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
        "model_all.compile(optimizer='sgd', loss='mae')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RftDxilRSZcP"
      },
      "source": [
        "# Training setting\n",
        "total_epochs = len(record_df)\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "epoch_length = 6\n",
        "num_epochs = 5\n",
        "iter_num = 0\n",
        "\n",
        "total_epochs += num_epochs\n",
        "\n",
        "losses = np.zeros((epoch_length, 5))\n",
        "rpn_accuracy_rpn_monitor = []\n",
        "rpn_accuracy_for_epoch = []\n",
        "\n",
        "if len(record_df)==0:\n",
        "    best_loss = np.Inf\n",
        "else:\n",
        "    best_loss = np.min(r_curr_loss)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8MrHYrdSijd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51909da8-b01e-4dae-ada7-e3e8686c75bc"
      },
      "source": [
        "print(len(record_df))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_EMW1eBpSeY"
      },
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOLDMybkiAB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e35d4f2-57ac-485a-8357-340f2f2cb420"
      },
      "source": [
        "print(rpn_accuracy_rpn_monitor)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1O4XWxbUUuw",
        "outputId": "174fd91b-cd94-44df-b181-ea4a6cd85281"
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(save_path,overwrite=True)\n",
        "                    #model_all.save_weights(save_path, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
        "                    \n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/14\n",
            "2/6 [=========>....................] - ETA: 1:03 - rpn_cls: 3.7018 - rpn_regr: 0.0310 - final_cls: 1.9294 - final_regr: 0.6541Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x7fa49f0793b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/6 [==============>...............] - ETA: 1:07 - rpn_cls: 4.1776 - rpn_regr: 0.0356 - final_cls: 1.8977 - final_regr: 0.5818Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 41s - rpn_cls: 4.4944 - rpn_regr: 0.0543 - final_cls: 1.8699 - final_regr: 0.5185 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 20s - rpn_cls: 4.7100 - rpn_regr: 0.0847 - final_cls: 1.8484 - final_regr: 0.4674Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 124s 21s/step - rpn_cls: 4.7650 - rpn_regr: 0.1075 - final_cls: 1.8327 - final_regr: 0.4260\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.6363636363636364\n",
            "Classifier accuracy for bounding boxes from RPN: 0.5833333333333334\n",
            "Loss RPN classifier: 5.040279905001323\n",
            "Loss RPN regression: 0.2211187455492715\n",
            "Loss Detector classifier: 1.753752867380778\n",
            "Loss Detector regression: 0.21904655928180242\n",
            "Total loss: 7.2341980772131755\n",
            "Elapsed time: 124.48290252685547\n",
            "Epoch 11/14\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 17s - rpn_cls: 5.4673 - rpn_regr: 0.3742 - final_cls: 1.4833 - final_regr: 0.2935Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 120s 19s/step - rpn_cls: 5.9076 - rpn_regr: 0.3817 - final_cls: 1.4528 - final_regr: 0.2708\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.6363636363636364\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 8.108933752365223\n",
            "Loss RPN regression: 0.41936830679575604\n",
            "Loss Detector classifier: 1.3005909323692322\n",
            "Loss Detector regression: 0.15760506884544156\n",
            "Total loss: 9.986498060375652\n",
            "Elapsed time: 119.8539650440216\n",
            "Epoch 12/14\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 2:24 - rpn_cls: 6.4115 - rpn_regr: 0.2749 - final_cls: 1.2181 - final_regr: 0.0561Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:31 - rpn_cls: 6.2442 - rpn_regr: 0.2661 - final_cls: 1.1492 - final_regr: 0.0457Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 123s 19s/step - rpn_cls: 4.5721 - rpn_regr: 0.2881 - final_cls: 1.1932 - final_regr: 0.0612\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.9090909090909091\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 4.152557217206322\n",
            "Loss RPN regression: 0.311476764579614\n",
            "Loss Detector classifier: 1.290792425473531\n",
            "Loss Detector regression: 0.09826359267268951\n",
            "Total loss: 5.853089999932156\n",
            "Elapsed time: 122.89231657981873\n",
            "Epoch 13/14\n",
            "1/6 [====>.........................] - ETA: 1:04 - rpn_cls: 6.4137 - rpn_regr: 0.1977 - final_cls: 0.7442 - final_regr: 6.2860e-04Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:08 - rpn_cls: 5.9116 - rpn_regr: 0.1744 - final_cls: 0.7846 - final_regr: 0.0047    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:23 - rpn_cls: 5.8514 - rpn_regr: 0.1659 - final_cls: 0.8336 - final_regr: 0.0068Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 49s - rpn_cls: 5.7725 - rpn_regr: 0.1552 - final_cls: 0.8641 - final_regr: 0.0478 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 126s 23s/step - rpn_cls: 5.7670 - rpn_regr: 0.1609 - final_cls: 0.9185 - final_regr: 0.0741\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.5384615384615384\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 5.8149964809417725\n",
            "Loss RPN regression: 0.1829678788781166\n",
            "Loss Detector classifier: 1.0366158187389374\n",
            "Loss Detector regression: 0.11512482947243068\n",
            "Total loss: 7.149705008031257\n",
            "Elapsed time: 125.72108268737793\n",
            "Epoch 14/14\n",
            "3/6 [==============>...............] - ETA: 47s - rpn_cls: 0.7932 - rpn_regr: 0.2082 - final_cls: 1.2520 - final_regr: 0.1585 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 16s - rpn_cls: 1.3250 - rpn_regr: 0.2214 - final_cls: 1.2775 - final_regr: 0.1501Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 128s 22s/step - rpn_cls: 1.5575 - rpn_regr: 0.2217 - final_cls: 1.2795 - final_regr: 0.1610\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.3636363636363635\n",
            "Classifier accuracy for bounding boxes from RPN: 0.5416666666666666\n",
            "Loss RPN classifier: 2.719737903941071\n",
            "Loss RPN regression: 0.22340433237453303\n",
            "Loss Detector classifier: 1.2895920674006145\n",
            "Loss Detector regression: 0.21531194931594655\n",
            "Total loss: 4.448046253032166\n",
            "Elapsed time: 127.58155369758606\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9fYNxQUtwQ",
        "outputId": "f032a71b-7c9e-4f3f-9800-bbadf14e30b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(save_path,overwrite=True)\n",
        "                    #model_all.save_weights(save_path, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/14\n",
            "4/6 [===================>..........] - ETA: 27s - rpn_cls: 0.4595 - rpn_regr: 0.1682 - final_cls: 1.3764 - final_regr: 0.0015Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 90s 15s/step - rpn_cls: 0.7552 - rpn_regr: 0.1888 - final_cls: 1.3170 - final_regr: 0.0088\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.1428571428571428\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 1.3198564989337076\n",
            "Loss RPN regression: 0.224336518595616\n",
            "Loss Detector classifier: 1.1763743956883748\n",
            "Loss Detector regression: 0.04527883185073733\n",
            "Total loss: 2.7658462450684356\n",
            "Elapsed time: 90.01951956748962\n",
            "Epoch 16/14\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 1:52 - rpn_cls: 4.7473 - rpn_regr: 0.6077 - final_cls: 1.2393 - final_regr: 9.3442e-05Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 59s - rpn_cls: 5.4007 - rpn_regr: 0.6421 - final_cls: 1.2040 - final_regr: 0.0288     Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 46s - rpn_cls: 4.9915 - rpn_regr: 0.6189 - final_cls: 1.1935 - final_regr: 0.0377Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 24s - rpn_cls: 4.6621 - rpn_regr: 0.6069 - final_cls: 1.1876 - final_regr: 0.0405Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 141s 24s/step - rpn_cls: 4.3517 - rpn_regr: 0.5874 - final_cls: 1.1687 - final_regr: 0.0411\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.5\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 2.7996254063521824\n",
            "Loss RPN regression: 0.4901788119847576\n",
            "Loss Detector classifier: 1.0741977393627167\n",
            "Loss Detector regression: 0.04415605041989087\n",
            "Total loss: 4.408158008119547\n",
            "Elapsed time: 140.97090983390808\n",
            "Epoch 17/14\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 1:54 - rpn_cls: 0.0291 - rpn_regr: 0.0811 - final_cls: 0.6347 - final_regr: 4.2086e-04Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 102s 16s/step - rpn_cls: 1.1532 - rpn_regr: 0.1661 - final_cls: 0.8409 - final_regr: 0.0486\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.0\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 2.569663855242652\n",
            "Loss RPN regression: 0.19906585787733397\n",
            "Loss Detector classifier: 0.9113968809445699\n",
            "Loss Detector regression: 0.07851364855499317\n",
            "Total loss: 3.7586402426195495\n",
            "Elapsed time: 102.30331301689148\n",
            "Epoch 18/14\n",
            "1/6 [====>.........................] - ETA: 1:18 - rpn_cls: 2.9854e-07 - rpn_regr: 0.1043 - final_cls: 1.7998 - final_regr: 0.7490Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "2/6 [=========>....................] - ETA: 1:07 - rpn_cls: 0.0327 - rpn_regr: 0.1439 - final_cls: 1.8312 - final_regr: 0.5618    Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 15s - rpn_cls: 1.3733 - rpn_regr: 0.2433 - final_cls: 1.6132 - final_regr: 0.3421Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 110s 19s/step - rpn_cls: 1.4809 - rpn_regr: 0.2501 - final_cls: 1.5687 - final_regr: 0.3059\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.7\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 2.018818948504697\n",
            "Loss RPN regression: 0.28429388999938965\n",
            "Loss Detector classifier: 1.345944086710612\n",
            "Loss Detector regression: 0.12485326570579976\n",
            "Total loss: 3.7739101909204984\n",
            "Elapsed time: 109.66622614860535\n",
            "Epoch 19/14\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "1/6 [====>.........................] - ETA: 1:50 - rpn_cls: 6.1064 - rpn_regr: 0.4608 - final_cls: 1.1571 - final_regr: 4.0999e-04Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 32s - rpn_cls: 5.1414 - rpn_regr: 0.3002 - final_cls: 1.1211 - final_regr: 0.0749Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 111s 18s/step - rpn_cls: 4.4230 - rpn_regr: 0.2669 - final_cls: 1.0825 - final_regr: 0.0890\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.8\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 2.721207618402938\n",
            "Loss RPN regression: 0.18781753381093344\n",
            "Loss Detector classifier: 1.0091788669427235\n",
            "Loss Detector regression: 0.17182582405318195\n",
            "Total loss: 4.090029843209777\n",
            "Elapsed time: 111.27223634719849\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nujhdfLVUzbK",
        "outputId": "b517e244-1011-4183-ba26-3b362efa87fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(save_path,overwrite=True)\n",
        "                    #model_all.save_weights('drive/My Drive/Parasite/New/Newlabel/model.h5', overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/14\n",
            "6/6 [==============================] - 62s 10s/step - rpn_cls: 6.1242 - rpn_regr: 0.2514 - final_cls: 1.0777 - final_regr: 0.1160\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.8\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 5.98693968852361\n",
            "Loss RPN regression: 0.21079356347521147\n",
            "Loss Detector classifier: 1.0133004784584045\n",
            "Loss Detector regression: 0.1467524993410431\n",
            "Total loss: 7.357786229798269\n",
            "Elapsed time: 61.757169246673584\n",
            "Epoch 26/14\n",
            "4/6 [===================>..........] - ETA: 28s - rpn_cls: 4.8243 - rpn_regr: 0.1947 - final_cls: 1.1959 - final_regr: 0.4018Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 89s 16s/step - rpn_cls: 3.9983 - rpn_regr: 0.2253 - final_cls: 1.1575 - final_regr: 0.3160\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.0\n",
            "Classifier accuracy for bounding boxes from RPN: 0.7083333333333334\n",
            "Loss RPN classifier: 2.1333140809244164\n",
            "Loss RPN regression: 0.29510147124528885\n",
            "Loss Detector classifier: 1.0666851103305817\n",
            "Loss Detector regression: 0.13148772532197958\n",
            "Total loss: 3.6265883878222667\n",
            "Elapsed time: 89.38986110687256\n",
            "Epoch 27/14\n",
            "2/6 [=========>....................] - ETA: 43s - rpn_cls: 6.0086 - rpn_regr: 0.2122 - final_cls: 0.8956 - final_regr: 0.0084     Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 56s - rpn_cls: 5.9642 - rpn_regr: 0.2316 - final_cls: 0.8784 - final_regr: 0.0093Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 39s - rpn_cls: 5.5751 - rpn_regr: 0.2325 - final_cls: 0.8784 - final_regr: 0.0091Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 23s - rpn_cls: 5.3268 - rpn_regr: 0.2304 - final_cls: 0.8861 - final_regr: 0.0087Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 133s 23s/step - rpn_cls: 5.2190 - rpn_regr: 0.2292 - final_cls: 0.8896 - final_regr: 0.0082\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.46153846153846156\n",
            "Classifier accuracy for bounding boxes from RPN: 0.75\n",
            "Loss RPN classifier: 4.679958407379066\n",
            "Loss RPN regression: 0.22331398725509644\n",
            "Loss Detector classifier: 0.9075254698594412\n",
            "Loss Detector regression: 0.005761239699116534\n",
            "Total loss: 5.816559104192719\n",
            "Elapsed time: 133.26358079910278\n",
            "Epoch 28/14\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.\n",
            "2/6 [=========>....................] - ETA: 47s - rpn_cls: 4.8102 - rpn_regr: 0.3570 - final_cls: 1.0049 - final_regr: 3.6310e-04 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 33s - rpn_cls: 4.2758 - rpn_regr: 0.3283 - final_cls: 0.9874 - final_regr: 0.0252Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 149s 19s/step - rpn_cls: 3.8498 - rpn_regr: 0.3548 - final_cls: 1.0631 - final_regr: 0.0667\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.4444444444444444\n",
            "Classifier accuracy for bounding boxes from RPN: 0.6666666666666666\n",
            "Loss RPN classifier: 2.7267584291094877\n",
            "Loss RPN regression: 0.4128214207788308\n",
            "Loss Detector classifier: 1.1978011926015217\n",
            "Loss Detector regression: 0.13590263730050842\n",
            "Total loss: 4.473283679790349\n",
            "Elapsed time: 149.28248238563538\n",
            "Epoch 29/14\n",
            "1/6 [====>.........................] - ETA: 56s - rpn_cls: 0.0131 - rpn_regr: 0.4982 - final_cls: 0.6936 - final_regr: 0.0223Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "3/6 [==============>...............] - ETA: 1:09 - rpn_cls: 1.7505 - rpn_regr: 0.4504 - final_cls: 1.3901 - final_regr: 0.1993Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "4/6 [===================>..........] - ETA: 49s - rpn_cls: 2.1474 - rpn_regr: 0.4557 - final_cls: 1.6624 - final_regr: 0.2561 Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "5/6 [========================>.....] - ETA: 25s - rpn_cls: 2.4522 - rpn_regr: 0.4666 - final_cls: 1.7791 - final_regr: 0.2733Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "Exception: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    <ipython-input-24-84f9950f7cd7>:53 class_loss_regr_fixed_num  *\n",
            "        x = y_true[:, :, 4*num_classes:] - y_pred\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n",
            "        raise e\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n",
            "        return func(x, y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n",
            "        return target(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract\n",
            "        return gen_math_ops.sub(x, y, name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10654 sub\n",
            "        \"Sub\", x=x, y=y, name=name)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper\n",
            "        inferred_from[input_arg.type_attr]))\n",
            "\n",
            "    TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type int64 of argument 'x'.\n",
            "\n",
            "6/6 [==============================] - 146s 27s/step - rpn_cls: 2.6942 - rpn_regr: 0.4628 - final_cls: 1.8193 - final_regr: 0.2825\n",
            "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.8125\n",
            "Classifier accuracy for bounding boxes from RPN: 0.5416666666666666\n",
            "Loss RPN classifier: 3.904300250733892\n",
            "Loss RPN regression: 0.44355972732106846\n",
            "Loss Detector classifier: 2.020740350087484\n",
            "Loss Detector regression: 0.3285297879483551\n",
            "Total loss: 6.697130116090799\n",
            "Elapsed time: 146.09099960327148\n",
            "Training complete, exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOSpIJMU01y"
      },
      "source": [
        "start_time = time.time()\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n",
        "    \n",
        "    r_epochs += 1\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "\n",
        "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "                rpn_accuracy_rpn_monitor = []\n",
        "#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "                if mean_overlapping_bboxes == 0:\n",
        "                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
        "            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n",
        "\n",
        "            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n",
        "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n",
        "            P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "            # R: bboxes (shape=(300,4))\n",
        "            # Convert rpn layer to roi bboxes\n",
        "            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "            \n",
        "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n",
        "            # Y1: one hot code for bboxes from above => x_roi (X)\n",
        "            # Y2: corresponding labels and corresponding gt bboxes\n",
        "            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "            # If X2 is None means there are no matching bboxes\n",
        "            if X2 is None:\n",
        "                rpn_accuracy_rpn_monitor.append(0)\n",
        "                rpn_accuracy_for_epoch.append(0)\n",
        "                continue\n",
        "            \n",
        "            # Find out the positive anchors and negative anchors\n",
        "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "            if len(neg_samples) > 0:\n",
        "                neg_samples = neg_samples[0]\n",
        "            else:\n",
        "                neg_samples = []\n",
        "\n",
        "            if len(pos_samples) > 0:\n",
        "                pos_samples = pos_samples[0]\n",
        "            else:\n",
        "                pos_samples = []\n",
        "\n",
        "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "            if C.num_rois > 1:\n",
        "                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
        "                if len(pos_samples) < C.num_rois//2:\n",
        "                    selected_pos_samples = pos_samples.tolist()\n",
        "                else:\n",
        "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "                \n",
        "                # Randomly choose (num_rois - num_pos) neg samples\n",
        "                try:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "                except:\n",
        "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "                \n",
        "                # Save all the pos and neg samples in sel_samples\n",
        "                sel_samples = selected_pos_samples + selected_neg_samples\n",
        "            else:\n",
        "                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "                selected_pos_samples = pos_samples.tolist()\n",
        "                selected_neg_samples = neg_samples.tolist()\n",
        "                if np.random.randint(0, 2):\n",
        "                    sel_samples = random.choice(neg_samples)\n",
        "                else:\n",
        "                    sel_samples = random.choice(pos_samples)\n",
        "\n",
        "            # training_data: [X, X2[:, sel_samples, :]]\n",
        "            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n",
        "            #  X                     => img_data resized image\n",
        "            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n",
        "            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n",
        "            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n",
        "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "            losses[iter_num, 0] = loss_rpn[1]\n",
        "            losses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "            losses[iter_num, 2] = loss_class[1]\n",
        "            losses[iter_num, 3] = loss_class[2]\n",
        "            losses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "            iter_num += 1\n",
        "\n",
        "            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "\n",
        "            if iter_num == epoch_length:\n",
        "                loss_rpn_cls = np.mean(losses[:, 0])\n",
        "                loss_rpn_regr = np.mean(losses[:, 1])\n",
        "                loss_class_cls = np.mean(losses[:, 2])\n",
        "                loss_class_regr = np.mean(losses[:, 3])\n",
        "                class_acc = np.mean(losses[:, 4])\n",
        "\n",
        "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "                rpn_accuracy_for_epoch = []\n",
        "\n",
        "                if C.verbose:\n",
        "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "                    elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "                iter_num = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "                if curr_loss < best_loss:\n",
        "                    if C.verbose:\n",
        "                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "                    best_loss = curr_loss\n",
        "                    model_all.save_weights(save_path,overwrite=True)\n",
        "                    #model_all.save_weights(save_path, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
        "\n",
        "\n",
        "                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                           'class_acc':round(class_acc, 3), \n",
        "                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                           'loss_class_cls':round(loss_class_cls, 3), \n",
        "                           'loss_class_regr':round(loss_class_regr, 3), \n",
        "                           'curr_loss':round(curr_loss, 3), \n",
        "                           'elapsed_time':round(elapsed_time, 3), \n",
        "                           'mAP': 0}\n",
        "\n",
        "                record_df = record_df.append(new_row, ignore_index=True)\n",
        "                record_df.to_csv(record_path, index=0)\n",
        "\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception: {}'.format(e))\n",
        "            continue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE1qTtYeU7CH"
      },
      "source": [
        "r_epochs=204\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n",
        "plt.title('mean_overlapping_bboxes')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n",
        "plt.title('class_acc')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n",
        "plt.title('loss_rpn_cls')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n",
        "plt.title('loss_rpn_regr')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "plt.title('loss_class_cls')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n",
        "plt.title('loss_class_regr')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "plt.title('total_loss')\n",
        "plt.show()\n",
        "\n",
        "# plt.figure(figsize=(15,5))\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n",
        "# plt.title('total_loss')\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['elapsed_time'], 'r')\n",
        "# plt.title('elapsed_time')\n",
        "# plt.show()\n",
        "\n",
        "# plt.title('loss')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'b')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'g')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n",
        "# plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'c')\n",
        "# # plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'm')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}